title,abstract,update_date,ai_generated
The Design of Efficiently-Encodable Rate-Compatible LDPC Codes,"  We present a new class of irregular low-density parity-check (LDPC) codes for
moderate block lengths (up to a few thousand bits) that are well-suited for
rate-compatible puncturing. The proposed codes show good performance under
puncturing over a wide range of rates and are suitable for usage in incremental
redundancy hybrid-automatic repeat request (ARQ) systems. In addition, these
codes are linear-time encodable with simple shift-register circuits. For a
block length of 1200 bits the codes outperform optimized irregular LDPC codes
and extended irregular repeat-accumulate (eIRA) codes for all puncturing rates
0.6~0.9 (base code performance is almost the same) and are particularly good at
high puncturing rates where good puncturing performance has been previously
difficult to achieve.
",2016-11-18,False
The Design of Efficiently-Encodable Rate-Compatible LDPC Codes,"This research paper presents a novel approach for designing rate-compatible low-density parity-check (LDPC) codes that can be efficiently encoded. The proposed method utilizes the concept of puncturing and shortening to achieve rate compatibility. The main contribution of the paper is the development of an efficient algorithm for generating rate-compatible LDPC codes with good performance. The proposed codes are evaluated through simulations, and the results demonstrate that they achieve competitive performance compared to state-of-the-art rate-compatible LDPC codes. The proposed methodology can be used for the design of efficient and flexible communication systems that can adapt to different channel conditions and data rates. Overall, the findings of this research provide insights into the development of rate-compatible LDPC codes that can be efficiently implemented in practical applications.",2016-11-18,True
"The Solar-Interior Equation of State with the Path-Integral Formalism I.
  Domain of Validity","  This is the first paper in a series that deals with solar-physics
applications of the equation-of-state formalism based on the formulation of the
so-called ""Feynman-Kac (FK) representation"". Here, the FK equation of state is
presented and adapted for solar applications. Its domain of validity is
assessed. The practical application to the Sun will be dealt with in Paper II.
Paper III will extend the current FK formalism to a higher order. Use of the FK
equation of state is limited to physical conditions for which more than 90% of
helium is ionized. This incudes the inner region of the Sun out to about .98 of
the solar radius. Despite this limitation, in the parts of the Sun where it is
applicable, the FK equation of state has the power to be more accurate than the
equations of state currently used in solar modeling. The FK approach is
especially suited to study physical effects such as Coulomb screening, bound
states, the onset of recombination of fully ionized species, as well as
diffraction and exchange effects. The localizing power of helioseismology
allows a test of the FK equation of state. Such a test will be beneficial both
for better solar models and for tighter solar constraints of the equation of
state.
",2009-08-07,False
"The Solar-Interior Equation of State with the Path-Integral Formalism I.
  Domain of Validity","The research paper titled ""The Solar-Interior Equation of State with the Path-Integral Formalism I. Domain of Validity"" presents a new approach to understanding the equation of state for the solar interior. The authors use the path-integral formalism to calculate the equation of state, which gives a more accurate description of the behavior of matter at high temperatures and densities. The study focuses on the domain of validity of the equation of state and found that the path-integral approach leads to a better agreement with observational data than previous models. The authors conclude that their new approach provides a more accurate description of the solar interior and can be applied to other astrophysical systems.",2009-08-07,True
Modified Brans-Dicke theory of gravity from five-dimensional vacuum,"  We investigate, in the context of five-dimensional (5D) Brans-Dicke theory of
gravity, the idea that macroscopic matter configurations can be generated from
pure vacuum in five dimensions, an approach first proposed in the framework of
general relativity. We show that the 5D Brans-Dicke vacuum equations when
reduced to four dimensions lead to a modified version of Brans-Dicke theory in
four dimensions (4D). As an application of the formalism, we obtain two
five-dimensional extensions of four-dimensional O'Hanlon and Tupper vacuum
solution and show that they lead two different cosmological scenarios in 4D.
",2008-11-26,False
Modified Brans-Dicke theory of gravity from five-dimensional vacuum,"This research paper investigates the Modified Brans-Dicke (MBD) theory of gravity derived from five-dimensional vacuum. The study analyzes the impact of the additional dimension on the scalar field of the MBD theory and derives the corresponding field equations. Our results reveal that the additional dimension's effect leads to the emergence of an additional scalar field, which influences the dynamics of gravity. The analysis reveals that the theory's predictions are consistent with the current experimental data. Furthermore, the study shows that the MBD theory can provide an alternative explanation for the dark matter and dark energy problems. The outcomes of this research have significant implications for the understanding of gravity and the universe's evolution.",2008-11-26,True
Free zero-range processes on networks,"  A free zero-range process (FRZP) is a simple stochastic process describing
the dynamics of a gas of particles hopping between neighboring nodes of a
network. We discuss three different cases of increasing complexity: (a) FZRP on
a rigid geometry where the network is fixed during the process, (b) FZRP on a
random graph chosen from a given ensemble of networks, (c) FZRP on a dynamical
network whose topology continuously changes during the process in a way which
depends on the current distribution of particles. The case (a) provides a very
simple realization of the phenomenon of condensation which manifests as the
appearance of a condensate of particles on the node with maximal degree. The
case (b) is very interesting since the averaging over typical ensembles of
graphs acts as a kind of homogenization of the system which makes all nodes
identical from the point of view of the FZRP. In the case (c), the distribution
of particles and the dynamics of network are coupled to each other. The
strength of this coupling depends on the ratio of two time scales: for changes
of the topology and of the FZRP. We will discuss a specific example of that
type of interaction and show that it leads to an interesting phase diagram.
",2007-10-25,False
Free zero-range processes on networks,"This research paper explores the use of free zero-range processes on networks as a basis for studying complex systems. Zero-range processes have been widely used in the study of particle systems, but their application to networked systems remains largely unexplored. In this paper, we investigate the properties of free zero-range processes on networks and demonstrate their usefulness in modeling a range of phenomena, from traffic flow to the spread of disease. We also provide a theoretical framework for analyzing these processes and discuss their potential applications in fields such as physics, biology, and engineering. Our findings suggest that free zero-range processes on networks offer a promising approach for understanding the behavior of complex systems and may lead to new insights and discoveries in a variety of fields.",2007-10-25,True
"Tail universalities in rank distributions as an algebraic problem: the
  beta-like function","  Although power laws of the Zipf type have been used by many workers to fit
rank distributions in different fields like in economy, geophysics, genetics,
soft-matter, networks etc., these fits usually fail at the tails. Some
distributions have been proposed to solve the problem, but unfortunately they
do not fit at the same time both ending tails. We show that many different data
in rank laws, like in granular materials, codons, author impact in scientific
journal, etc. are very well fitted by a beta-like function. Then we propose
that such universality is due to the fact that a system made from many
subsystems or choices, imply stretched exponential frequency-rank functions
which qualitatively and quantitatively can be fitted with the proposed
beta-like function distribution in the limit of many random variables. We prove
this by transforming the problem into an algebraic one: finding the rank of
successive products of a given set of numbers.
",2015-10-12,False
"Tail universalities in rank distributions as an algebraic problem: the
  beta-like function","This research paper aims to investigate the emergence of universal properties in rank distributions by exploring the algebraic basis of the beta-like function. The study utilizes mathematical models and analytical tools to examine the relationship between the beta-like function and tail universalities in rank distributions. The paper highlights the significance of the beta-like function as a basis for understanding the underlying algebraic structure of power-law distributions. The findings of this research contribute to the understanding of the mechanisms that govern the emergence of universal properties in complex systems and provide insights into the mathematical foundations of power-law distributions. Overall, this study sheds light on the algebraic problem of tail universalities in rank distributions and presents the beta-like function as a potential solution.",2015-10-12,True
Time-Reversal Coherent Control in Nanoplasmonics,"  We introduce an approach to determining the required waveforms to coherently
control the optical energy localization in plasmonic nanosystems. This approach
is based on the impulsive localized excitation of the nanosystem and time
reversal of the generated far-zone field at a single point with one
polarization. Despite strong interaction and significant dephasing and
dissipation in metal plasmonic systems, and incompleteness of this time
reversal, the proposed approach proves to be very efficient in controlling the
nanoscale optical fields. Possible applications include nanoscale spectroscopy
and photomodification, ultradense memory, and information processing on the
nanoscale.
",2007-05-23,False
Time-Reversal Coherent Control in Nanoplasmonics,"This research paper explores the use of time-reversal coherent control in nanoplasmonics, a promising field for nanophotonic applications. The study presents a theoretical model of time-reversal control and its application to nanoparticle systems. Using numerical simulations, the authors demonstrate the ability to manipulate nanoparticle properties such as scattering cross-section and field enhancement. The findings suggest that time-reversal coherent control can be a powerful tool to enhance the performance of plasmonic devices and improve their functionality.",2007-05-23,True
"Ballistic Graphene Nanoribbon MOSFETs: a full quantum real-space
  simulation study","  A real-space quantum transport simulator for carbon nanoribbon (CNR) MOSFETs
has been developed. Using this simulator, the performance of carbon nanoribbon
(CNR) MOSFETs is examined in the ballistic limit. The impact of quantum effects
on device performance of CNR MOSFETs is also studied. We found that 2D
semi-infinite graphene contacts provide metal-induced-gap-states (MIGS) in the
CNR channel. These states would provide quantum tunneling in the short channel
device and cause Fermi level pining. These effects cause device performance
degradation both on the ON-state and the OFF-state. Pure 1D devices (infinite
contacts), however, show no MIGS. Quantum tunneling effects are still playing
an important role in the device characteristics. Conduction due to band-to-band
tunneling is accurately captured in our simulations. It is important in these
devices, and found to dominate the off-state current. Based on our simulations,
both a 1.4nm wide and a 1.8nm wide CNR with channel length of 12.5nm can
outperform ultra scaled Si devices in terms of drive current capabilities and
electrostatic control. Although subthreshold slopes in the forward-bias
conduction are better than in Si transistors, tunneling currents are important
and prevent the achievement of the theoretical limit of 60mV/dec.
",2007-05-23,False
"Ballistic Graphene Nanoribbon MOSFETs: a full quantum real-space
  simulation study","This research paper presents a comprehensive quantum real-space simulation study of ballistic graphene nanoribbon MOSFETs. The simulation results reveal that the device performance is highly dependent on the width and edge configuration of the graphene nanoribbon. The study also highlights the potential of these devices for high-frequency applications due to their high carrier mobility. Additionally, the simulation results indicate the need for improved control over the doping level and edge roughness to optimize device performance. Overall, this study provides valuable insights into the design and optimization of graphene nanoribbon MOSFETs for future electronic applications.",2007-05-23,True
Rate Bounds for MIMO Relay Channels,"  This paper considers the multi-input multi-output (MIMO) relay channel where
multiple antennas are employed by each terminal. Compared to single-input
single-output (SISO) relay channels, MIMO relay channels introduce additional
degrees of freedom, making the design and analysis of optimal cooperative
strategies more complex. In this paper, a partial cooperation strategy that
combines transmit-side message splitting and block-Markov encoding is
presented. Lower bounds on capacity that improve on a previously proposed
non-cooperative lower bound are derived for Gaussian MIMO relay channels.
",2008-05-03,False
Rate Bounds for MIMO Relay Channels,"The research paper titled ""Rate Bounds for MIMO Relay Channels"" investigates the maximum achievable rate of a multiple-input multiple-output (MIMO) relay channel. The authors derive lower and upper bounds on the capacity of the MIMO relay channel with multiple antennas at the source, relay, and destination. They also propose a new achievable rate region for the MIMO relay channel, which outperforms previous results. The research concludes that the use of relay channels can significantly improve the communication rate and performance in MIMO systems. The proposed bounds and achievable rate region provide valuable insights into the fundamental limits and potential of MIMO relay channels.",2008-05-03,True
"Influence of the extent of the eigenstates of a system on the resonances
  formed through its coupling to a field","  We examine resonances for two systems consisting of a particle coupled to a
massless boson's field. The field is the free field in the whole space. In the
first system, the particle is confined inside a ball. We show that besides the
usual energy levels of the particle, which have become complex through the
coupling to the field, other resonances are to be taken into account if the
ball's radius is comparable to the particle's Compton wavelength. In the second
system, the particle is in a finite-depth square-well potential. We study the
way the resonances' width depends on the extent of the uncoupled particle's
wave functions. In both cases, we limit ourselves to considering two levels of
the particle only.
",2007-05-23,False
"Influence of the extent of the eigenstates of a system on the resonances
  formed through its coupling to a field","This paper explores the relationship between the extent of the eigenstates of a system and the resonances formed through its coupling to a field. Using theoretical analysis and numerical simulations, we investigate how the size of the eigenstates affects the formation and properties of resonances. Our results show that the extent of the eigenstates plays a crucial role in determining the resonance frequencies and widths, and that this effect is particularly pronounced for weak coupling strengths. We discuss the implications of our findings for various physical systems, including atoms, molecules, and solid-state devices, and suggest possible avenues for future experimental and theoretical research. Overall, this study sheds new light on the fundamental mechanisms underlying resonance phenomena and provides important insights into the design and optimization of resonant devices and systems.",2007-05-23,True
Bivariate linear mixed models using SAS proc MIXED,"  Bivariate linear mixed models are useful when analyzing longitudinal data of
two associated markers. In this paper, we present a bivariate linear mixed
model including random effects or first-order auto-regressive process and
independent measurement error for both markers. Codes and tricks to fit these
models using SAS Proc MIXED are provided. Limitations of this program are
discussed and an example in the field of HIV infection is shown. Despite some
limitations, SAS Proc MIXED is a useful tool that may be easily extendable to
multivariate response in longitudinal studies.
",2007-05-23,False
Bivariate linear mixed models using SAS proc MIXED,"The research paper titled ""Bivariate linear mixed models using SAS proc MIXED"" describes a method for analyzing two correlated continuous outcomes using SAS software. The authors explain the advantages of using bivariate models over separate univariate models and provide step-by-step instructions for implementing the approach in SAS proc MIXED. They also demonstrate the method using a real-world dataset. 

The study concludes that bivariate models can provide more accurate estimates and better prediction of outcomes compared to univariate models. The authors also highlight the importance of considering the correlation between outcomes in the analysis of longitudinal data. Overall, the research paper provides a useful guide for researchers interested in using bivariate models to analyze correlated continuous outcomes.",2007-05-23,True
Mixed models for longitudinal left-censored repeated measures,"  Longitudinal studies could be complicated by left-censored repeated measures.
For example, in Human Immunodeficiency Virus infection, there is a detection
limit of the assay used to quantify the plasma viral load. Simple imputation of
the limit of the detection or of half of this limit for left-censored measures
biases estimations and their standard errors. In this paper, we review two
likelihood-based methods proposed to handle left-censoring of the outcome in
linear mixed model. We show how to fit these models using SAS Proc NLMIXED and
we compare this tool with other programs. Indications and limitations of the
programs are discussed and an example in the field of HIV infection is shown.
",2007-05-23,False
Mixed models for longitudinal left-censored repeated measures,This research paper introduces mixed models as a statistical method for analyzing longitudinal left-censored repeated measures data. The paper discusses the advantages of using mixed models and provides examples of their application in various fields. Notable outcomes include increased accuracy and flexibility in analyzing complex data sets. The conclusion highlights the importance of utilizing appropriate statistical methods to draw meaningful conclusions from longitudinal studies.,2007-05-23,True
"Integrable lattices and their sublattices II. From the B-quadrilateral
  lattice to the self-adjoint schemes on the triangular and the honeycomb
  lattices","  An integrable self-adjoint 7-point scheme on the triangular lattice and an
integrable self-adjoint scheme on the honeycomb lattice are studied using the
sublattice approach. The star-triangle relation between these systems is
introduced, and the Darboux transformations for both linear problems from the
Moutard transformation of the B-(Moutard) quadrilateral lattice are obtained. A
geometric interpretation of the Laplace transformations of the self-adjoint
7-point scheme is given and the corresponding novel integrable discrete 3D
system is constructed.
",2010-04-19,False
"Integrable lattices and their sublattices II. From the B-quadrilateral
  lattice to the self-adjoint schemes on the triangular and the honeycomb
  lattices","The research paper explores the theory of integrable lattices and their sublattices. In particular, it focuses on the B-quadrilateral lattice and its relation to self-adjoint schemes on the triangular and honeycomb lattices. The paper presents a detailed analysis of the properties and symmetries of these lattices, and derives several important results concerning their integrability and the existence of special types of solutions. The main conclusion of the paper is that the B-quadrilateral lattice and its sublattices are important objects of study in the theory of integrable systems, and can be used to derive new insights into the properties of lattice models in physics and mathematics.",2010-04-19,True
"Continuum and all-atom description of the energetics of graphene
  nanocones","  Energies of graphene nanocones with 1 to 5 pentagonal disclinations are
studied on an atomically detailed level. The numerical results are interpreted
in terms of three different contributions to the cone energy: the core
disclination energy, the bending energy of the cone surface, and the ''line
tension'' energy of the cone edge that is related to different coordination of
carbon atoms situated at the edge. This continuum description allows for a
construction of analytic expressions for the cone energetics and indicates
different regimes of cone sizes in which cones with a particular number of
disclinations are preferred energywise. An important result of the study is
that the energetics of various types of cones profoundly depends upon whether
the dangling carbon bonds at the cone basis are saturated by hydrogen atoms or
not. This may be of use for explaining the differences in the yields of various
cone types in different production processes.
",2007-08-23,False
"Continuum and all-atom description of the energetics of graphene
  nanocones","This research paper investigates the energetics of graphene nanocones using both continuum and all-atom models. By comparing the results of these models, the paper reveals the importance of atomistic details in accurately predicting the energetics of graphene nanocones. The study also provides insights into the effects of cone angle and size on the energetics of graphene nanocones, which can inform the design and optimization of graphene-based nanodevices. Overall, the research highlights the relevance of combining different modeling techniques to fully understand the properties of complex nanosystems.",2007-08-23,True
"Applicability of layered sine-Gordon models to layered superconductors:
  II. The case of magnetic coupling","  In this paper, we propose a quantum field theoretical renormalization group
approach to the vortex dynamics of magnetically coupled layered
superconductors, to supplement our earlier investigations on the
Josephson-coupled case. We construct a two-dimensional multi-layer sine-Gordon
type model which we map onto a gas of topological excitations. With a special
choice of the mass matrix for our field theoretical model, vortex dominated
properties of magnetically coupled layered superconductors can be described.
The well known interaction potentials of fractional flux vortices are
consistently obtained from our field-theoretical analysis, and the physical
parameters (vortex fugacity and temperature parameter) are also identified. We
analyse the phase structure of the multi-layer sine--Gordon model by a
differential renormalization group method for the magnetically coupled case
from first principles. The dependence of the transition temperature on the
number of layers is found to be in agreement with known results based on other
methods.
",2009-11-13,False
"Applicability of layered sine-Gordon models to layered superconductors:
  II. The case of magnetic coupling","This research paper examines the applicability of layered sine-Gordon models to layered superconductors, specifically focusing on the case of magnetic coupling. The study investigates the effects of magnetic coupling on the behavior of layered superconductors and evaluates the suitability of the layered sine-Gordon model in accurately describing their properties. The research involves numerical simulations and analysis of the results, leading to conclusions on the effectiveness of the model in predicting the behavior of layered superconductors in the presence of magnetic coupling. The findings of this study can provide useful insights into the behavior of layered superconductors and contribute to the development of more accurate models for their description.",2009-11-13,True
"Stochastic resonance with weak monochromatic driving: gains above unity
  induced by high-frequency signals","  We study the effects of a high-frequency (HF) signal on the response of a
noisy bistable system to a low-frequency subthreshold sinusoidal signal. We
show that, by conveniently choosing the ratio of the amplitude of the HF signal
to its frequency, stochastic resonance gains greater than unity can be measured
at the low-frequency value. Thus, the addition of the HF signal can entail an
improvement in the detection of weak monochromatic signals. The results are
explained in terms of an effective model and illustrated by means of numerical
simulations.
",2016-08-14,False
"Stochastic resonance with weak monochromatic driving: gains above unity
  induced by high-frequency signals","This research study investigates the phenomenon of stochastic resonance with weak monochromatic driving and its ability to achieve gains above unity through high-frequency signals. The paper presents a theoretical framework for this phenomenon and analyzes the conditions under which it can occur. Results indicate that stochastic resonance with weak monochromatic driving can indeed achieve gains above unity through high-frequency signals, and that this effect is strongest when the system is near a bifurcation point. These findings have important implications for a wide range of applications, including signal processing, communication systems, and neural networks. Overall, this research paper concludes that stochastic resonance with weak monochromatic driving is a powerful and versatile mechanism that can be harnessed to enhance the performance of many different systems.",2016-08-14,True
"Actions of the braid group, and new algebraic proofs of results of
  Dehornoy and Larue","  This article surveys many standard results about the braid group with
emphasis on simplifying the usual algebraic proofs.
  We use van der Waerden's trick to illuminate the Artin-Magnus proof of the
classic presentation of the algebraic mapping-class group of a punctured disc.
  We give a simple, new proof of the Dehornoy-Larue braid-group trichotomy,
and, hence, recover the Dehornoy right-ordering of the braid group.
  We then turn to the Birman-Hilden theorem concerning braid-group actions on
free products of cyclic groups, and the consequences derived by Perron-Vannier,
and the connections with the Wada representations. We recall the very simple
Crisp-Paris proof of the Birman-Hilden theorem that uses the Larue-Shpilrain
technique. Studying ends of free groups permits a deeper understanding of the
braid group; this gives us a generalization of the Birman-Hilden theorem.
Studying Jordan curves in the punctured disc permits a still deeper
understanding of the braid group; this gave Larue, in his PhD thesis,
correspondingly deeper results, and, in an appendix, we recall the essence of
Larue's thesis, giving simpler combinatorial proofs.
",2016-08-14,False
"Actions of the braid group, and new algebraic proofs of results of
  Dehornoy and Larue","This research paper explores the actions of braid groups and their application in providing new algebraic proofs of results of Dehornoy and Larue. Braid groups have been extensively studied in algebraic topology, but their actions have not been fully understood. By examining the actions of braid groups, we are able to uncover new insights into their algebraic structure. In particular, we show how these actions can be leveraged to provide alternative proofs of results established by Dehornoy and Larue, which have important implications in a range of fields. Our findings have the potential to deepen our understanding of braid groups and their applications, and we anticipate that they will be of interest to researchers in algebraic topology and related fields.",2016-08-14,True
Clustering Co-occurrence of Maximal Frequent Patterns in Streams,"  One way of getting a better view of data is using frequent patterns. In this
paper frequent patterns are subsets that occur a minimal number of times in a
stream of itemsets. However, the discovery of frequent patterns in streams has
always been problematic. Because streams are potentially endless it is in
principle impossible to say if a pattern is often occurring or not. Furthermore
the number of patterns can be huge and a good overview of the structure of the
stream is lost quickly. The proposed approach will use clustering to facilitate
the analysis of the structure of the stream.
  A clustering on the co-occurrence of patterns will give the user an improved
view on the structure of the stream. Some patterns might occur so much together
that they should form a combined pattern. In this way the patterns in the
clustering will be the largest frequent patterns: maximal frequent patterns.
  Our approach to decide if patterns occur often together will be based on a
method of clustering when only the distance between pairs is known. The number
of maximal frequent patterns is much smaller and combined with clustering
methods these patterns provide a good view on the structure of the stream.
",2007-05-23,False
Clustering Co-occurrence of Maximal Frequent Patterns in Streams,"The paper focuses on clustering maximal frequent patterns in streams. The authors propose a novel algorithm that can cluster co-occurrence of maximal frequent patterns in real-time streams. The proposed algorithm is designed to handle high-dimensional and large-scale data and can effectively identify clusters of patterns with high co-occurrence. The authors evaluate the algorithm using real-world datasets and demonstrate its effectiveness in identifying clusters of frequent patterns. The main outcome of the study is the proposed algorithm, which provides a useful tool for analyzing and clustering frequent patterns in real-time streams. The study also highlights the importance of efficient data mining algorithms for handling high-dimensional and large-scale data.",2007-05-23,True
Clustering with Lattices in the Analysis of Graph Patterns,"  Mining frequent subgraphs is an area of research where we have a given set of
graphs (each graph can be seen as a transaction), and we search for (connected)
subgraphs contained in many of these graphs. In this work we will discuss
techniques used in our framework Lattice2SAR for mining and analysing frequent
subgraph data and their corresponding lattice information. Lattice information
is provided by the graph mining algorithm gSpan; it contains all
supergraph-subgraph relations of the frequent subgraph patterns -- and their
supports.
  Lattice2SAR is in particular used in the analysis of frequent graph patterns
where the graphs are molecules and the frequent subgraphs are fragments. In the
analysis of fragments one is interested in the molecules where patterns occur.
This data can be very extensive and in this paper we focus on a technique of
making it better available by using the lattice information in our clustering.
Now we can reduce the number of times the highly compressed occurrence data
needs to be accessed by the user. The user does not have to browse all the
occurrence data in search of patterns occurring in the same molecules. Instead
one can directly see which frequent subgraphs are of interest.
",2007-05-23,False
Clustering with Lattices in the Analysis of Graph Patterns,"The research paper explores the application of clustering with lattices in the analysis of graph patterns. The authors demonstrate the effectiveness of this method in identifying similar patterns within large datasets and highlight its potential for use in various fields. Notably, the paper provides insights into how clustering with lattices can improve the accuracy and efficiency of graph analysis.",2007-05-23,True
Physically Sound Hamiltonian Formulation of the Dynamical Casimir Effect,"  Recently [J. Haro and E. Elizalde, Phys. Rev. Lett. {\bf 97}, 130401 (2006)],
a Hamiltonian formulation has been introduced in order to address some
longstanding severe problems associated with the physical description of the
dynamical Casimir effect at all times while the mirrors are moving. Here we
present the complete calculation providing precise details, in particular, of
the regularization procedure, which is decisive for the correct derivation of
physically meaningful quantities. A basic difference when comparing with the
results previously obtained by other authors is the fact that the motion force
derived in our approach contains a reactive term --proportional to the mirrors'
acceleration. This is of the essence in order to obtain particles with a
positive energy all the time during the oscillation of the mirrors --while
always satisfying the energy conservation law. A careful analysis of the
interrelations among the different results previously obtained in the
literature is then carried out. For simplicity, the specific case of a neutral
scalar field in one dimension, with one or two partially transmitting mirrors
(a fundamental proviso for the regularization issue) is considered in more
detail, but our general method is shown to be generalizable, without essential
problems (Sect. 2 of this paper), to fields of any kind in two and higher
dimensions.
",2008-11-26,False
Physically Sound Hamiltonian Formulation of the Dynamical Casimir Effect,"This research paper presents a physically sound Hamiltonian formulation of the dynamical Casimir effect, a phenomenon where a vacuum is induced to produce real particles due to the time-varying boundary conditions of a cavity. The primary theme of the paper is to develop a rigorous mathematical framework that accurately describes the dynamics of the system and provides a physically intuitive understanding of the effect. The research findings suggest that the proposed Hamiltonian formulation provides a more accurate and complete description of the dynamical Casimir effect compared to previous formulations. The conclusions drawn from the study provide valuable insights into the physics of the effect and can aid in the design and development of experimental systems to observe the phenomenon.",2008-11-26,True
NodeTrix: Hybrid Representation for Analyzing Social Networks,"  The need to visualize large social networks is growing as hardware
capabilities make analyzing large networks feasible and many new data sets
become available. Unfortunately, the visualizations in existing systems do not
satisfactorily answer the basic dilemma of being readable both for the global
structure of the network and also for detailed analysis of local communities.
To address this problem, we present NodeTrix, a hybrid representation for
networks that combines the advantages of two traditional representations:
node-link diagrams are used to show the global structure of a network, while
arbitrary portions of the network can be shown as adjacency matrices to better
support the analysis of communities. A key contribution is a set of interaction
techniques. These allow analysts to create a NodeTrix visualization by dragging
selections from either a node-link or a matrix, flexibly manipulate the
NodeTrix representation to explore the dataset, and create meaningful summary
visualizations of their findings. Finally, we present a case study applying
NodeTrix to the analysis of the InfoVis 2004 coauthorship dataset to illustrate
the capabilities of NodeTrix as both an exploration tool and an effective means
of communicating results.
",2020-08-04,False
NodeTrix: Hybrid Representation for Analyzing Social Networks,"NodeTrix is a novel hybrid representation for analyzing social networks that combines the strengths of both node-link and matrix representations. In this paper, we present the design principles and implementation details of NodeTrix, and evaluate its effectiveness in various tasks such as detecting community structures, identifying influential nodes, and exploring network evolution. Our experiments show that NodeTrix provides a more effective and efficient approach for visualizing and analyzing social networks compared to traditional representations. Overall, NodeTrix has the potential to improve the understanding of complex network structures and facilitate decision-making in various domains.",2020-08-04,True
Risk Assessment Algorithms Based On Recursive Neural Networks,"  The assessment of highly-risky situations at road intersections have been
recently revealed as an important research topic within the context of the
automotive industry. In this paper we shall introduce a novel approach to
compute risk functions by using a combination of a highly non-linear processing
model in conjunction with a powerful information encoding procedure.
Specifically, the elements of information either static or dynamic that appear
in a road intersection scene are encoded by using directed positional acyclic
labeled graphs. The risk assessment problem is then reformulated in terms of an
inductive learning task carried out by a recursive neural network. Recursive
neural networks are connectionist models capable of solving supervised and
non-supervised learning problems represented by directed ordered acyclic
graphs. The potential of this novel approach is demonstrated through well
predefined scenarios. The major difference of our approach compared to others
is expressed by the fact of learning the structure of the risk. Furthermore,
the combination of a rich information encoding procedure with a generalized
model of dynamical recurrent networks permit us, as we shall demonstrate, a
sophisticated processing of information that we believe as being a first step
for building future advanced intersection safety systems
",2007-05-23,False
Risk Assessment Algorithms Based On Recursive Neural Networks,"This research paper explores the use of recursive neural networks (RNNs) for developing risk assessment algorithms. The study analyzes the effectiveness of RNNs in modeling the temporal dependencies of risk factors and predicting the likelihood of future events. The paper highlights the advantages of using RNNs over traditional machine learning algorithms and presents a case study on predicting credit default risk. Through empirical analysis, the research demonstrates the superior accuracy and efficiency of RNN-based risk assessment algorithms. The findings of this study have significant implications for risk management in various domains, including finance, healthcare, and cybersecurity.",2007-05-23,True
"Quasi Ordinary Singularities, Essential Divisors and Poincare Series","  We define Poincar\'e series associated to a toric or analytically irreducible
quasi-ordinary hypersurface singularity, (S,0), by a finite sequence of
monomial valuations, such that at least one of them is centered at the origin
0. This involves the definition of a multi-graded ring associated to the
analytic algebra of the singularity by the sequence of valuations. We prove
that the Poincar\'e series is a rational function with integer coefficients,
which can be defined also as an integral with respect of the Euler
characteristic, over the projectivization of the analytic algebra of the
singularity, of a function defined by the valuations. In particular, the
Poincar\'e series associated to the set of divisorial valuations associated to
the essential divisors, considered both over the singular locus and over the
point 0, is an analytic invariant of the singularity. In the quasi-ordinary
hypersurface case we prove that this Poincar\'e series determines and it is
determined by the normalized sequence of characteristic monomials. These
monomials in the analytic case define a complete invariant of the embedded
topological type of the hypersurface singularity.
",2014-02-26,False
"Quasi Ordinary Singularities, Essential Divisors and Poincare Series","This research paper explores the relationship between quasi-ordinary singularities, essential divisors, and Poincare series. The authors define and analyze essential divisors, which provide a way to decompose a singular variety into simpler pieces. They then use Poincare series to study the behavior of various invariants of the singular variety, such as cohomology and intersection theory. The main conclusion of the paper is that essential divisors and Poincare series provide powerful tools for understanding the geometry and topology of singular varieties.",2014-02-26,True
"Poloidal-toroidal decomposition in a finite cylinder. I. Influence
  matrices for the magnetohydrodynamic equations","  The Navier-Stokes equations and magnetohydrodynamics equations are written in
terms of poloidal and toroidal potentials in a finite cylinder. This
formulation insures that the velocity and magnetic fields are divergence-free
by construction, but leads to systems of partial differential equations of
higher order, whose boundary conditions are coupled. The influence matrix
technique is used to transform these systems into decoupled parabolic and
elliptic problems. The magnetic field in the induction equation is matched to
that in an exterior vacuum by means of the Dirichlet-to-Neumann mapping, thus
eliminating the need to discretize the exterior. The influence matrix is scaled
in order to attain an acceptable condition number.
",2007-11-22,False
"Poloidal-toroidal decomposition in a finite cylinder. I. Influence
  matrices for the magnetohydrodynamic equations","This paper investigates the use of poloidal-toroidal decomposition in the analysis of the magnetohydrodynamic (MHD) equations in a finite cylinder. In particular, we focus on the development of influence matrices for the decomposition, which can be used to identify the impact of various physical and geometric parameters on the MHD equations. We present a detailed derivation of the influence matrices, as well as numerical simulations to demonstrate their efficacy. Our results highlight the importance of considering the poloidal-toroidal decomposition in the analysis of MHD equations in a finite cylinder, and provide a valuable tool for future research in this area.",2007-11-22,True
"Privacy - an Issue for eLearning? A Trend Analysis Reflecting the
  Attitude of European eLearning Users","  Availing services provided via the Internet became a widely accepted means in
organising one's life. Beside others, eLearning goes with this trend as well.
But, while employing Internet service makes life more convenient, at the same
time, it raises risks with respect to the protection of the users' privacy.
This paper analyses the attitudes of eLearning users towards their privacy by,
initially, pointing out terminology and legal issues connected with privacy.
Further, the concept and implementation as well as a result analysis of a
conducted study is presented, which explores the problem area from different
perspectives. The paper will show that eLearning users indeed care for the
protection of their personal information when using eLearning services.
However, their attitudes and behaviour slightly differ. In conclusion, we
provide first approaches of assisting possibilities for users how to resolve
the difference of requirements and their actual activities with respect to
privacy protection.
",2007-05-23,False
"Privacy - an Issue for eLearning? A Trend Analysis Reflecting the
  Attitude of European eLearning Users","This research paper examines the issue of privacy in eLearning and analyzes the attitudes of European eLearning users towards this issue. The paper presents a trend analysis of the current state of privacy in eLearning, including the legal framework and existing policies. The study concludes that privacy is indeed a concern for eLearning users, and that there is a need for better privacy protection measures. The paper suggests that eLearning providers should take steps to address these concerns and improve privacy protection for users.",2007-05-23,True
"Axion Searches in the Past, at Present, and in the Near Future","  Theoretical axion models state that axions are very weakly interacting
particles. In order to experimentally detect them, the use of colorful and
inspired techniques becomes mandatory. There is a wide variety of experimental
approaches that were developed during the last 30 years, most of them make use
of the Primakoff effect, by which axions convert into photons in the presence
of an electromagnetic field. We review the experimental techniques used to
search for axions and will give an outlook on experiments planned for the near
future.
",2011-04-11,False
"Axion Searches in the Past, at Present, and in the Near Future","This research paper provides an overview of the past, present, and future searches for axions, a hypothetical particle that could solve several outstanding problems in physics. The paper covers the history of axion searches, the current status of experimental efforts, and the potential for future discoveries. The authors highlight recent advances in technology that have enabled more sensitive searches and discuss the implications of negative results. Overall, the paper emphasizes the importance of continued axion research in the quest to understand the fundamental nature of the universe.",2011-04-11,True
Monitoring Air Moisture with Laser Absorption Spectroscopy,"  Determination of air density and the quantitative estimates of water vapour
adsorbed or desorbed by the surface of mass standard, remain the principals
sources of uncertainties when weighing mass standard made from stainless steel
or super alloy. The classical method, for air density determination, use the so
called CIPM-1981/91 formula and the measured air parameters. An other approach
is based only on the results of comparisons, realized successively in air and
in vacuum, between special artefacts. The distribution and the state of water
molecules inside the chamber of mass comparator influence the results of
weighing. Also, the instruments used for air moisture measurement are either,
not very sensitive (capacitive hygrometer) or disturbing for environment
(dew-point hygrometer). To control that, a proposal method is given and
observations of water vapour behaviour inside the enclosure for different
conditions are reported. Keywords. mass metrology, air density, water vapour
",2007-05-23,False
Monitoring Air Moisture with Laser Absorption Spectroscopy,"The research paper titled ""Monitoring Air Moisture with Laser Absorption Spectroscopy"" explores the use of laser absorption spectroscopy to measure water vapor in the atmosphere. The main subject of the paper is the potential of this technology to provide highly accurate and sensitive measurements of atmospheric moisture, which can be used to improve weather forecasting and climate modeling.

The paper presents the results of laboratory experiments and field tests of a laser absorption spectrometer designed to measure water vapor in real-time. The researchers found that the instrument was able to detect changes in atmospheric moisture levels with a high degree of accuracy and precision, even in challenging environments with high levels of interference from other gases.

The paper concludes that laser absorption spectroscopy has significant potential as a tool for monitoring air moisture, and could be used to improve our understanding of weather patterns and climate change. However, further research is needed to optimize the technology and ensure that it can be deployed effectively in a range of real-world settings.",2007-05-23,True
Optical detection of anyons in an integer quantum Hall system,"  Further experiments showed the incorrectness of proposed interpretation. We
have studied an in-plane resonant photo-response of an integer quantum Hall
system in which time-reversal and parity symmetries are broken. The response of
initially homogeneous system exhibits a complicate spatial structure sensitive
to the system macroscopic sizes. Conceptually, the effect is explained by the
large-scale quantum entanglement originated from an indistinguishable particle
statistics. The concept is supported by the demonstration of
entanglement-related transfer of information in the system interior.
",2013-02-12,False
Optical detection of anyons in an integer quantum Hall system,"The research paper titled ""Optical detection of anyons in an integer quantum Hall system"" discusses the experimental observation of anyons in an integer quantum Hall system using optical methods. The study uses a two-dimensional electron gas confined to a GaAs quantum well and subjected to a strong magnetic field.

The researchers observed the creation of anyons by applying a well-calibrated laser pulse to the system, which creates a quasiparticle excitation. The excitation then splits into two anyons, which move in opposite directions along the edge of the sample.

The results of the study provide evidence for the existence of anyons in an integer quantum Hall system and demonstrate the potential for using optical methods to manipulate and control these particles. The findings have significant implications for the development of topological quantum computing, which relies on the properties of anyons to perform calculations that are resistant to errors caused by environmental noise.

Overall, the research paper highlights the importance of studying anyons in quantum systems and provides a promising avenue for further research in this field.",2013-02-12,True
"Understanding fragility in supercooled Lennard-Jones mixtures. I.
  Locally preferred structures","  We reveal the existence of systematic variations of isobaric fragility in
different supercooled Lennard-Jones binary mixtures by performing molecular
dynamics simulations. The connection between fragility and local structures in
the bulk is analyzed by means of a Voronoi construction. We find that clusters
of particles belonging to locally preferred structures form slow, long-lived
domains, whose spatial extension increases by decreasing temperature. As a
general rule, a more rapid growth, upon supercooling, of such domains is
associated to a more pronounced super-Arrhenius behavior, hence to a larger
fragility.
",2007-10-02,False
"Understanding fragility in supercooled Lennard-Jones mixtures. I.
  Locally preferred structures","This research paper aims at understanding the fragility in supercooled Lennard-Jones mixtures by investigating the locally preferred structures. The study uses molecular dynamics simulations to analyze the structural and dynamical properties of the mixtures. The results show that the mixtures exhibit fragility, which is attributed to the formation of locally preferred structures that impede the mobility of the molecules. The study also reveals that the fragility is strongly correlated with the degree of structural ordering and the size of the locally preferred structures. These findings provide a better understanding of the underlying mechanisms of fragility in supercooled mixtures, with potential applications in materials science and industrial processes.",2007-10-02,True
"Understanding fragility in supercooled Lennard-Jones mixtures. II.
  Potential energy surface","  We numerically investigated the connection between isobaric fragility and the
properties of high-order stationary points of the potential energy surface in
different supercooled Lennard-Jones mixtures. The increase of effective
activation energies upon supercooling appears to be driven by the increase of
average potential energy barriers measured by the energy dependence of the
fraction of unstable modes. Such an increase is sharper, the more fragile is
the mixture. Correlations between fragility and other properties of high-order
stationary points, including the vibrational density of states and the
localization features of unstable modes, are also discussed.
",2007-10-02,False
"Understanding fragility in supercooled Lennard-Jones mixtures. II.
  Potential energy surface","This research paper investigates the underlying causes of fragility in supercooled Lennard-Jones mixtures by analyzing the potential energy surface. The fragility of these mixtures is a well-known phenomenon, characterized by a rapid increase in viscosity with decreasing temperature. By exploring the potential energy surface, we aim to gain a deeper understanding of the complex dynamics and structural changes that occur in supercooled mixtures. Our results suggest that the fragility of Lennard-Jones mixtures is closely related to the complexity of the potential energy surface, which exhibits a high degree of roughness and heterogeneity. This study provides valuable insights into the mechanisms that govern the behavior of supercooled mixtures, with potential applications in fields such as materials science and chemical engineering.",2007-10-02,True
Dyons with potentials: duality and black hole thermodynamics,"  A modified version of the double potential formalism for the electrodynamics
of dyons is constructed. Besides the two vector potentials, this manifestly
duality invariant formulation involves four additional potentials, scalar
potentials which appear as Lagrange multipliers for the electric and magnetic
Gauss constraints and potentials for the longitudinal electric and magnetic
fields. In this framework, a static dyon appears as a Coulomb-like solution
without string singularities. Dirac strings are needed only for the Lorentz
force law, not for Maxwell's equations. The magnetic charge no longer appears
as a topological conservation law but as a surface integral on a par with
electric charge. The theory is generalized to curved space. As in flat space,
the string singularities of dyonic black holes are resolved. As a consequence
all singularities are protected by the horizon and the thermodynamics is shown
to follow from standard arguments in the grand canonical ensemble.
",2008-11-26,False
Dyons with potentials: duality and black hole thermodynamics,"This research paper focuses on the study of dyons with potentials, exploring the duality and black hole thermodynamics of such systems. Through a theoretical analysis of the electromagnetic potentials of dyons, we demonstrate the existence of a duality symmetry that relates electric and magnetic charges. We also investigate the thermodynamic properties of black holes in the presence of dyons and their potentials, showing that the dyonic contributions to the entropy and temperature of black holes can be significant. Our findings provide new insights into the behavior of dyons and their interactions with black holes, and could have important implications for the understanding of fundamental physics and cosmology.",2008-11-26,True
Formation of OB Associations in Galaxies,"  We consider the formation of OB associations from two perspectives: (a) the
fractional gas consumption in star formation,epsilon, per dynamical time scale
t_dyn in a galaxy, and (b) the origin of the so-called Kennicutt-Schmidt law
that the rate of star formation per unit area is proportional to a power,
alpha, of the surface density in HI and H_2 gas when certain thresholds are
crossed. The empirical findings that epsilon is approximately 0.01 and alpha is
approximately 1.4 or 1.5 have simple explanations if the rate of star formation
is magnetically regulated. An empirical test of the ideas resides in an
analysis of why giant OB associations are ``strung out like pearls along the
arms"" of spiral galaxies.
",2009-11-13,False
Formation of OB Associations in Galaxies,"This research paper investigates the formation of OB associations in galaxies with the primary focus on understanding the underlying physical processes and environmental factors that influence their formation. Based on a comprehensive analysis of observational data and theoretical simulations, the study reveals that OB associations are predominantly formed in the spiral arms regions of galaxies, where the density of gas and dust is higher, providing an ideal environment for the formation of massive stars. The critical outcome of this study is the identification of several key factors, such as the density of interstellar gas, the presence of magnetic fields, and the initial mass function, that significantly influence the formation and evolution of OB associations in galaxies. The study also provides important insights into the role of OB associations in galactic evolution and the formation of other stellar structures. Overall, the research highlights the importance of understanding the formation of OB associations in galaxies for advancing our knowledge of astrophysics and cosmology.",2009-11-13,True
"Moving Walkways, Escalators, and Elevators","  We study a simple geometric model of transportation facility that consists of
two points between which the travel speed is high. This elementary definition
can model shuttle services, tunnels, bridges, teleportation devices, escalators
or moving walkways. The travel time between a pair of points is defined as a
time distance, in such a way that a customer uses the transportation facility
only if it is helpful.
  We give algorithms for finding the optimal location of such a transportation
facility, where optimality is defined with respect to the maximum travel time
between two points in a given set.
",2011-11-09,False
"Moving Walkways, Escalators, and Elevators","This research paper investigates the impact of moving walkways, escalators, and elevators on pedestrian traffic flow in public spaces. The study examines the efficiency and safety of these forms of transportation for pedestrians, and the factors that influence their use. The research uses a combination of quantitative analysis and qualitative observations to assess the effectiveness of these systems. The findings suggest that moving walkways and escalators are more efficient in high traffic areas, while elevators are better suited for vertical movement. Additionally, the study highlights the importance of proper design and maintenance of these systems to ensure optimal performance and safety for pedestrians. Overall, this research provides valuable insights for urban planners and designers in creating pedestrian-friendly public spaces.",2011-11-09,True
"Bond formation and slow heterogeneous dynamics in adhesive spheres with
  long--ranged repulsion: Quantitative test of Mode Coupling Theory","  A colloidal system of spheres interacting with both a deep and narrow
attractive potential and a shallow long-ranged barrier exhibits a prepeak in
the static structure factor. This peak can be related to an additional
mesoscopic length scale of clusters and/or voids in the system. Simulation
studies of this system have revealed that it vitrifies upon increasing the
attraction into a gel-like solid at intermediate densities. The dynamics at the
mesoscopic length scale corresponding to the prepeak represents the slowest
mode in the system. Using mode coupling theory with all input directly taken
from simulations, we reveal the mechanism for glassy arrest in the system at
40% packing fraction. The effects of the low-q peak and of polydispersity are
considered in detail. We demonstrate that the local formation of physical bonds
is the process whose slowing down causes arrest.
  It remains largely unaffected by the large-scale heterogeneities, and sets
the clock for the slow cluster mode. Results from mode-coupling theory without
adjustable parameters agree semi-quantitatively with the local density
correlators but overestimate the lifetime of the mesoscopic structure (voids).
",2009-11-13,False
"Bond formation and slow heterogeneous dynamics in adhesive spheres with
  long--ranged repulsion: Quantitative test of Mode Coupling Theory","The aim of this research paper is to investigate the bond formation and slow heterogeneous dynamics in adhesive spheres with long-ranged repulsion. We present a quantitative test of Mode Coupling Theory (MCT) to understand the dynamic behavior of these systems. Our results demonstrate that MCT is capable of predicting the slow dynamics observed in these systems, particularly the dynamics of bond formation and the formation of glassy structures. Moreover, our findings indicate that the long-range repulsion significantly affects the dynamics, leading to a more complex behavior. Our study provides insights into the fundamental understanding of the dynamic behavior of adhesive spheres and highlights the importance of considering long-range interactions in predicting their behavior.",2009-11-13,True
"A Rigorous Path Integral for Supersymmetric Quantum Mechanics and the
  Heat Kernel","  In a rigorous construction of the path integral for supersymmetric quantum
mechanics on a Riemann manifold, based on B\""ar and Pf\""affle's use of
piecewise geodesic paths, the kernel of the time evolution operator is the heat
kernel for the Laplacian on forms. The path integral is approximated by the
integral of a form on the space of piecewise geodesic paths which is the
pullback by a natural section of Mathai and Quillen's Thom form of a bundle
over this space.
  In the case of closed paths, the bundle is the tangent space to the space of
geodesic paths, and the integral of this form passes in the limit to the
supertrace of the heat kernel.
",2008-11-26,False
"A Rigorous Path Integral for Supersymmetric Quantum Mechanics and the
  Heat Kernel",This research paper presents a rigorous path integral approach to solve supersymmetric quantum mechanics problems and to calculate the heat kernel. The method is based on the supersymmetric extension of the Feynman-Kac formula and the associated bosonic and fermionic coherent states. The authors show that the path integral is well-defined and can be expressed in terms of the heat kernel. They also demonstrate the usefulness of this approach by applying it to a simple example of a supersymmetric harmonic oscillator and comparing the results with the standard supersymmetric algebraic method. This new path integral approach provides a powerful tool for solving supersymmetric quantum mechanics problems and exploring their physical implications.,2008-11-26,True
Hydrocarbon anions in interstellar clouds and circumstellar envelopes,"  The recent detection of the hydrocarbon anion C6H- in the interstellar medium
has led us to investigate the synthesis of hydrocarbon anions in a variety of
interstellar and circumstellar environments. We find that the anion/neutral
abundance ratio can be quite large, on the order of at least a few percent,
once the neutral has more than five carbon atoms. Detailed modeling shows that
the column densities of C6H- observed in IRC+10216 and TMC-1 can be reproduced.
Our calculations also predict that other hydrocarbon anions, such as C4H- and
C8H-, are viable candidates for detection in IRC+10216, TMC-1 and
photon-dominated regions such as the Horsehead Nebula.
",2009-11-13,False
Hydrocarbon anions in interstellar clouds and circumstellar envelopes,"Hydrocarbon anions have been detected in various interstellar clouds and circumstellar envelopes, providing important insights into the chemical processes occurring in these environments. This paper reviews the current state of knowledge on the detection, properties, and formation mechanisms of hydrocarbon anions in interstellar clouds and circumstellar envelopes. Theoretical and experimental studies of the structures and reactivity of these anions are discussed, with a particular focus on their potential roles in the formation of larger organic molecules. The implications of these findings for our understanding of the origin of life and the evolution of planetary systems are also considered. Overall, the detection of hydrocarbon anions in these environments highlights the richness and complexity of interstellar chemistry and underscores the importance of continued research in this field.",2009-11-13,True
"Simultaneous recording of two- and four-probe resistive transitions in
  doped laser-processed Sr-Ru-O","  To confirm previously reported evidence of high-temperature superconductivity
in laser processed Sr-Ru-O, we performed simultaneous two-probe and four-probe
resistive measurements using bar-geometry samples. A superconducting-type
transition with an onset at about 250K was recorded in one of the samples,
consistent with our previously reported measurements in the X-bridge geometry.
Some compositional details of the samples are also provided which were not
known at the time of previous web-publication.
",2009-11-13,False
"Simultaneous recording of two- and four-probe resistive transitions in
  doped laser-processed Sr-Ru-O","The research paper titled ""Simultaneous recording of two- and four-probe resistive transitions in doped laser-processed Sr-Ru-O"" focuses on studying the electrical properties of doped laser-processed Sr-Ru-O. The primary theme of the research is to understand the resistive transitions in this material by simultaneously recording two- and four-probe measurements. The study reveals that the resistive transitions in doped laser-processed Sr-Ru-O are highly dependent on the dopant concentration and the measurement technique used. The research provides important insights into the electrical properties of this material, which can be useful in the development of new electronic devices.",2009-11-13,True
The star-forming content of the W3 giant molecular cloud,"  We have surveyed a ~0.9-square-degree area of the W3 giant molecular cloud
and star-forming region in the 850-micron continuum, using the SCUBA bolometer
array on the James Clerk Maxwell Telescope. A complete sample of 316 dense
clumps was detected with a mass range from around 13 to 2500 Msun. Part of the
W3 GMC is subject to an interaction with the HII region and fast stellar winds
generated by the nearby W4 OB association. We find that the fraction of total
gas mass in dense, 850-micron traced structures is significantly altered by
this interaction, being around 5% to 13% in the undisturbed cloud but ~25 - 37%
in the feedback-affected region. The mass distribution in the detected clump
sample depends somewhat on assumptions of dust temperature and is not a simple,
single power law but contains significant structure at intermediate masses.
This structure is likely to be due to crowding of sources near or below the
spatial resolution of the observations. There is little evidence of any
difference between the index of the high-mass end of the clump mass function in
the compressed region and in the unaffected cloud. The consequences of these
results are discussed in terms of current models of triggered star formation.
",2009-06-23,False
The star-forming content of the W3 giant molecular cloud,"The research paper titled ""The star-forming content of the W3 giant molecular cloud"" presents a study of the W3 giant molecular cloud, which is known to be a region of active star formation. The study utilizes data from the Herschel infrared space observatory to examine the properties of the cloud's star-forming regions. The main points of the study include the identification of 89 star-forming regions within the cloud, the determination of their physical properties such as temperature and mass, and the characterization of their star formation activity. The significant findings of the study include the observation of a trend between the star formation rate and the mass of the star-forming regions, as well as the identification of a subset of regions with unusually high star formation activity. The study concludes that the W3 giant molecular cloud is a complex region with a wide range of star-forming environments and that further studies are needed to fully understand the processes driving star formation in this region.",2009-06-23,True
Spectral method for matching exterior and interior elliptic problems,"  A spectral method is described for solving coupled elliptic problems on an
interior and an exterior domain. The method is formulated and tested on the
two-dimensional interior Poisson and exterior Laplace problems, whose solutions
and their normal derivatives are required to be continuous across the
interface. A complete basis of homogeneous solutions for the interior and
exterior regions, corresponding to all possible Dirichlet boundary values at
the interface, are calculated in a preprocessing step. This basis is used to
construct the influence matrix which serves to transform the coupled boundary
conditions into conditions on the interior problem. Chebyshev approximations
are used to represent both the interior solutions and the boundary values. A
standard Chebyshev spectral method is used to calculate the interior solutions.
The exterior harmonic solutions are calculated as the convolution of the
free-space Green's function with a surface density; this surface density is
itself the solution to an integral equation which has an analytic solution when
the boundary values are given as a Chebyshev expansion. Properties of Chebyshev
approximations insure that the basis of exterior harmonic functions represents
the external near-boundary solutions uniformly. The method is tested by
calculating the electrostatic potential resulting from charge distributions in
a rectangle. The resulting influence matrix is well-conditioned and solutions
converge exponentially as the resolution is increased. The generalization of
this approach to three-dimensional problems is discussed, in particular the
magnetohydrodynamic equations in a finite cylindrical domain surrounded by a
vacuum.
",2007-11-22,False
Spectral method for matching exterior and interior elliptic problems,This research paper presents a spectral method for matching exterior and interior elliptic problems. The proposed method uses a combination of boundary integral equations and spectral approximations to solve the exterior and interior problems simultaneously. The method is shown to be accurate and efficient for solving problems with smooth boundaries and homogeneous Dirichlet conditions. The paper also includes numerical experiments that demonstrate the effectiveness of the method in solving various elliptic problems. The results show that the spectral method is highly accurate and can achieve high convergence rates. The paper concludes that the proposed method is a promising approach for solving elliptic problems in both the interior and exterior domains.,2007-11-22,True
Scalar field confinement as a model for accreting systems,"  We investigate the possibility to localize scalar field configurations as a
model for black hole accretion. We analyze and resolve difficulties encountered
when localizing scalar fields in General Relativity. We illustrate this ability
with a simple spherically symmetric model which can be used to study features
of accreting shells around a black hole. This is accomplished by prescribing a
scalar field with a coordinate dependent potential. Numerical solutions to the
Einstein-Klein-Gordon equations are shown, where a scalar filed is indeed
confined within a region surrounding a black hole. The resulting spacetime can
be described in terms of simple harmonic time dependence.
",2008-11-26,False
Scalar field confinement as a model for accreting systems,"This research paper explores the use of scalar field confinement as a model for accreting systems. The central focus of the study is to investigate the behavior of scalar fields in the presence of a black hole and the implications for understanding the accretion process. Through computational simulations, the authors demonstrate that scalar fields can become confined in the vicinity of a black hole, leading to enhanced accretion rates. The study offers important insights into the dynamics of accreting systems and the role of scalar fields in driving the accretion process.",2008-11-26,True
"Blazar Duty-Cycle at gamma-ray Frequecies: Constraints from
  Extragalactic Background Radiation and Prospects for AGILE and GLAST","  We take into account the constraints from the observed extragalactic
gamma-ray background to estimate the maximum duty cycle allowed for a selected
sample of WMAP Blazars, in order to be detectable by AGILE and GLAST gamma-ray
experiments. For the nominal sensitivity values of both instruments, we
identify a subset of sources which can in principle be detectable also in a
steady state without over-predicting the extragalactic background. This work is
based on the results of a recently derived Blazar radio LogN-LogS obtained by
combining several multi-frequency surveys.
",2009-06-23,False
"Blazar Duty-Cycle at gamma-ray Frequecies: Constraints from
  Extragalactic Background Radiation and Prospects for AGILE and GLAST","This research paper explores the duty-cycles of blazars at gamma-ray frequencies, using data from the Extragalactic Background Radiation. The study finds that blazars have a duty-cycle of approximately 10%, with some variability depending on the specific blazar. The paper also discusses the potential for future research using the AGILE and GLAST telescopes to further investigate duty-cycles and other characteristics of blazars. Overall, this research provides important insights into the behavior of blazars and their impact on the extragalactic background radiation.",2009-06-23,True
"SFI++ II: A New I-band Tully-Fisher Catalog, Derivation of Peculiar
  Velocities and Dataset Properties","  We present the SFI++ dataset, a homogeneously derived catalog of photometric
and rotational properties and the Tully-Fisher distances and peculiar
velocities derived from them. We make use of digital optical images, optical
long-slit spectra, and global HI line profiles to extract parameters of
relevance to disk scaling relations, incorporating several previously published
datasets as well as a new photometric sample of some 2000 objects. According to
the completeness of available redshift samples over the sky area, we exploit
both a modified percolation algorithm and the Voronoi-Delaunay method to assign
individual galaxies to groups as well as clusters, thereby reducing scatter
introduced by local orbital motions. We also provide corrections to the
peculiar velocities for both homogeneous and inhomogeneous Malmquist bias,
making use of the 2MASS Redshift Survey density field to approximate large
scale structure. We summarize the sample selection criteria, corrections made
to raw observational parameters, the grouping techniques, and our procedure for
deriving peculiar velocities. The final SFI++ peculiar velocity catalog of 4861
field and cluster galaxies is large enough to permit the study not just of the
global statistics of large scale flows but also of the {\it details} of the
local velocity field.
",2009-06-23,False
"SFI++ II: A New I-band Tully-Fisher Catalog, Derivation of Peculiar
  Velocities and Dataset Properties","This research paper presents the SFI++ II catalog, a new I-band Tully-Fisher catalog, and analyzes the peculiar velocities and dataset properties. The primary focus is on creating a more accurate and comprehensive catalog of Tully-Fisher distances. Noteworthy findings include improved accuracy in distance measurements and the identification of several outliers in the peculiar velocity distribution. The conclusion emphasizes the importance of accurate distance measurements for cosmological studies.",2009-06-23,True
Theory of a Magnetically-Controlled Quantum-Dot Spin Transistor,"  We examine transport through a quantum dot coupled to three ferromagnetic
leads in the regime of weak tunnel coupling. A finite source-drain voltage
generates a nonequilibrium spin on the otherwise non-magnetic quantum dot. This
spin accumulation leads to magnetoresistance. A ferromagnetic but current-free
base electrode influences the quantum-dot spin via incoherent spin-flip
processes and coherent spin precession. As the dot spin determines the
conductance of the device, this allows for a purely magnetic transistor-like
operation. We analyze the effect of both types of processes on the electric
current in different geometries.
",2007-09-28,False
Theory of a Magnetically-Controlled Quantum-Dot Spin Transistor,"This research paper aims to propose a new theory for a magnetically-controlled quantum-dot spin transistor. The proposed theory is based on the manipulation of the spin states of electrons in a quantum dot using an external magnetic field. The transistor is designed to function as a switch, where the spin state of the electron can be controlled using a magnetic field, leading to the enhancement of the device's performance. The paper discusses the theoretical foundations of the proposed transistor, including the use of magnetic fields to manipulate spin states, the properties of quantum dots, and the principles of transistor operation. The study also presents simulations that demonstrate the effectiveness of the proposed transistor design. The research paper concludes with a discussion of the potential applications of the magnetically-controlled quantum-dot spin transistor in the development of advanced electronic devices.",2007-09-28,True
Broadening effects due to alloy scattering in Quantum Cascade Lasers,"  We report on calculations of broadening effects in QCL due to alloy
scattering. The output of numerical calculations of alloy broadened Landau
levels compare favorably with calculations performed at the self-consistent
Born approximation. Results for Landau level width and optical absorption are
presented. A disorder activated forbidden transition becomes significant in the
vicinity of crossings of Landau levels which belong to different subbands. A
study of the time dependent survival probability in the lowest Landau level of
the excited subband is performed. It is shown that at resonance the population
relaxation occurs in a subpicosecond scale.
",2009-11-13,False
Broadening effects due to alloy scattering in Quantum Cascade Lasers,"This research paper investigates the broadening effects in Quantum Cascade Lasers (QCLs) due to alloy scattering. QCLs are crucial for applications such as gas sensing and spectroscopy, but their performance is limited by the broadening of the gain spectrum. The use of alloy scattering has been proposed as a solution to this problem, but the fundamental mechanisms behind this effect are still unclear. In this paper, we explore the impact of alloy scattering on QCLs through theoretical modeling and experimental measurements. Our results provide insight into the mechanisms of alloy scattering and its potential applications in improving the performance of QCLs.",2009-11-13,True
"Nanostructure and velocity of field-driven solid-on-solid interfaces
  moving under a phonon-assisted dynamic","  The nanoscopic structure and the stationary propagation velocity of
(1+1)-dimensional solid-on-solid interfaces in an Ising lattice-gas model,
which are driven far from equilibrium by an applied force, such as a magnetic
field or a difference in (electro)chemical potential, are studied by an
analytic nonlinear-response approximation together with kinetic Monte Carlo
simulations. Here we consider the case that the system is coupled to a
two-dimensional phonon bath. In the resulting dynamic, transitions that
conserve the system energy are forbidden, and the effects of the applied force
and the interaction energies do not factorize (a so-called hard dynamic). In
full agreement with previous general theoretical results we find that the local
interface width changes dramatically with the applied force. However, in
contrast with other hard dynamics, this change is nonmonotonic in the driving
force. However, significant differences between theory and simulation are found
near two special values of the driving force, where certain transitions allowed
by the solid-on-solid model become forbidden by the phonon-assisted dynamic.
Our results represent a significant step toward providing a solid physical
foundation for kinetic Monte Carlo simulations.
",2007-07-24,False
"Nanostructure and velocity of field-driven solid-on-solid interfaces
  moving under a phonon-assisted dynamic","This research paper investigates the nanostructure and velocity of field-driven solid-on-solid interfaces moving under a phonon-assisted dynamic. The study aims to understand the fundamental mechanisms that govern the behavior of these interfaces and their response to external stimuli. By using molecular dynamics simulations, we explore the effects of different parameters such as temperature, interface roughness, and driving force on the interface velocity and nanostructure. Our results indicate that the phonon-assisted dynamic plays a crucial role in determining the interface behavior, and temperature has a significant influence on the velocity of the interface. Additionally, we observe that the nanostructure of the interface evolves dynamically under the influence of the driving force. These findings provide insights into the fundamental mechanisms that govern the behavior of field-driven solid-on-solid interfaces and have implications for the design of nanomachines and devices.",2007-07-24,True
Hamiltonian Unification of General Relativity and Standard Model,"  The Hamiltonian approach to the General Relativity and the Standard Model is
studied in the context of its consistency with the Newton law, the Higgs
effect, the Hubble cosmological evolution and the Cosmic Microwave Background
radiation physics.
  The version of the Higgs potential is proposed, where its constant parameter
is replaced by the dynamic zeroth Fourier harmonic of the very Higgs field. In
this model, the extremum of the Coleman--Weinberg effective potential obtained
from the unit vacuum--vacuum transition amplitude immediately predicts mass of
Higgs field and removes tremendous vacuum cosmological density.
  We show that the relativity principles unambiguously treat the Planck epoch,
in the General Relativity, as the present-day one. It was shown that there are
initial data of the Electro-Weak epoch compatible with supposition that all
particles in the Universe are final products of decays of primordial Higgs
particles and W-, Z-vector bosons created from vacuum at the instant treated as
the ""Big-Bang"".
",2014-11-18,False
Hamiltonian Unification of General Relativity and Standard Model,"This research paper proposes a unification of General Relativity and the Standard Model of particle physics by introducing a Hamiltonian formulation. The main objective was to provide a framework for a consistent and unified theory that describes all fundamental interactions of nature. The approach involved describing the dynamics of both gravity and matter in terms of a canonical Hamiltonian that incorporates the principles of General Relativity and quantum field theory. The key results of this study showed that the Hamiltonian formulation provides a new perspective on the interplay between gravity and matter, yielding a unified and coherent picture of the fundamental forces of nature. Furthermore, the study showed that the Hamiltonian unification framework can be used to explore new and exciting phenomena, such as the unification of gravity and the Higgs boson, and the possible existence of dark matter and dark energy. These findings provide a promising direction for future research in the field of theoretical physics and offer new insights into the fundamental nature of the universe.",2014-11-18,True
SQUID-based instrumentation for ultra-low-field MRI,"  Magnetic resonance imaging at ultra-low fields (ULF MRI) is a promising new
imaging method that uses SQUID sensors to measure the spatially encoded
precession of pre-polarized nuclear spin populations at a microtesla-range
measurement field. In this work, a seven-channel SQUID system designed for
simultaneous 3D ULF MRI and magnetoencephalography (MEG) is described. The
system includes seven second-order SQUID gradiometers, characterized by
magnetic field resolutions of 1.2 - 2.8 fT/rtHz. It is also equipped with five
sets of coils for 3D Fourier imaging with pre-polarization. Essential technical
details of the design are discussed. The system's ULF MRI performance is
demonstrated by multi-channel 3D images of a preserved sheep brain acquired at
46 microtesla measurement field with pre-polarization at 40 mT. The imaging
resolution is 2.5 mm x 2.5 mm x 5 mm. The ULF MRI images are compared to images
of the same brain acquired using conventional high-field MRI. Different ways to
improve imaging SNR are discussed.
",2007-10-18,False
SQUID-based instrumentation for ultra-low-field MRI,"This research paper focuses on the development of SQUID-based instrumentation for ultra-low-field MRI, which has the potential to revolutionize medical imaging with its ability to produce high-resolution images with reduced risk and cost. The results of the study demonstrate the feasibility of using SQUID-based sensors for ultra-low-field MRI and provide insights into the benefits and limitations of this technology. The conclusion drawn from this research is that SQUID-based instrumentation has great potential for future medical imaging applications.",2007-10-18,True
"Lagrangian subcategories and braided tensor equivalences of twisted
  quantum doubles of finite groups","  We classify Lagrangian subcategories of the representation category of a
twisted quantum double of a finite group. In view of results of 0704.0195v2
this gives a complete description of all braided tensor equivalent pairs of
twisted quantum doubles of finite groups. We also establish a canonical
bijection between Lagrangian subcategories of the representation category of a
twisted quantum double of a finite group G and module categories over the
category of twisted G-graded vector spaces such that the dual tensor category
is pointed. This can be viewed as a quantum version of V. Drinfeld's
characterization of homogeneous spaces of a Poisson-Lie group in terms of
Lagrangian subalgebras of the double of its Lie bialgebra. As a consequence, we
obtain that two group-theoretical fusion categories are weakly Morita
equivalent if and only if their centers are equivalent as braided tensor
categories.
",2009-11-13,False
"Lagrangian subcategories and braided tensor equivalences of twisted
  quantum doubles of finite groups","This research paper investigates the relationship between Lagrangian subcategories and braided tensor equivalences of twisted quantum doubles of finite groups. We demonstrate that Lagrangian subcategories are preserved under braided tensor equivalences, and we provide examples of twisted quantum doubles that are braided tensor equivalent but not Morita equivalent. Our findings suggest that Lagrangian subcategories can be used as a tool to distinguish between certain twisted quantum doubles.",2009-11-13,True
Validating module network learning algorithms using simulated data,"  In recent years, several authors have used probabilistic graphical models to
learn expression modules and their regulatory programs from gene expression
data. Here, we demonstrate the use of the synthetic data generator SynTReN for
the purpose of testing and comparing module network learning algorithms. We
introduce a software package for learning module networks, called LeMoNe, which
incorporates a novel strategy for learning regulatory programs. Novelties
include the use of a bottom-up Bayesian hierarchical clustering to construct
the regulatory programs, and the use of a conditional entropy measure to assign
regulators to the regulation program nodes. Using SynTReN data, we test the
performance of LeMoNe in a completely controlled situation and assess the
effect of the methodological changes we made with respect to an existing
software package, namely Genomica. Additionally, we assess the effect of
various parameters, such as the size of the data set and the amount of noise,
on the inference performance. Overall, application of Genomica and LeMoNe to
simulated data sets gave comparable results. However, LeMoNe offers some
advantages, one of them being that the learning process is considerably faster
for larger data sets. Additionally, we show that the location of the regulators
in the LeMoNe regulation programs and their conditional entropy may be used to
prioritize regulators for functional validation, and that the combination of
the bottom-up clustering strategy with the conditional entropy-based assignment
of regulators improves the handling of missing or hidden regulators.
",2007-11-15,False
Validating module network learning algorithms using simulated data,"The research paper titled ""Validating module network learning algorithms using simulated data"" evaluates the effectiveness of module network learning algorithms using simulated data. The main subject of the paper is the validation of module network learning algorithms, which are widely used in systems biology to identify functional modules or groups of genes that work together to perform specific biological functions. The authors generated simulated data sets with varying levels of noise to test the accuracy and robustness of four different module network learning algorithms. 

The key findings of the paper suggest that all four algorithms are effective in identifying functional modules, but their performance varies depending on the noise level of the data. Specifically, the authors found that the algorithms perform better with low noise levels and that the accuracy decreases as the noise level increases. Moreover, the authors found that some algorithms are more robust to noise than others, suggesting that researchers should carefully consider the choice of algorithm depending on the characteristics of the data. Overall, the paper provides important insights into the validation of module network learning algorithms and highlights the importance of using simulated data to evaluate their effectiveness.",2007-11-15,True
Towards a new concept of photomultiplier based on silicon technology,"  In order to build a new concept of photomultiplier based on silicon
technology, design and characterization of 5x5 arrays of a new generation of
single photon avalanche diodes (SPAD) manufactured by ST-Microelectronics have
been performed. Single photons sensitivity, dark noise and timing resolution of
the SPAD- STM devices in several experimental conditions have been evaluated.
Moreover, the effects arising from the multiple integration of many elements
and the study of their common read-out have been deeply investigated.
",2007-05-23,False
Towards a new concept of photomultiplier based on silicon technology,"This research paper aims to explore the feasibility of developing a new concept of photomultiplier based on silicon technology. The current photomultiplier tubes are bulky, expensive, and limited in their performance. Silicon technology offers several advantages, including miniaturization, low cost, and high sensitivity. The paper discusses the design, fabrication, and characterization of the proposed photomultiplier based on silicon technology. The experimental results indicate that the new concept has the potential to outperform the existing photomultiplier tubes in terms of sensitivity, response time, and cost-effectiveness. The paper concludes with a discussion of the implications and future directions of this research for the development of advanced photodetectors.",2007-05-23,True
Updating the Phase Diagram of the Gross-Neveu Model in 2+1 Dimensions,"  The method of optimized perturbation theory (OPT) is used to study the phase
diagram of the massless Gross-Neveu model in 2+1 dimensions. In the temperature
and chemical potential plane, our results give strong support to the existence
of a tricritical point and line of first order phase transition, previously
only suspected to exist from extensive lattice Monte Carlo simulations. In
addition of presenting these results we discuss how the OPT can be implemented
in conjunction with the Landau expansion in order to determine all the relevant
critical quantities.
",2008-11-26,False
Updating the Phase Diagram of the Gross-Neveu Model in 2+1 Dimensions,"This research paper updates the phase diagram of the Gross-Neveu model in 2+1 dimensions by employing the numerical simulation method of the lattice field theory. The Gross-Neveu model is a well-known quantum field theory that describes the dynamics of interacting fermions in 2+1 dimensions. The phase diagram of this model is of great interest in condensed matter physics and high-energy physics. In this study, we investigate the phase diagram of the Gross-Neveu model by taking into account the effect of finite temperature and density. Our results show that the phase diagram of the Gross-Neveu model in 2+1 dimensions is similar to that in 1+1 dimensions, but with some subtle differences. We find that the phase transition between the chiral symmetry breaking phase and the symmetric phase is of second order, while the transition between the symmetric phase and the massive phase is of first order. Our findings provide important insights into the behavior of interacting fermions in 2+1 dimensions and may have implications for the study of condensed matter systems and high-energy physics.",2008-11-26,True
A new spinfoam vertex for quantum gravity,"  We introduce a new spinfoam vertex to be used in models of 4d quantum gravity
based on SU(2) and SO(4) BF theory plus constraints. It can be seen as the
conventional vertex of SU(2) BF theory, the 15j symbol, in a particular basis
constructed using SU(2) coherent states. This basis makes the geometric
interpretation of the variables transparent: they are the vectors normal to the
triangles within each tetrahedron. We study the condition under which these
states can be considered semiclassical, and we show that the semiclassical ones
dominate the evaluation of quantum correlations. Finally, we describe how the
constraints reducing BF to gravity can be directly written in terms of the new
variables, and how the semiclassicality of the states might improve
understanding the correct way to implement the constraints.
",2008-11-26,False
A new spinfoam vertex for quantum gravity,"The research paper ""A new spinfoam vertex for quantum gravity"" proposes a new way to compute the amplitudes of quantum gravitational interactions using a spinfoam formalism. The paper introduces a new type of vertex that is based on the geometry of the underlying space-time and incorporates the concept of causal cones. The proposed vertex is shown to have better convergence properties and to be able to produce more accurate results compared to previous approaches. The paper concludes that this new spinfoam vertex has the potential to significantly advance our understanding of quantum gravity and its role in the fundamental structure of the universe.",2008-11-26,True
"Small scale aspects of flows in proximity of the turbulent/non-turbulent
  interface","  The work reported below is a first of its kind study of the properties of
turbulent flow without strong mean shear in a Newtonian fluid in proximity of
the turbulent/non-turbulent interface, with emphasis on the small scale
aspects. The main tools used are a three-dimensional particle tracking system
(3D-PTV) allowing to measure and follow in a Lagrangian manner the field of
velocity derivatives and direct numerical simulations (DNS). The comparison of
flow properties in the turbulent (A), intermediate (B) and non-turbulent (C)
regions in the proximity of the interface allows for direct observation of the
key physical processes underlying the entrainment phenomenon. The differences
between small scale strain and enstrophy are striking and point to the definite
scenario of turbulent entrainment via the viscous forces originating in strain.
",2009-11-13,False
"Small scale aspects of flows in proximity of the turbulent/non-turbulent
  interface","This research paper focuses on the small-scale aspects of flows in the proximity of the turbulent/non-turbulent interface. The study aims to understand the characteristics of the interface and its impact on the surrounding flow. The research was conducted through high-resolution numerical simulations and experimental measurements. The results show that the interface has a significant influence on the local flow structures, including the formation of vortices and the development of turbulence. The study also highlights the importance of the interface in determining the mixing efficiency in turbulent flows. Overall, the findings of this research contribute to the fundamental understanding of turbulent flows and have implications for practical applications in fields such as fluid dynamics and engineering design.",2009-11-13,True
"Emergence of Tricritical Point and Liquid-Gas Phase in the Massless 2+1
  Dimensional Gross-Neveu Model","  A complete thermodynamical analysis of the 2+1 dimensional massless
Gross-Neveu model is performed using the optimized perturbation theory. This is
a non-perturbative method that allows us to go beyond the known large-N results
already at lowest order. Our results, for a finite number of fermion species,
N, show the existence of a tricritical point in the temperature and chemical
potential phase diagram for discrete chiral phase transition allowing us to
precisely to locate it. By studying the phase diagram in the pressure and
inverse density plane, we also show the existence of a liquid-gas phase, which,
so far, was unknown to exist in this model. Finally, we also derive N dependent
analytical expressions for the fermionic mass, critical temperature and
critical chemical potential.
",2008-11-26,False
"Emergence of Tricritical Point and Liquid-Gas Phase in the Massless 2+1
  Dimensional Gross-Neveu Model",The research paper investigates the emergence of tricritical point and liquid-gas phase in the massless 2+1 dimensional Gross-Neveu model. The study employs Monte Carlo simulations to analyze the model's phase structure and critical behavior. The results reveal the existence of a tricritical point and a liquid-gas phase in the model. The findings provide insights into the universality class of the model and its relevance to condensed matter physics.,2008-11-26,True
On the near-equality case of the Positive Mass Theorem,"  The Positive Mass Conjecture states that any complete asymptotically flat
manifold of nonnnegative scalar curvature has nonnegative mass. Moreover, the
equality case of the Positive Mass Conjecture states that in the above
situation, if the mass is zero, then the Riemannian manifold must be Euclidean
space. The Positive Mass Conjecture was proved by R. Schoen and S.-T. Yau for
all manifolds of dimension less than 8, and it was proved by E. Witten for all
spin manifolds. In this paper, we consider complete asymptotically flat
manifolds of nonnegative scalar curvature that are also harmonically flat in an
end. We show that, whenever the Positive Mass Theorem holds, any appropriately
normalized sequence of such manifolds whose masses converge to zero must have
metrics that are uniformly converging to Euclidean metrics outside a compact
region. This result is an ingredient in a forthcoming proof, co-authored with
H. Bray, of the Riemannian Penrose inequality in dimensions less than 8.
",2007-05-23,False
On the near-equality case of the Positive Mass Theorem,"The Positive Mass Theorem is a fundamental result in general relativity that relates the mass of an asymptotically flat spacetime to its geometry. In this research paper, we focus on the near-equality case of the theorem, where the mass is almost zero but not quite. We establish new criteria for the near-equality case and show that they are satisfied in certain important examples, such as the Schwarzschild spacetime. Our findings suggest that the near-equality case is not a pathological regime of the theorem and should be taken seriously as a physical situation. We conclude that the Positive Mass Theorem remains a powerful tool for understanding the geometry and physics of spacetimes in general relativity.",2007-05-23,True
Bimodality in spectator fragmentation,"  The fluctuations of the largest fragment charge of a partition and of the
charge asymmetries of the two or three largest fragments in spectator decays
following 197Au + 197Au collisions at 1000 MeV per nucleon are investigated.
The observed bimodal distributions at specific values of the sorting variable
Z_bound exhibit features known from percolation theory where they appear as
finite-size effects. The underlying configurational fluctuations seem generic
for fragmentation processes in small systems.
",2007-05-23,False
Bimodality in spectator fragmentation,"The research paper titled ""Bimodality in spectator fragmentation"" investigates the phenomenon of bimodal fragmentation in high-energy particle collisions. The study focuses on the primary theme of identifying the sources and characteristics of this phenomenon and its impact on particle physics research. Through extensive simulations and data analysis, the researchers found that bimodality in spectator fragmentation is a robust and common feature of high-energy collisions. The study also highlights the potential of bimodality as a tool for probing the properties of the quark-gluon plasma. The findings of this study provide valuable insights into the complex dynamics of high-energy particle collisions and have important implications for ongoing research in particle physics.",2007-05-23,True
"Production of light particles by very strong and slowly varying magnetic
  fields","  The possibility that around some astrophysical objects there are non-static
magnetic fields of enormous intensity suggests that in these situations real
particles may be produced. The slowness of the variation is compensated by the
huge intensity. The main issue is the production of e+,e- pairs annihilating
into photons and the direct production of photons, as one of the concurrent
process in the GRB (gamma ray bursts). Then some simple effects due to the
presence of the intense gravity are studied and finally a look is given to the
production of other kinds of particles.
",2008-11-26,False
"Production of light particles by very strong and slowly varying magnetic
  fields","The article focuses on the production of light particles, specifically photons, by strong and slowly varying magnetic fields. The study involves the use of a theoretical model to analyze the behavior of photons in such magnetic fields, with the aim of understanding the mechanisms that lead to their production. The main conclusion of the study is that strong and slowly varying magnetic fields can indeed produce photons, and that this process may have applications in areas such as astrophysics and plasma physics. The study also highlights the importance of further research in this area to fully understand the underlying mechanisms and potential applications.",2008-11-26,True
"Entanglement in a Jaynes-Cummings Model with Two Atoms and Two Photon
  Modes","  We investigate the conditions of entanglement for a system of two atoms and
two photon modes in vacuum, using the Jaynes-Cummings model in the
rotating-wave approximation. It is found, by generalizing the existing results,
that the strength of entanglement is a periodic function of time. We explicitly
show that our results are in agreement with the existing results of
entanglement conditions under appropriate limits. Results for the two-atom and
two-photon system are generalized to the case of arbitrary values for the
atomic energies, corresponding to photon modes frequencies. Though it is
apparently a generalization of the existing work, we have considered for the
first time both the resonant and nonresonant conditions and found a general
equation which could be true for both cases. Moreover, we show that periodicity
of the entanglement is a distinct feature of resonant system. Considering the
two atoms and two photons system, in detail, we setup an approach which could
be generalized for many particle systems and the resulting master equation can
also be analyzed.
",2016-06-27,False
"Entanglement in a Jaynes-Cummings Model with Two Atoms and Two Photon
  Modes","This research paper investigates the entanglement dynamics of a system consisting of two atoms and two photon modes in a Jaynes-Cummings model. We analyze the time evolution of the entanglement of the atoms and photons using the concurrence and entropy measures. Different initial states of the system are considered, and the entanglement behavior is studied under various system parameters such as coupling strength and detuning. Our results show that the entanglement dynamics are highly dependent on the initial state and system parameters. We also observe that the entanglement between the atoms and photons can be sustained for longer periods of time under certain conditions. These findings have implications for quantum information processing and quantum communication using two-qubit and two-mode systems.",2016-06-27,True
Analytic models of plausible gravitational lens potentials,"  Gravitational lenses on galaxy scales are plausibly modelled as having
ellipsoidal symmetry and a universal dark matter density profile, with a Sersic
profile to describe the distribution of baryonic matter. Predicting all lensing
effects requires knowledge of the total lens potential: in this work we give
analytic forms for that of the above hybrid model. Emphasising that complex
lens potentials can be constructed from simpler components in linear
combination, we provide a recipe for attaining elliptical symmetry in either
projected mass or lens potential. We also provide analytic formulae for the
lens potentials of Sersic profiles for integer and half-integer index. We then
present formulae describing the gravitational lensing effects due to
smoothly-truncated universal density profiles in cold dark matter model. For
our isolated haloes the density profile falls off as radius to the minus fifth
or seventh power beyond the tidal radius, functional forms that allow all
orders of lens potential derivatives to be calculated analytically, while
ensuring a non-divergent total mass. We show how the observables predicted by
this profile differ from that of the original infinite-mass NFW profile.
Expressions for the gravitational flexion are highlighted. We show how
decreasing the tidal radius allows stripped haloes to be modelled, providing a
framework for a fuller investigation of dark matter substructure in galaxies
and clusters. Finally we remark on the need for finite mass halo profiles when
doing cosmological ray-tracing simulations, and the need for readily-calculable
higher order derivatives of the lens potential when studying catastrophes in
strong lenses.
",2009-11-13,False
Analytic models of plausible gravitational lens potentials,"This research paper aims to develop analytic models of plausible gravitational lens potentials, which are important in understanding the properties of gravitational lenses and their impact on observations. The study focuses on creating models that can accurately represent the gravitational potential of lensing galaxies and clusters, allowing for better predictions of lensing effects. The authors use a combination of numerical simulations and theoretical models to construct these potential models. The key findings of the study include the identification of several new potential models that accurately reproduce the observed properties of lensing galaxies and clusters. The authors also demonstrate the importance of considering the impact of substructures within lensing systems on the overall gravitational potential. The study concludes that these analytic models can provide valuable insights into the complex nature of gravitational lensing and can be used to inform future observations and analyses.",2009-11-13,True
Elucidation of Conformational Hysteresis on a Giant DNA,"  The conformational behavior of a giant DNA mediated by condensing agents in
the bulk solution has been investigated through experimental and theoretical
approaches. Experimentally, a pronounced conformational hysteresis is observed
for folding and unfolding processes, by increasing and decreasing the
concentration of condensing agent PEG (Polyethylene glycol), respectively. To
elucidate the observed hysteresis, a semiflexible chain model is studied by
using Monte Carlo simulations for the coil-globule transition. In the
simulations, the hysteresis loop emerges for stiff enough chains, indicating
distinct pathways for folding and unfolding processes. Also, our results show
that globular state is thermodynamically more stable than coiled state in the
hysteresis loop. Our findings suggest that increasing chain stiffness may
reduce the chain conformations relevant to the folding pathway, which impedes
the folding process.
",2009-11-13,False
Elucidation of Conformational Hysteresis on a Giant DNA,"This research paper focuses on the study of conformational hysteresis on a giant DNA molecule. The authors used single-molecule fluorescence microscopy techniques to investigate the changes in the DNA molecule's conformation as it was stretched and relaxed. The study revealed that the DNA molecule exhibits hysteresis in its conformational changes, meaning that its response to mechanical stress is dependent on its previous mechanical history. The authors suggest that this phenomenon could have implications for the behavior of DNA in living cells and could potentially be used in the development of new DNA-based materials.",2009-11-13,True
"PSR J1453+1902 and the radio luminosities of solitary versus binary
  millisecond pulsars","  We present 3 yr of timing observations for PSR J1453+1902, a 5.79-ms pulsar
discovered during a 430-MHz drift-scan survey with the Arecibo telescope. Our
observations show that PSR J1453+1902 is solitary and has a proper motion of
8(2) mas/yr. At the nominal distance of 1.2 kpc estimated from the pulsar's
dispersion measure, this corresponds to a transverse speed of 46(11) km/s,
typical of the millisecond pulsar population. We analyse the current sample of
55 millisecond pulsars in the Galactic disk and revisit the question of whether
the luminosities of isolated millisecond pulsars are different from their
binary counterparts. We demonstrate that the apparent differences in the
luminosity distributions seen in samples selected from 430-MHz surveys can be
explained by small-number statistics and observational selection biases. An
examination of the sample from 1400-MHz surveys shows no differences in the
distributions. The simplest conclusion from the current data is that the spin,
kinematic, spatial and luminosity distributions of isolated and binary
millisecond pulsars are consistent with a single homogeneous population.
",2009-06-23,False
"PSR J1453+1902 and the radio luminosities of solitary versus binary
  millisecond pulsars","This research paper focuses on the comparison of the radio luminosities of solitary and binary millisecond pulsars, with a specific focus on PSR J1453+1902. The study found that binary pulsars have higher radio luminosities than solitary pulsars, which may be attributed to the interaction between the pulsar and its companion star. Additionally, the analysis of PSR J1453+1902 revealed that it has a relatively low radio luminosity compared to other binary pulsars, suggesting that it may have a unique evolutionary history. Overall, the study sheds light on the relationship between pulsar evolution and radio luminosity, and provides insights into the properties of PSR J1453+1902.",2009-06-23,True
Results of the IGEC-2 search for gravitational wave bursts during 2005,"  The network of resonant bar detectors of gravitational waves resumed
coordinated observations within the International Gravitational Event
Collaboration (IGEC-2). Four detectors are taking part in this collaboration:
ALLEGRO, AURIGA, EXPLORER and NAUTILUS. We present here the results of the
search for gravitational wave bursts over 6 months during 2005, when IGEC-2 was
the only gravitational wave observatory in operation. The network data analysis
implemented is based on a time coincidence search among AURIGA, EXPLORER and
NAUTILUS, keeping the data from ALLEGRO for follow-up studies. With respect to
the previous IGEC 1997-2000 observations, the amplitude sensitivity of the
detectors to bursts improved by a factor about 3 and the sensitivity bandwidths
are wider, so that the data analysis was tuned considering a larger class of
detectable waveforms. Thanks to the higher duty cycles of the single detectors,
we decided to focus the analysis on three-fold observation, so to ensure the
identification of any single candidate of gravitational waves (gw) with high
statistical confidence. The achieved false detection rate is as low as 1 per
century. No candidates were found.
",2008-11-26,False
Results of the IGEC-2 search for gravitational wave bursts during 2005,"The research paper titled ""Results of the IGEC-2 search for gravitational wave bursts during 2005"" aimed to search for gravitational wave bursts using data collected by the International Gravitational Event Collaboration (IGEC) during the year 2005. The collaboration used five detectors, located in different parts of the world, to search for gravitational waves.

The main objective of the study was to detect gravitational waves from astrophysical sources such as supernovae, binary mergers, and pulsars. The researchers used a data analysis method called the Coherent WaveBurst (CWB) algorithm to search for gravitational wave bursts.

The study found no significant gravitational wave signals during the observation period. However, the researchers were able to set upper limits on the amplitude of gravitational wave bursts from astrophysical sources. These limits provided important constraints on theoretical models of these sources and helped to improve the sensitivity of future gravitational wave detectors.

In conclusion, the study demonstrated the capability of the CWB algorithm to search for gravitational wave bursts and provided important constraints on the properties of astrophysical sources of gravitational waves. The results of the study have contributed to the ongoing efforts to detect and study gravitational waves, which have the potential to revolutionize our understanding of the universe.",2008-11-26,True
Dynamic Properties of Molecular Motors in Burnt-Bridge Models,"  Dynamic properties of molecular motors that fuel their motion by actively
interacting with underlying molecular tracks are studied theoretically via
discrete-state stochastic ``burnt-bridge'' models. The transport of the
particles is viewed as an effective diffusion along one-dimensional lattices
with periodically distributed weak links. When an unbiased random walker passes
the weak link it can be destroyed (``burned'') with probability p, providing a
bias in the motion of the molecular motor. A new theoretical approach that
allows one to calculate exactly all dynamic properties of motor proteins, such
as velocity and dispersion, at general conditions is presented. It is found
that dispersion is a decreasing function of the concentration of bridges, while
the dependence of dispersion on the burning probability is more complex. Our
calculations also show a gap in dispersion for very low concentrations of weak
links which indicates a dynamic phase transition between unbiased and biased
diffusion regimes. Theoretical findings are supported by Monte Carlo computer
simulations.
",2009-11-13,False
Dynamic Properties of Molecular Motors in Burnt-Bridge Models,This research paper explores the dynamic properties of molecular motors in burnt-bridge models. The primary focus is on the effect of thermal fluctuations on the motors' performance and efficiency. The study employs computer simulations to investigate the behavior of the motors in different scenarios. The findings suggest that thermal fluctuations can significantly impact the motors' efficiency and performance. The study concludes that understanding the dynamic properties of molecular motors is crucial for designing more efficient and effective nanoscale machines.,2009-11-13,True
Learning to Bluff,"  The act of bluffing confounds game designers to this day. The very nature of
bluffing is even open for debate, adding further complication to the process of
creating intelligent virtual players that can bluff, and hence play,
realistically. Through the use of intelligent, learning agents, and carefully
designed agent outlooks, an agent can in fact learn to predict its opponents
reactions based not only on its own cards, but on the actions of those around
it. With this wider scope of understanding, an agent can in learn to bluff its
opponents, with the action representing not an illogical action, as bluffing is
often viewed, but rather as an act of maximising returns through an effective
statistical optimisation. By using a tee dee lambda learning algorithm to
continuously adapt neural network agent intelligence, agents have been shown to
be able to learn to bluff without outside prompting, and even to learn to call
each others bluffs in free, competitive play.
",2007-05-23,False
Learning to Bluff,"The ability to bluff is a crucial aspect of human social interaction, and yet little is known about how individuals learn to bluff effectively. This research paper investigates the process of learning to bluff by conducting a series of experiments using a computer game that simulates a strategic bluffing scenario. Participants were given the opportunity to learn and improve their bluffing skills over multiple rounds of play. Results indicate that individuals can learn to bluff more effectively over time and that this skill can be improved through feedback and practice. This research has important implications for understanding social cognition and improving interpersonal communication skills. By better understanding the process of learning to bluff, individuals may be able to improve their ability to navigate complex social situations and improve their overall social competence.",2007-05-23,True
"Quasiparticle Poisoning and Quantum Coherence in a Differential Charge
  Qubit","  We demonstrate the operation of a differential single Cooper-pair box, a
charge qubit consisting of two aluminum islands, isolated from ground, coupled
by a pair of small-area Josephson junctions, and read out with a
superconducting differential radio-frequency single electron transistor. We
have tested four devices, all of which show evidence of quasiparticle
poisoning. The devices are characterized with microwave spectroscopy and
temperature dependence studies, and Coulomb staircases are shown to be
e-periodic in all samples. However, coherent control is still possible with
non-adiabatic voltage pulses. Coherent oscillation experiments and a relaxation
time measurement were performed using a charge derivative readout technique.
",2007-05-23,False
"Quasiparticle Poisoning and Quantum Coherence in a Differential Charge
  Qubit","This research paper investigates the effects of quasiparticle poisoning on quantum coherence in a differential charge qubit. By analyzing the behavior of the qubit under various conditions, we observe that quasiparticle poisoning can significantly degrade the coherence of the system. Our results show that the coherence time of the qubit decreases exponentially with increasing quasiparticle density. Furthermore, we find that the impact of quasiparticle poisoning is more severe in the case of the differential charge qubit compared to the standard charge qubit. This study provides valuable insights into the sources of decoherence in quantum systems and highlights the importance of understanding and mitigating the effects of quasiparticle poisoning in the design of quantum devices.",2007-05-23,True
"A Documentary of High-Mass Star Formation: Probing the Dynamical
  Evolution of Orion Source I on 10-100 AU Scales using SiO Masers","  A comprehensive picture of high-mass star formation has remained elusive, in
part because examples of high-mass YSOs tend to be relatively distant, deeply
embedded, and confused with other emission sources. These factors have impeded
dynamical investigations within tens of AU of high-mass YSOs--scales that are
critical for probing the interfaces where outflows from accretion disks are
launched and collimated. Using observations of SiO masers obtained with the VLA
and the VLBA, the KaLYPSO project is overcoming these limitations by mapping
the structure and dynamical/temporal evolution of the material 10-1000 AU from
the nearest high-mass YSO: Radio Source I in the Orion BN/KL region. Our data
include ~40 epochs of VLBA observations over a several-year period, allowing us
to track the proper motions of individual SiO maser spots and to monitor
changes in the physical conditions of the emitting material with time.
Ultimately these data will provide 3-D maps of the outflow structure over
approximately 30% of the outflow crossing time. Here we summarize recent
results from the KaLYPSO project, including evidence that high-mass star
formation is occurring via disk-mediated accretion.
",2009-11-13,False
"A Documentary of High-Mass Star Formation: Probing the Dynamical
  Evolution of Orion Source I on 10-100 AU Scales using SiO Masers",This research paper focuses on the high-mass star formation process and the dynamical evolution of Orion Source I on 10-100 AU scales using SiO masers. The researchers utilized the Atacama Large Millimeter/submillimeter Array (ALMA) to obtain high-resolution images of the SiO masers and analyzed the data to understand the physical properties of the masers and their location relative to the central protostar. The results of the study reveal that the SiO masers trace the outflowing gas and the rotation of the circumstellar disk around the protostar. The findings provide critical insights into the early stages of high-mass star formation and the role of SiO masers in probing the dynamical evolution of protostellar systems.,2009-11-13,True
Inflated Beta Distributions,"  This paper considers the issue of modeling fractional data observed in the
interval [0,1), (0,1] or [0,1]. Mixed continuous-discrete distributions are
proposed. The beta distribution is used to describe the continuous component of
the model since its density can have quite diferent shapes depending on the
values of the two parameters that index the distribution. Properties of the
proposed distributions are examined. Also, maximum likelihood and method of
moments estimation is discussed. Finally, practical applications that employ
real data are presented.
",2008-03-19,False
Inflated Beta Distributions,"This research paper explores the concept of inflated beta distributions, which are probability distributions that have an excess of observations at either end of the distribution. The main focus of the study is to provide a comprehensive overview of inflated beta distributions and their properties, including moments, skewness, and kurtosis. The paper also examines the application of inflated beta distributions in modeling empirical data, such as financial returns and the likelihood of extreme events. The crucial finding of this study is that inflated beta distributions are useful for modeling data with heavy tails and provide a better fit than traditional beta distributions. The conclusion of the paper is that inflated beta distributions offer a flexible and powerful tool for modeling complex data and should be considered by researchers and practitioners in various fields.",2008-03-19,True
An X-ray Imaging Study of the Stellar Population in RCW49,"  We present the results of a high-resolution X-ray imaging study of the
stellar population in the Galactic massive star-forming region RCW49 and its
central OB association Westerlund 2. We obtained a 40 ks X-ray image of a
17'x17' field using the Chandra X-ray Observatory and deep NIR images using the
Infrared Survey Facility in a concentric 8'3x8'3 region. We detected 468 X-ray
sources and identified optical, NIR, and Spitzer Space Telescope MIR
counterparts for 379 of them. The unprecedented spatial resolution and
sensitivity of the X-ray image, enhanced by optical and infrared imaging data,
yielded the following results: (1) The central OB association Westerlund 2 is
resolved for the first time in the X-ray band. X-ray emission is detected from
all spectroscopically-identified early-type stars in this region. (2) Most
(86%) X-ray sources with optical or infrared identifications are cluster
members in comparison with a control field in the Galactic Plane. (3) A loose
constraint (2--5 kpc) for the distance to RCW49 is derived from the mean X-ray
luminosity of T Tauri stars. (4) The cluster X-ray population consists of
low-mass pre--main-sequence and early-type stars as obtained from X-ray and NIR
photometry. About 30 new OB star candidates are identified. (5) We estimate a
cluster radius of 6'--7' based on the X-ray surface number density profiles.
(6) A large fraction (90%) of cluster members are identified individually using
complimentary X-ray and MIR excess emission. (7) The brightest five X-ray
sources, two Wolf-Rayet stars and three O stars, have hard thermal spectra.
",2019-08-19,False
An X-ray Imaging Study of the Stellar Population in RCW49,"This research paper presents the results of an X-ray imaging study of the stellar population in RCW49, an active star-forming region in the Milky Way galaxy. Using data from the Chandra X-ray Observatory, we identified a total of 362 X-ray sources within the region, including a number of young, high-mass stars. Our analysis of the X-ray properties of these sources allowed us to estimate their ages, masses, and other physical characteristics. We also compared our results to previous studies of RCW49 and found that our sample of X-ray sources provides a more complete picture of the stellar population in the region. Overall, our study contributes to our understanding of the processes involved in star formation and the evolution of young, massive stars.",2019-08-19,True
On Certain Quantization Aspects of (Generalized) Toda Systems,"  Ordinary and gl(n,R) generalized Toda systems as well as a related hierarchy
are probed with respect to certain quantization characteristics. ""Quantum""
canonical and Poisson transformations are used to study quantizations of
transformed Toda systems. With a Lax pair setting, a hierarchy of related
systems are shown and their quantizations discussed. Finally, comments are
added about quantum aspects of gl(n,R) generalized Toda systems with the
approaches of deformation quantization or quantum groups in mind.
",2007-05-23,False
On Certain Quantization Aspects of (Generalized) Toda Systems,"The research paper titled ""On Certain Quantization Aspects of (Generalized) Toda Systems"" explores the quantum aspects of Toda systems and their generalizations. The primary theme of the paper is to investigate the quantization of Toda systems and the relationship between classical and quantum integrability. The indispensable findings of the research are the discovery of new quantum integrable structures related to Toda systems, the quantization of Toda lattices, and the identification of quantum Toda systems as natural quantum deformations of classical Toda systems. The paper concludes that the study of quantization aspects of Toda systems could provide new insights into the fundamental principles of quantum mechanics and their relationship to classical mechanics.",2007-05-23,True
Spin-exchange collisions of submerged shell atoms below 1 Kelvin,"  Angular momentum changing collisions can be suppressed in atoms whose valence
electrons are submerged beneath filled shells of higher principle quantum
number. To determine whether spin-exchange collisions are suppressed in these
""submerged shell"" atoms, we measured spin-exchange collisions of six hyperfine
states of Mn at temperatures below 1 K. Although the 3d valence electrons in Mn
are submerged beneath a filled 4s orbital, we find that the spin exchange rate
coefficients are similar to those of Na and H (which are non-submerged shell
atoms).
",2009-11-13,False
Spin-exchange collisions of submerged shell atoms below 1 Kelvin,"This paper presents a study on the spin-exchange collisions of submerged shell atoms below 1 Kelvin. We investigate the interaction between two atoms in a cold gas, focusing on the exchange of their magnetic moments. The experimental setup employs a magnetic trap to confine a cloud of ultracold atoms and a radio-frequency technique to measure the spin-exchange rates. Our results show that the spin-exchange cross-section decreases as the temperature decreases, which is consistent with the theoretical prediction. We also observed that the collisional relaxation time increases as the density of the gas decreases. Our findings have important implications for the development of quantum computing and atomic clocks.",2009-11-13,True
Light Curve Calculations of Supernovae from Fallback Gamma-Ray Bursts,"  The currently-favored model for long-duration gamma-ray bursts (GRBs) invokes
explosions from the collapse of a massive star down to a black hole: either
directly or through fallback. Those GRBs forming via fallback will produce much
less radioactive nickel, and hence it has been argued (without any real
calculation) that these systems produce dim supernovae. These fallback
black-hole GRBs have been recently been argued as possible progenitors of a
newly discovered set of GRBs lacking any associated supernovae. Here we present
the first ever radiation-hydrodynamics calculations of the light-curves
produced in the hypernova explosion by a delayed-fallback gamma-ray burst. We
find that the bolometric light-curve is dominated by shock-deposited energy,
not the decay of radioactive elements. As such, observations of such bursts
actually probe the density in the progenitor wind more than it does the
production of radioactive nickel.
",2009-11-13,False
Light Curve Calculations of Supernovae from Fallback Gamma-Ray Bursts,This research paper investigates the light curves of supernovae resulting from fallback gamma-ray bursts. The study uses numerical simulations to calculate the light curves of various models and compares the results with observations of actual supernovae. The paper concludes that the fallback gamma-ray burst mechanism can explain the diverse light curves of supernovae and provides insights into the properties of the surrounding circumstellar material. These findings have significant implications for understanding the physics of supernovae and the role of gamma-ray bursts in their evolution.,2009-11-13,True
Field-Theoretic Simulations of Polyelectrolyte Complexation,"  We briefly discuss our recent field-theoretic study of polyelectrolyte
complexation, which occurs in solutions of two oppositely charged
polyelectrolytes. Charged systems require theoretical methods beyond the
mean-field (or self-consistent field) approximation; indeed, mean-field theory
is qualitatively incorrect for such polyelectrolyte solutions. Both analytical
(one-loop) and numerical (complex Langevin) methods to account for charge
correlations are discussed. In particular, the first application of
field-theoretic simulations to polyelectrolyte systems is reported. The
polyelectrolyte charge-charge correlation length and a phase diagram are
provided; effects of charge redistribution are qualitatively explored.
",2015-05-13,False
Field-Theoretic Simulations of Polyelectrolyte Complexation,"The research paper ""Field-Theoretic Simulations of Polyelectrolyte Complexation"" presents a study of the complexation between oppositely charged polyelectrolytes using field-theoretic simulations. The authors investigate the effects of various parameters such as charge density, chain length, and salt concentration on the complexation process. They find that the complexation behavior is strongly influenced by the charge density and chain length of the polyelectrolytes, as well as the ionic strength of the solution. The simulations also reveal the formation of various types of complex structures, including spherical and cylindrical micelles, as well as interconnected networks. The study provides valuable insights into the fundamental mechanisms underlying the complexation of polyelectrolytes and has implications for a wide range of applications in fields such as biotechnology and materials science.",2015-05-13,True
"Limit cycles in the presence of convection, a travelling wave analysis","  We consider a diffusion model with limit cycle reaction functions, in the
presence of convection. We select a set of functions derived from a realistic
reaction model: the Schnakenberg equations. This resultant form is
unsymmetrical. We find a transformation which maps the irregular equations into
model form. Next we transform the dependent variables into polar form. From
here, a travelling wave analysis is performed on the radial variable. Results
are complex, but we make some simple estimates.
  We carry out numerical experiments to test our analysis. An initial `knock'
starts the propagation of pattern. The speed of the travelling wave is not
quite as expected. We investigate further. The system demonstrates distinctly
different behaviour to the left and the right. We explain how this phenomenon
occurs by examining the underlying behaviour.
",2009-11-13,False
"Limit cycles in the presence of convection, a travelling wave analysis","This research paper explores the phenomenon of limit cycles in the presence of convection and utilizes a travelling wave analysis to understand the underlying mechanisms. Limit cycles are oscillations that occur in dynamical systems and have important applications in various fields, including physics and biology. Convection, which arises due to temperature differences, can significantly affect the behavior of limit cycles. The paper proposes a mathematical model to describe the interplay between limit cycles and convection and investigates the resulting dynamics. The travelling wave analysis provides insight into the spatiotemporal behavior of the system and reveals important features such as bifurcations and stability. The results of this study can contribute to a better understanding of limit cycles in complex systems and have implications for the design of control strategies in practical applications.",2009-11-13,True
"Energy Distribution of a Charged Black Hole with a Minimally Coupled
  Scalar Field","  Using three different energy-momentum complexes, the Einstein,
Landau-Lifshitz, and Papapetrou prescriptions, we calculate the energy of an
electrically charged black hole exact solution with a self-interacting,
minimally-coupled scalar field and the asymptotic region locally an
Anti-deSitter spacetime. Writing the metric in Kerr-Schild Cartesian
coordinates, we demonstrate that this metric belongs to the Kerr-Schild class
of solutions. Applying each of the three energy-momentum prescriptions and
comparing the results, we find consistency among these complexes, suggesting
their utility as localized measures of energy.
",2008-11-26,False
"Energy Distribution of a Charged Black Hole with a Minimally Coupled
  Scalar Field","This research paper examines the energy distribution of a charged black hole with a minimally coupled scalar field. The study utilizes the Newman-Penrose formalism to derive the energy-momentum tensor of the scalar field and investigates the energy distribution in the presence of a black hole charge. The results show that the presence of the charge significantly affects the energy distribution, leading to a shift in the location of the energy peak. Moreover, the study finds that the scalar field's energy density decreases as the charge of the black hole increases. These findings have significant implications for understanding the behavior of charged black holes and their interactions with scalar fields.",2008-11-26,True
"Zero-variance zero-bias quantum Monte Carlo estimators of the
  spherically and system-averaged pair density","  We construct improved quantum Monte Carlo estimators for the spherically- and
system-averaged electron pair density (i.e. the probability density of finding
two electrons separated by a relative distance u), also known as the
spherically-averaged electron position intracule density I(u), using the
general zero-variance zero-bias principle for observables, introduced by
Assaraf and Caffarel. The calculation of I(u) is made vastly more efficient by
replacing the average of the local delta-function operator by the average of a
smooth non-local operator that has several orders of magnitude smaller
variance. These new estimators also reduce the systematic error (or bias) of
the intracule density due to the approximate trial wave function. Used in
combination with the optimization of an increasing number of parameters in
trial Jastrow-Slater wave functions, they allow one to obtain well converged
correlated intracule densities for atoms and molecules. These ideas can be
applied to calculating any pair-correlation function in classical or quantum
Monte Carlo calculations.
",2009-11-13,False
"Zero-variance zero-bias quantum Monte Carlo estimators of the
  spherically and system-averaged pair density",This research paper presents zero-variance zero-bias quantum Monte Carlo estimators for the spherically and system-averaged pair density. The results show that the estimators have significantly reduced statistical errors compared to traditional methods. These findings have important implications for the efficient calculation of electronic structure properties in quantum many-body systems.,2009-11-13,True
Toward Full Spatio-Temporal Control on the Nanoscale,"  We introduce an approach to implement full coherent control on nanometer
length scales. It is based on spatio-temporal modulation of the surface plasmon
polariton (SPP) fields at the thick edge of a nanowedge. The SPP wavepackets
propagating toward the sharp edge of this nanowedge are compressed and
adiabatically concentrated at a nanofocus, forming an ultrashort pulse of local
fields. The one-dimensional spatial profile and temporal waveform of this pulse
are completely coherently controlled.
",2015-05-13,False
Toward Full Spatio-Temporal Control on the Nanoscale,"The research paper titled ""Toward Full Spatio-Temporal Control on the Nanoscale"" focuses on the development of a new technique that allows for full spatio-temporal control on the nanoscale. The main objective of the study is to investigate the use of ultrafast laser pulses to manipulate the spatial and temporal properties of materials at the nanoscale.

The researchers conducted experiments using a laser scanning microscope and a femtosecond laser to manipulate the properties of gold nanoparticles. They discovered that by controlling the intensity and duration of the laser pulses, they could precisely control the size and shape of the nanoparticles.

The study also explored the use of two-photon lithography to create complex nanoscale structures. The researchers found that they could use this technique to create high-resolution structures with a precision of less than 100 nanometers.

The notable conclusion of the study is that the use of ultrafast laser pulses and two-photon lithography provides a powerful tool for controlling the properties of materials at the nanoscale. This technique has the potential to revolutionize a wide range of fields, including electronics, photonics, and biomedicine.",2015-05-13,True
"Diversity of Decline-Rate-Corrected Type Ia Supernova Rise Times: One
  Mode or Two?","  B-band light-curve rise times for eight unusually well-observed nearby Type
Ia supernovae (SNe) are fitted by a newly developed template-building
algorithm, using light-curve functions that are smooth, flexible, and free of
potential bias from externally derived templates and other prior assumptions.
  From the available literature, photometric BVRI data collected over many
months, including the earliest points, are reconciled, combined, and fitted to
a unique time of explosion for each SN. On average, after they are corrected
for light-curve decline rate, three SNe rise in 18.81 +- 0.36 days, while five
SNe rise in 16.64 +- 0.21 days. If all eight SNe are sampled from a single
parent population (a hypothesis not favored by statistical tests), the rms
intrinsic scatter of the decline-rate-corrected SN rise time is 0.96 +0.52
-0.25 days -- a first measurement of this dispersion. The corresponding global
mean rise time is 17.44 +- 0.39 days, where the uncertainty is dominated by
intrinsic variance. This value is ~2 days shorter than two published averages
that nominally are twice as precise, though also based on small samples. When
comparing high-z to low-z SN luminosities for determining cosmological
parameters, bias can be introduced by use of a light-curve template with an
unrealistic rise time. If the period over which light curves are sampled
depends on z in a manner typical of current search and measurement strategies,
a two-day discrepancy in template rise time can bias the luminosity comparison
by ~0.03 magnitudes.
",2009-11-13,False
"Diversity of Decline-Rate-Corrected Type Ia Supernova Rise Times: One
  Mode or Two?","This research paper investigates the diversity of rise times in Type Ia supernovae and whether they can be separated into two distinct modes. The study uses a sample of 118 supernovae and applies a decline-rate correction to the rise times. The results suggest that there may be two distinct modes of rise times, with one mode having a faster rise time and the other having a slower rise time. However, further research is needed to confirm these findings and to understand the physical mechanisms behind this diversity. The implications of these findings for the use of Type Ia supernovae as cosmological distance indicators are also discussed.",2009-11-13,True
Nonholonomic Ricci Flows: Exact Solutions and Gravity,"  In a number of physically important cases, the nonholonomically
(nonintegrable) constrained Ricci flows can be modelled by exact solutions of
Einstein equations with nonhomogeneous (anisotropic) cosmological constants. We
develop two geometric methods for constructing such solutions: The first
approach applies the formalism of nonholonomic frame deformations when the
gravitational evolution and field equations transform into systems of nonlinear
partial differential equations which can be integrated in general form. The
second approach develops a general scheme when one (two) parameter families of
exact solutions are defined by any source-free solutions of Einstein's
equations with one (two) Killing vector field(s). A successive iteration
procedure results in a class of solutions characterized by an infinite number
of parameters for a non-Abelian group involving arbitrary functions on one
variable. We also consider nonlinear superpositions of some mentioned classes
of solutions in order to construct more general integral varieties of the Ricci
flow and Einstein equations depending on infinite number of parameters and
three/ four coordinates on four/ five dimensional (semi) Riemannian spaces.
",2009-02-17,False
Nonholonomic Ricci Flows: Exact Solutions and Gravity,"The research paper titled ""Nonholonomic Ricci Flows: Exact Solutions and Gravity"" explores the behavior of nonholonomic Ricci flows in the context of gravity. The authors investigate exact solutions of the nonholonomic Ricci flow equation and their implications for gravitational theories. They demonstrate that nonholonomic Ricci flows can be used to study the dynamics of spacetime in the presence of matter and energy. The paper also discusses the potential applications of these findings in cosmology and astrophysics. The main conclusion of the paper is that nonholonomic Ricci flows provide a powerful tool for understanding the complex dynamics of gravity and the evolution of spacetime.",2009-02-17,True
"Nonholonomic Ricci Flows and Parametric Deformations of the Solitonic
  pp--Waves and Schwarzschild Solutions","  We study Ricci flows of some classes of physically valuable solutions in
Einstein and string gravity. The anholonomic frame method is applied for
generic off-diagonal metric ansatz when the field/ evolution equations are
transformed into exactly integrable systems of partial differential equations.
The integral varieties of such solutions, in four and five dimensional gravity,
depend on arbitrary generation and integration functions of one, two and/ or
three variables. Certain classes of nonholonomic frame constraints allow us to
select vacuum and/or Einstein metrics, to generalize such solutions for
nontrivial string (for instance, with antisymmetric torsion fields) and matter
field sources. A very important property of this approach (originating from
Finsler and Lagrange geometry but re-defined for semi-Riemannian spaces) is
that new classes of exact solutions can be generated by nonholonomic
deformations depending on parameters associated to some generalized Geroch
transforms and Ricci flow evolution. In this paper, we apply the method to
construct in explicit form some classes of exact solutions for multi-parameter
Einstein spaces and their nonholonomic Ricci flows describing evolutions/
interactions of solitonic pp-waves and deformations of the Schwarzschild
metric. We explore possible physical consequences and speculate on their
importance in modern gravity.
",2009-05-05,False
"Nonholonomic Ricci Flows and Parametric Deformations of the Solitonic
  pp--Waves and Schwarzschild Solutions","This research paper investigates the nonholonomic Ricci flows and parametric deformations of solitonic pp-waves and Schwarzschild solutions. The study explores the geometrical properties of these solutions and their dynamical evolution. The results show that the nonholonomic Ricci flows can lead to the formation of singularities in the solitonic pp-waves. Furthermore, the parametric deformations of the Schwarzschild solutions reveal interesting properties related to the stability of the black hole horizons. The findings of this study contribute to a better understanding of the behavior of these important solutions in general relativity.",2009-05-05,True
"Mixing and decoherence to nearest separable states in quantum
  measurements","  We illustrate through numerical results a number of features of
environment-induced decoherence under a broad class of apparatus-environment
interactions in quantum measurements wherein the reduced system-apparatus
density matrix evolves towards the nearest separable state and, in addition,
there occurs a mixing in relevant groups of apparatus microstates (see below).
The resulting final state is unique and correctly embodies the measurement
statistics even in the absence of environment-induced superselection because of
energy differences between these groups of states. The partial transpose
remains non-positive throughout the process.
",2007-06-13,False
"Mixing and decoherence to nearest separable states in quantum
  measurements","The research paper investigates the effects of mixing and decoherence on quantum measurements, specifically in terms of the nearest separable states. The study utilizes mathematical models to analyze the behavior of quantum systems under these conditions. The findings suggest that the presence of mixing and decoherence can significantly affect the accuracy and reliability of quantum measurements. Additionally, the study highlights the importance of understanding these effects in the development of quantum technologies and applications.",2007-06-13,True
"AdS_3, Black Holes and Higher Derivative Corrections","  Using AdS/CFT correspondence and the Euclidean action formalism for black
hole entropy Kraus and Larsen have argued that the entropy of a BTZ black hole
in three dimensional supergravity with (0,4) supersymmetry does not receive any
correction from higher derivative terms in the action. We argue that as a
consequence of AdS/CFT correspondence the action of a three dimensional
supergravity with (0,4) supersymmetry cannot receive any higher derivative
correction except for those which can be removed by field redefinition. The
non-renormalization of the entropy then follows as a consequence of this and
the invariance of Wald's formula under a field redefinition.
",2009-04-17,False
"AdS_3, Black Holes and Higher Derivative Corrections","The paper investigates the effects of higher derivative corrections on black hole physics in three-dimensional anti-de Sitter (AdS) space. The authors use a combination of analytic and numerical techniques to study the behavior of black holes under various conditions, including the presence of scalar fields and magnetic charges. They find that the higher derivative corrections can significantly modify the thermodynamic properties of the black holes, leading to new phenomena such as phase transitions and non-universal behavior. The results have important implications for the holographic correspondence between AdS gravity and conformal field theory, and suggest new avenues for exploring the behavior of black holes in higher dimensions.",2009-04-17,True
The Optimization of a Novel Prismatic Drive,"  The design of a mechanical transmission taking into account the transmitted
forces is reported in this paper. This transmission is based on Slide-o-Cam, a
cam mechanism with multiple rollers mounted on a common translating follower.
The design of Slide-o-Cam, a transmission intended to produce a sliding motion
from a turning drive, or vice versa, was reported elsewhere. This transmission
provides pure-rolling motion, thereby reducing the friction of rack-and-pinions
and linear drives. The pressure angle is a relevant performance index for this
transmission because it determines the amount of force transmitted to the load
vs. that transmitted to the machine frame. To assess the transmission
capability of the mechanism, the Hertz formula is introduced to calculate the
stresses on the rollers and on the cams. The final transmission is intended to
replace the current ball-screws in the Orthoglide, a three-DOF parallel robot
for the production of translational motions, currently under development for
machining applications at Ecole Centrale de Nantes.
",2007-05-23,False
The Optimization of a Novel Prismatic Drive,"This research paper presents the optimization of a novel prismatic drive, which is a type of linear actuator. The design is based on a combination of a prismatic joint and a cam mechanism. The optimization process involves the selection of appropriate design parameters to achieve maximum efficiency and minimum energy consumption. The results of the study show that the optimized prismatic drive has significantly improved performance compared to traditional linear actuation methods. The novel design can be used in a range of applications, including robotics, automation, and manufacturing. The study concludes that the prismatic drive offers a promising alternative to traditional linear actuators, with potential for further optimization and improvement.",2007-05-23,True
Nonperturbative physics at short distances,"  There is accumulating evidence in lattice QCD that attempts to locate
confining fields in vacuum configurations bring results explicitly depending on
tha lattice spacing (that is, ultraviolet cut off). Generically, one deals with
low-dimensional vacuum defects which occupy a vanishing fraction of the total
four-dimensional space. We review briefly existing data on the vacuum defects
and their significance for confinement and other nonperturbative phenomena. We
introduce the notion of `quantum numbers' of the defects and draw an analogy,
rather formal one, to developments which took place about 50 years ago and were
triggered by creation of the Sakata model.
",2009-11-13,False
Nonperturbative physics at short distances,"This research paper explores nonperturbative physics at short distances, focusing on the use of lattice simulations to investigate strong interactions in quantum chromodynamics (QCD). The paper discusses the importance of understanding nonperturbative phenomena, such as confinement and chiral symmetry breaking, in QCD and the progress made in simulating these effects on a lattice. The authors highlight the significant contributions of lattice QCD to our understanding of hadron physics and the potential for future developments in this area.",2009-11-13,True
The ontology of temperature in nonequilibrium systems,"  The laws of thermodynamics provide a clear concept of the temperature for an
equilibrium system in the continuum limit. Meanwhile, the equipartition theorem
allows one to make a connection between the ensemble average of the kinetic
energy and the uniform temperature. When a system or its environment is far
from equilibrium, however, such an association does not necessarily apply. In
small systems, the regression hypothesis may not even apply. Herein, we show
that in small nonequilibrium systems, the regression hypothesis still holds
though with a generalized definition of the temperature. The latter must now be
defined for each such manifestation.
",2009-11-13,False
The ontology of temperature in nonequilibrium systems,"This research paper explores the ontology of temperature in nonequilibrium systems. The main objective is to investigate how temperature can be defined and understood in systems that are not in thermal equilibrium. The paper examines the role of statistical mechanics in defining temperature and discusses how this approach can be extended to nonequilibrium systems. The results show that temperature in nonequilibrium systems is a complex and multifaceted concept that cannot be reduced to a single measure. Instead, temperature must be understood in the context of the system's dynamics, with different measures of temperature depending on the specific properties of the system under consideration. The paper concludes by discussing the implications of these findings for the study of nonequilibrium systems and for the broader understanding of temperature in physics.",2009-11-13,True
"The Higgs sector of the complex MSSM at two-loop order: QCD
  contributions","  Results are presented for the leading two-loop contributions of O(alpha_t
alpha_s) to the masses and mixing effects in the Higgs sector of the MSSM with
complex parameters. They are obtained in the Feynman-diagrammatic approach
using on-shell renormalization. The full dependence on all complex phases is
taken into account. The renormalization of the appropriate contributions of the
Higgs-boson sector and the scalar top and bottom sector is discussed. Our
numerical analysis for the lightest MSSM Higgs-boson mass is based on the new
two-loop corrections, supplemented by the full one-loop result. The corrections
induced by the phase variation in the scalar top sector are enhanced by the
two-loop contributions. We find that the corresponding shift in M_h1 can amount
to 5 GeV.
",2008-11-26,False
"The Higgs sector of the complex MSSM at two-loop order: QCD
  contributions","The research paper titled ""The Higgs sector of the complex MSSM at two-loop order: QCD contributions"" investigates the quantum chromodynamics (QCD) contributions to the Higgs sector of the Minimal Supersymmetric Standard Model (MSSM). The central theme of the paper is to determine the impact of QCD corrections on the Higgs sector, particularly at the two-loop level.

The authors used a combination of analytical and numerical methods to calculate the two-loop QCD corrections to the Higgs boson mass and decay rates in the complex MSSM. They found that the QCD corrections play a significant role in the Higgs sector, affecting the masses and decay rates of the Higgs bosons. In particular, they found that the QCD corrections can increase the mass of the lightest Higgs boson by up to 10 GeV, which has important implications for experimental searches for the Higgs boson.

The authors also investigated the impact of the QCD corrections on the decays of the Higgs bosons into bottom quarks and tau leptons. They found that the QCD corrections can increase the branching ratio of the lightest Higgs boson into bottom quarks by up to 20%, while decreasing the branching ratio into tau leptons by up to 10%. These findings have important implications for the interpretation of experimental data from the Large Hadron Collider (LHC) and future colliders.

Overall, the paper provides a comprehensive analysis of the QCD corrections to the Higgs sector of the complex MSSM at the two-loop level, and highlights the importance of including these corrections in theoretical predictions for the Higgs sector.",2008-11-26,True
Damped Corrections to Inflationary Spectra from a Fluctuating Cutoff,"  We reconsider trans-Planckian corrections to inflationary spectra by taking
into account a physical effect which has been overlooked and which could have
important consequences. We assume that the short length scale characterizing
the new physics is endowed with a finite width, the origin of which could be
found in quantum gravity. As a result, the leading corrections responsible for
superimposed osillations in the CMB temperature anisotropies are generically
damped by the blurring of the UV scale. To determine the observational
ramifications of this damping, we compare it to that which effectively occurs
when computing the angular power spectrum of temperature anisotropies. The
former gives an overall change of the oscillation amplitudes whereas the latter
depends on the angular scale. Therefore, in principle they could be
distinguished. In any case, the observation of superimposed oscillations would
place tight constraint on the variance of the UV cutoff.
",2008-11-26,False
Damped Corrections to Inflationary Spectra from a Fluctuating Cutoff,"This research paper investigates the effect of a fluctuating cutoff on the inflationary spectra. Specifically, we consider the scenario where the cutoff is subject to stochastic fluctuations that could introduce damped corrections to the spectra. We use the stochastic inflationary model to explore this scenario and derive the corresponding equations that govern the dynamics of the cutoff and the spectra. Our analysis shows that the fluctuations in the cutoff can indeed lead to damped corrections to the spectra, which could have important implications for the interpretation of cosmological observations. We discuss the physical mechanisms behind these corrections and explore their dependence on the parameters of the model. Our results suggest that a better understanding of the cutoff fluctuations could help improve our ability to extract information about the early universe from observational data.",2008-11-26,True
"Ratios of star cluster core and half-mass radii: a cautionary note on
  intermediate-mass black holes in star clusters","  There is currently much interest in the possible presence of
intermediate-mass black holes in the cores of globular clusters. Based on
theoretical arguments and simulation results it has previously been suggested
that a large core radius -- or particularly a large ratio of the core radius to
half-mass radius -- is a promising indicator for finding such a black hole in a
star cluster. In this study N-body models of 100000 stars with and without
primordial binaries are used to investigate the long-term structural evolution
of star clusters. Importantly, the simulation data is analysed using the same
processes by which structural parameters are extracted from observed star
clusters. This gives a ratio of the core and half-mass (or half-light) radii
that is directly comparable to the Galactic globular cluster sample. As a
result, it is shown that the ratios observed for the bulk of this sample can be
explained without the need for an intermediate-mass black hole. Furthermore, it
is possible that clusters with large core to half-light radius ratios harbour a
black-hole binary (comprised of stellar mass black holes) rather than a single
massive black hole. This work does not rule out the existence of
intermediate-mass black holes in the cores of at least some star clusters.
",2009-06-23,False
"Ratios of star cluster core and half-mass radii: a cautionary note on
  intermediate-mass black holes in star clusters","This research paper examines the use of core and half-mass radii ratios as a tool for identifying intermediate-mass black holes (IMBHs) in star clusters. Through simulations and statistical analyses, the study reveals that caution must be exercised when interpreting these ratios as indicators of IMBH presence. The paper highlights the importance of considering various factors, such as cluster size, age, and initial conditions, when interpreting observed ratios. The findings have significant implications for the search for IMBHs in star clusters and suggest that alternative methods may be necessary for their detection.",2009-06-23,True
The E_{11} origin of all maximal supergravities,"  Starting from the eleven dimensional E_{11} non-linear realisation of
M-theory we compute all possible forms, that is objects with totally
antisymmetrised indices, that occur in four dimensions and above as well as all
the 1-forms and 2-forms in three dimensions. In any dimension D, the D-1-forms
lead to maximal supergravity theories with cosmological constants and they are
in precise agreement with the patterns of gauging found in any dimension using
supersymmetry. The D-forms correspond to the presence of space-filling branes
which are crucial for the consistency of orientifold models and have not been
derived from an alternative approach, with the exception of the 10-dimensional
case. It follows that the gaugings of supergravities and the spacetime-filling
branes possess an eleven dimensional origin within the E_{11} formulation of
M-theory. This and previous results very strongly suggest that all the fields
in the adjoint representation of E_{11} have a physical interpretation.
",2009-04-17,False
The E_{11} origin of all maximal supergravities,"This research paper explores the origins of all maximal supergravities from the perspective of the E_{11} symmetry group. The paper begins with a brief overview of the historical development of supergravity theories and their limitations. It then introduces the E_{11} group and its relevance as a unifying framework for all maximal supergravities. The paper presents a detailed analysis of the E_{11} symmetry algebra, including its generators and structure constants, and shows how it can be used to derive the field equations of all maximal supergravities. The paper also discusses the connection between E_{11} and M-theory, providing insight into the fundamental nature of both theories. The main conclusion of the paper is that E_{11} provides a powerful tool for understanding the origins and relationships among all maximal supergravities, paving the way for further advancements in theoretical physics.",2009-04-17,True
Transcritical bifurcations in non-integrable Hamiltonian systems,"  We report on transcritical bifurcations of periodic orbits in non-integrable
two-dimensional Hamiltonian systems. We discuss their existence criteria and
some of their properties using a recent mathematical description of
transcritical bifurcations in families of symplectic maps. We then present
numerical examples of transcritical bifurcations in a class of generalized
H\'enon-Heiles Hamiltonians and illustrate their stabilities and unfoldings
under various perturbations of the Hamiltonians. We demonstrate that for
Hamiltonians containing straight-line librating orbits, the transcritical
bifurcation of these orbits is the typical case which occurs also in the
absence of any discrete symmetries, while their isochronous pitchfork
bifurcation is an exception. We determine the normal forms of both types of
bifurcations and derive the uniform approximation required to include
transcritically bifurcating orbits in the semiclassical trace formula for the
density of states of the quantum Hamiltonian. We compute the coarse-grained
density of states in a specific example both semiclassically and quantum
mechanically and find excellent agreement of the results.
",2008-04-14,False
Transcritical bifurcations in non-integrable Hamiltonian systems,"The research paper ""Transcritical bifurcations in non-integrable Hamiltonian systems"" investigates the behavior of Hamiltonian systems that are not integrable. It focuses on the occurrence of transcritical bifurcations, which are points where the equilibrium points of the system change stability. The paper presents a theoretical framework for understanding these bifurcations and uses numerical simulations to demonstrate their occurrence in specific systems. The authors conclude that transcritical bifurcations play an important role in the dynamics of non-integrable Hamiltonian systems and should be considered in their analysis.",2008-04-14,True
Stallings' Foldings and Subgroups of Amalgams of Finite Groups,"  In the 1980's Stallings showed that every finitely generated subgroup of a
free group is canonically represented by a finite minimal immersion of a
bouquet of circles. In terms of the theory of automata, this is a minimal
finite inverse automaton. This allows for the deep algorithmic theory of finite
automata and finite inverse monoids to be used to answer questions about
finitely generated subgroups of free groups.
  In this paper we attempt to apply the same methods to other classes of
groups. A fundamental new problem is that the Stallings folding algorithm must
be modified to allow for ``sewing'' on relations of non-free groups. We look at
the class of groups that are amalgams of finite groups. It is known that these
groups are locally quasiconvex and thus all finitely generated subgroups are
represented by finite automata. We present an algorithm to compute such a
finite automaton and use it to solve various algorithmic problems.
",2007-05-23,False
Stallings' Foldings and Subgroups of Amalgams of Finite Groups,"The research paper ""Stallings' Foldings and Subgroups of Amalgams of Finite Groups"" explores a method for studying subgroups of amalgams of finite groups using Stallings' foldings. The authors begin by introducing the concept of an amalgam of finite groups and discussing the difficulties in studying their subgroups. They then introduce Stallings' foldings as a powerful tool for studying subgroups of finitely presented groups.

The main result of the paper is a theorem that gives necessary and sufficient conditions for a subgroup of an amalgam to be finitely generated. The authors also discuss applications of this theorem to other areas of group theory, such as the study of the automorphism groups of free groups.

Overall, the paper highlights the usefulness of Stallings' foldings in studying subgroups of amalgams of finite groups and provides a valuable contribution to the field of group theory.",2007-05-23,True
Metallic phase in the two-dimensional ionic Hubbard model,"  We investigate the phases of the ionic Hubbard model in a two-dimensional
square lattice using determinant quantum Monte Carlo (DQMC). At half-filling,
when the interaction strength or the staggered potential dominate we find Mott
and band insulators, respectively. When these two energies are of the same
order we find a metallic region. Charge and magnetic structure factors
demonstrate the presence of antiferromagnetism only in the Mott region,
although the externally imposed density modulation is present everywhere in the
phase diagram. Away from half-filling, other insulating phases are found.
Kinetic energy correlations do not give clear signals for the existence of a
bond-ordered phase.
",2009-11-13,False
Metallic phase in the two-dimensional ionic Hubbard model,"The two-dimensional ionic Hubbard model is a theoretical model used to study the behavior of electrons in materials with both ionic and metallic properties. In this study, the focus was on the metallic phase of the model, which describes the behavior of electrons in a material with metallic properties. The researchers used computer simulations to explore the behavior of electrons in the metallic phase of the model and found that the behavior was highly dependent on the strength of the ionic interactions. They also found that the metallic phase could exhibit a variety of different behaviors, including superconductivity and magnetic ordering. The study provides important insights into the behavior of electrons in materials with both metallic and ionic properties, which could have important implications for the development of new materials with unique electronic properties.",2009-11-13,True
Equivalence of three-dimensional spacetimes,"  A solution to the equivalence problem in three-dimensional gravity is given
and a practically useful method to obtain a coordinate invariant description of
local geometry is presented. The method is a nontrivial adaptation of Karlhede
invariant classification of spacetimes of general relativity. The local
geometry is completely determined by the curvature tensor and a finite number
of its covariant derivatives in a frame where the components of the metric are
constants. The results are presented in the framework of real two-component
spinors in three-dimensional spacetimes, where the algebraic classifications of
the Ricci and Cotton-York spinors are given and their isotropy groups and
canonical forms are determined. As an application we discuss Goedel-type
spacetimes in three-dimensional General Relativity. The conditions for local
space and time homogeneity are derived and the equivalence of three-dimensional
Goedel-type spacetimes is studied and the results are compared with previous
works on four-dimensional Goedel-type spacetimes.
",2011-03-28,False
Equivalence of three-dimensional spacetimes,"The concept of equivalence has been a central theme in the study of spacetimes. In this research paper, we investigate the equivalence of three-dimensional spacetimes. We focus on the notion of isometry, which captures the idea of preserving distances and angles between points. We consider three different types of three-dimensional spacetimes, namely, flat, hyperbolic, and spherical. Using the tools of differential geometry, we explore the properties of isometries in each of these spacetimes. We then examine the relationship between these spacetimes through the lens of isometry. Our analysis reveals that the three-dimensional spacetimes are not equivalent in the sense of isometry. Our findings have important implications for the study of spacetimes and contribute to a deeper understanding of the geometry of the universe.",2011-03-28,True
"Equivalence of LP Relaxation and Max-Product for Weighted Matching in
  General Graphs","  Max-product belief propagation is a local, iterative algorithm to find the
mode/MAP estimate of a probability distribution. While it has been successfully
employed in a wide variety of applications, there are relatively few
theoretical guarantees of convergence and correctness for general loopy graphs
that may have many short cycles. Of these, even fewer provide exact ``necessary
and sufficient'' characterizations.
  In this paper we investigate the problem of using max-product to find the
maximum weight matching in an arbitrary graph with edge weights. This is done
by first constructing a probability distribution whose mode corresponds to the
optimal matching, and then running max-product. Weighted matching can also be
posed as an integer program, for which there is an LP relaxation. This
relaxation is not always tight. In this paper we show that \begin{enumerate}
\item If the LP relaxation is tight, then max-product always converges, and
that too to the correct answer. \item If the LP relaxation is loose, then
max-product does not converge. \end{enumerate} This provides an exact,
data-dependent characterization of max-product performance, and a precise
connection to LP relaxation, which is a well-studied optimization technique.
Also, since LP relaxation is known to be tight for bipartite graphs, our
results generalize other recent results on using max-product to find weighted
matchings in bipartite graphs.
",2007-07-13,False
"Equivalence of LP Relaxation and Max-Product for Weighted Matching in
  General Graphs","This research paper investigates the equivalence of the linear programming (LP) relaxation method and the max-product algorithm for solving the weighted matching problem in general graphs. The weighted matching problem is a fundamental optimization problem in graph theory, with applications in various fields such as computer science and operations research. Previous studies have shown that the LP relaxation method yields a tight bound for the maximum weight of a matching in a bipartite graph. However, it is not clear whether this equivalence holds for general graphs. In this paper, we provide a thorough analysis of the LP relaxation method and the max-product algorithm for the weighted matching problem in general graphs. We show that under certain conditions, the LP relaxation method and the max-product algorithm produce equivalent solutions. Our results shed light on the relationship between these two methods and provide insights into the effectiveness of the LP relaxation method for solving the weighted matching problem in general graphs.",2007-07-13,True
Bayesian Approach to Neuro-Rough Models,"  This paper proposes a neuro-rough model based on multi-layered perceptron and
rough set. The neuro-rough model is then tested on modelling the risk of HIV
from demographic data. The model is formulated using Bayesian framework and
trained using Monte Carlo method and Metropolis criterion. When the model was
tested to estimate the risk of HIV infection given the demographic data it was
found to give the accuracy of 62%. The proposed model is able to combine the
accuracy of the Bayesian MLP model and the transparency of Bayesian rough set
model.
",2007-08-28,False
Bayesian Approach to Neuro-Rough Models,"This research paper proposes a Bayesian approach to Neuro-Rough models for effective classification and prediction in complex datasets. Neuro-Rough models combine the power of neural networks and rough sets to handle uncertainties and inconsistencies in data. However, selecting appropriate parameters and optimizing the model's performance remains a challenge. In contrast, Bayesian inference provides a probabilistic framework for model training, selection, and evaluation, offering a principled approach to address these issues. Our proposed Bayesian Neuro-Rough model shows promising results on benchmark datasets and demonstrates the potential to improve classification accuracy and interpretability in various applications.",2007-08-28,True
"Symmetries in Differential Geometry: A Computational Approach to
  Prolongations","  The aim of this work is to develop a systematic manner to close
overdetermined systems arising from conformal Killing tensors (CKT). The
research performs this action for 1-tensor and 2-tensors. This research makes
it possible to develop a new general method for any rank of CKT. This method
can also be applied to other types of Killing equations, as well as to
overdetermined systems constrained by some other conditions.
  The major methodological apparatus of the research is a decomposition of the
section bundles where the covariant derivatives of the CKT land via generalized
gradients. This decomposition generates a tree in which each row represents a
higher derivative. After using the conformal Killing equation, just a few
components (branches) survive, which means that most of them can be expressed
in terms of lower order terms. This results in a finite number of independent
jets. Thus, any higher covariant derivative can be written in terms of these
jets.
  The findings of this work are significant methodologically and, more
specifically, in the potential for the discovery of symmetries. First, this
work has uncovered a new method that could be used to close overdetermined
systems arising from conformal Killing tensors (CKT). Second, through an
application of this method, this research finds higher symmetry operators of
first and second degree, which are known by other means, for the Laplace
operator. The findings also reveal the first order symmetry operators for the
Yamabe case. Moreover, the research leads to conjectures about the second order
symmetries of the Yamabe operator.
",2007-05-23,False
"Symmetries in Differential Geometry: A Computational Approach to
  Prolongations","This research paper focuses on the computational approach to prolongations in differential geometry, exploring the symmetries involved. The authors present a comprehensive overview of the subject and propose a new algorithm for computing prolongations. The findings suggest that this approach can be used to effectively analyze the symmetries in differential geometry, opening up new avenues for research in this field.",2007-05-23,True
Elementary excitations in a supersolid,"  We study elementary low energy excitations inside a supersolid. We find that
the coupling between the longitudinal lattice vibration mode and the superfluid
mode leads to two longitudinal modes (one upper branch and one lower branch)
inside the supersolid, while the transverse modes in the supersolid stay the
same as those inside a normal solid. We also work out various experimental
signatures of these novel elementary excitations by evaluating the Debye-Waller
factor, density-density correlation, vortex loop-vertex loop interactions,
specific heat and excess entropy from the vacancies per mole.
",2008-03-15,False
Elementary excitations in a supersolid,"In a supersolid, the atoms are arranged in a regular pattern like a solid, but they also flow like a superfluid. This unique state of matter has been studied extensively, and this research focuses on the elementary excitations within a supersolid. Elementary excitations are the vibrations and movements of the atoms within the material, and they play a crucial role in understanding its properties. The study used a combination of theoretical calculations and experimental measurements to investigate these excitations and their behavior in a supersolid. The research found that the excitations in a supersolid are different from those in a typical solid or superfluid and are characterized by a lower energy and longer lifetime. The findings provide important insights into the fundamental properties of a supersolid and could have implications for the development of new materials and technologies.",2008-03-15,True
"Revisiting the Fermi Golden Rule: Quantum Dynamical Phase Transition as
  a Paradigm Shift","  Classical and quantum phase transitions involve observables which are
non-analytic as functions of a controlled thermodynamical variable. As occurs
with the self-consistent Fermi Golden Rule, one condition to obtain the
discontinuous behavior is the proper evaluation of a classical or quantum
thermodynamic limit. We show that in presence of an environment, the
oscillatory dynamics of a quantum two-level system, in analogy with a classical
damped oscillator, can undergo a quantum dynamical phase transition to a
non-oscillatory phase. This is obtained from a self-consistent solution of the
Generalized Landauer Buettiker Equations, a simplified integral form of the
Keldysh formalism. I argue that working at each side of the transition implies
standing under different paradigms in the Kuhn's sense of the word. In
consequence, paradigms incommensurability obtains a sound mathematical
justification as a consequence of the non-analyticity of the observables. A
strong case is made upon the need to deepen the public's intuition and
understanding on the abrupt transition from static to dynamical friction
regimes.
  Keywords: Self Consistent Fermi Golden Rule, Paradigm Shift, Quantum
Dynamical Phase Transition, Decoherence, Energy-time Wigner Function,
Dissipative Two-level system, Keldysh Formalisma, Generalized
Landauer-Buettiker Equations, Loschmidt Echo, Mesoscopic Echo, Spin Dynamics,
Solid State NMR, Dynamical Quantum Zeno Effect, Liquid Crystal NMR.
",2009-11-13,False
"Revisiting the Fermi Golden Rule: Quantum Dynamical Phase Transition as
  a Paradigm Shift","This research paper revisits the Fermi Golden Rule, a fundamental principle in quantum mechanics that describes the probability of a quantum system transitioning from one state to another. The main objective of this study is to explore the concept of quantum dynamical phase transition and its implications for the Fermi Golden Rule. The authors argue that quantum dynamical phase transition represents a paradigm shift in our understanding of quantum mechanics and its applications. They provide a theoretical framework for this concept and demonstrate its relevance to various physical systems, including quantum spin chains and Bose-Einstein condensates. The key findings of this study include the identification of critical points in the quantum phase space, the emergence of coherent quantum states, and the breakdown of the Fermi Golden Rule at certain transition points. The authors conclude that quantum dynamical phase transition offers a new perspective on quantum mechanics and its potential for practical applications in fields such as quantum computing and quantum sensing.",2009-11-13,True
Stability of Polytropes,"  This paper is an investigation of the stability of some ideal stars. It is
in- tended as a study in General Relativity, with emphasis on the coupling to
matter, eventually aimed at a better understanding of very strong gravitational
fields and Black Holes. The work is based on an action principle for the
complete system of metric and matter fields. We propose a complete revision of
the treatment of boundary conditions. An ideal star in our terminology has
spherical symmetry and an isentropic equation of state. In our first work on
this subject it was assumed that the density vanishes beyond a finite distance
from the origin. But it is difficult to decide what the proper boundary
conditions should be and we are consequently skeptical of the concept of a
fixed boundary. In this paper we investigate the double polytrope,
characterized by a polytropic index n less than 5 in the bulk of the star and a
value larger than 5 in an outer atmosphere that extends to infinity. It has no
fixed boundary but a region of critical density where the polytropic index
changes from a value that is appropriate for the bulk of the star to a value
that provides a crude model for the atmosphere. The existence of a relation
between mass and radius is confirmed, as well as an upper limit on the mass.
The principal conclusion is that all the static configurations are stable.
",2008-11-26,False
Stability of Polytropes,"The research paper titled ""Stability of Polytropes"" investigates the stability of polytropic gas spheres. The study focuses on the conditions under which the polytropes maintain their equilibrium and the factors that affect their stability. The paper presents numerical simulations of polytropes with different values of the polytropic index and discusses the impact of rotation and magnetic fields on their stability. The findings indicate that the stability of polytropes is mainly influenced by the polytropic index and rotation, while the magnetic field has a minor effect. The paper concludes that polytropes with higher values of the polytropic index and slower rotation tend to be more stable.",2008-11-26,True
Binary Quantum Search,"  Database search has wide applications and is used as a subroutine in many
important algorithms. We shall consider a database with one target item.
Quantum algorithm finds the target item in a database faster than any classical
algorithm. It frequently occurs in practice that only a portion of information
about the target item is interesting, or we need to find a group of items
sharing some common feature as the target item. This problem is in general
formulated as search for a part of the database [a block] containing the target
item, instead of the item itself. This is partial search. Partial search trades
accuracy for speed, i.e. it works faster than a full search. Partial search
algorithm was discovered by Grover and Radhakrishnan. We shall consider
optimized version of the algorithm and call it GRK. It can be applied
successively [in a sequence]. First the database is partitioned into blocks and
we use GRK to find the target block. Then this target block is partitioned into
sub-blocks and we use GRK again to find the target sub-block. [We can call it
binary quantum search.] Another possibility is to partition the database into
sub-blocks directly and use GRK to find the target sub-block in one time. In
this paper we prove that the latter is faster [makes less queries to the
oracle].
",2009-11-13,False
Binary Quantum Search,"Binary quantum search is a quantum algorithm that aims to find a specific item in an unstructured database with an exponential speedup over classical algorithms. The algorithm involves the use of quantum parallelism and interference to search through a database of N items in O(sqrt(N)) time. This algorithm has the potential to revolutionize the field of database searching and has implications for fields such as cryptography and machine learning. Recent research has focused on improving the efficiency and reliability of the algorithm, as well as exploring its applications in different areas. Noteworthy outcomes of this research include the development of new techniques for implementing the algorithm on different types of quantum hardware and the identification of potential limitations in its scalability and robustness. Overall, binary quantum search represents a promising area of quantum computing research with significant implications for a wide range of applications.",2009-11-13,True
Ageing memory and glassiness of a driven vortex system,"  Many systems in nature, glasses, interfaces and fractures being some
examples, cannot equilibrate with their environment, which gives rise to novel
and surprising behaviour such as memory effects, ageing and nonlinear dynamics.
Unlike their equilibrated counterparts, the dynamics of out-of- equilibrium
systems is generally too complex to be captured by simple macroscopic laws.
Here we investigate a system that straddles the boundary between glass and
crystal: a Bragg glass formed by vortices in a superconductor. We find that the
response to an applied force evolves according to a stretched exponential, with
the exponent reflecting the deviation from equilibrium. After the force is
removed, the system ages with time and its subsequent response time scales
linearly with its age (simple ageing), meaning that older systems are slower
than younger ones. We show that simple ageing can occur naturally in the
presence of sufficient quenched disorder. Moreover, the hierarchical
distribution of timescales, arising when chunks of loose vortices cannot move
before trapped ones become dislodged, leads to a stretched-exponential
response.
",2015-05-13,False
Ageing memory and glassiness of a driven vortex system,"This research paper investigates the ageing memory and glassiness of a driven vortex system using numerical simulations. The primary theme is to understand the dynamics of the vortex system and its response to external driving forces. The paper finds that the system exhibits ageing memory, where its response depends on the history of the driving force. Additionally, the system shows glassy behavior, where its relaxation time increases as the temperature decreases. These findings provide insights into the complex behavior of driven vortex systems and have implications for a range of physical systems that exhibit similar dynamics.",2015-05-13,True
Medical Image Segmentation and Localization using Deformable Templates,"  This paper presents deformable templates as a tool for segmentation and
localization of biological structures in medical images. Structures are
represented by a prototype template, combined with a parametric warp mapping
used to deform the original shape. The localization procedure is achieved using
a multi-stage, multi-resolution algorithm de-signed to reduce computational
complexity and time. The algorithm initially identifies regions in the image
most likely to contain the desired objects and then examines these regions at
progressively increasing resolutions. The final stage of the algorithm involves
warping the prototype template to match the localized objects. The algorithm is
presented along with the results of four example applications using MRI, x-ray
and ultrasound images.
",2007-05-23,False
Medical Image Segmentation and Localization using Deformable Templates,"This research paper aims to present a new approach for medical image segmentation and localization using deformable templates. Medical image segmentation and localization are essential tasks in medical image analysis and diagnosis. The proposed method employs deformable templates to model the shape and appearance of anatomical structures in medical images. The templates are designed to be flexible and adaptable to different image characteristics, allowing accurate segmentation and localization of objects of interest in medical images. The method is evaluated on several medical image datasets, and the results demonstrate its effectiveness and robustness compared to other state-of-the-art methods. The proposed approach has the potential to improve the accuracy and reliability of medical image analysis, leading to better and more precise diagnosis and treatment planning.",2007-05-23,True
"Non-cooperative games for spreading code optimization, power control and
  receiver design in wireless data networks","  This paper focuses on the issue of energy efficiency in wireless data
networks through a game theoretic approach. The case considered is that in
which each user is allowed to vary its transmit power, spreading code, and
uplink receiver in order to maximize its own utility, which is here defined as
the ratio of data throughput to transmit power. In particular, the case in
which linear multiuser detectors are employed at the receiver is treated first,
and, then, the more challenging case in which non-linear decision feedback
multiuser receivers are adopted is addressed. It is shown that, for both
receivers, the problem at hand of utility maximization can be regarded as a
non-cooperative game, and it is proved that a unique Nash equilibrium point
exists. Simulation results show that significant performance gains can be
obtained through both non-linear processing and spreading code optimization; in
particular, for systems with a number of users not larger than the processing
gain, remarkable gains come from spreading code optimization, while, for
overloaded systems, the largest gainscome from the use of non-linear
processing. In every case, however, the non-cooperative games proposed here are
shown to outperform competing alternatives.
",2007-07-13,False
"Non-cooperative games for spreading code optimization, power control and
  receiver design in wireless data networks","This research paper focuses on applying non-cooperative game theory to optimize code spreading, power control and receiver design in wireless data networks. The study proposes a distributed algorithm based on a non-cooperative game model to achieve optimal performance in these three areas. The results demonstrate that the proposed algorithm outperforms existing solutions in terms of convergence speed and energy efficiency. The paper concludes that non-cooperative game theory can be an effective tool for optimizing wireless networks, especially in scenarios with limited information exchange and centralized control.",2007-07-13,True
"Using a Laguerre-Gaussian beam to trap and cool the rotational motion of
  a mirror","  We show theoretically that it is possible to trap and cool the rotational
motion of a macroscopic mirror made of a perfectly reflecting spiral phase
element using orbital angular momentum transfer from a Laguerre-Gaussian
optical field. This technique offers a promising route to the placement of the
rotor in its quantum mechanical ground state in the presence of thermal noise.
It also opens up the possibility of simultaneously cooling a vibrational mode
of the same mirror. Lastly, the proposed design may serve as a sensitive
torsional balance in the quantum regime.
",2015-05-13,False
"Using a Laguerre-Gaussian beam to trap and cool the rotational motion of
  a mirror","This research paper investigates the use of a Laguerre-Gaussian beam to trap and cool the rotational motion of a mirror. The experiment aims to demonstrate the effectiveness of this technique in reducing the rotational motion of the mirror, which is essential in gravitational wave detectors. The study utilizes a combination of classical mechanics and quantum optics to analyze the properties of the Laguerre-Gaussian beam and its interaction with the mirror. The results show that the beam successfully reduces the mirror's rotational motion and confirms the potential of this technique in improving the sensitivity of gravitational wave detectors. Overall, this study establishes a promising avenue for further research in the field of gravitational wave detection.",2015-05-13,True
"Poloidal-toroidal decomposition in a finite cylinder. II.
  Discretization, regularization and validation","  The Navier-Stokes equations in a finite cylinder are written in terms of
poloidal and toroidal potentials in order to impose incompressibility.
Regularity of the solutions is ensured in several ways: First, the potentials
are represented using a spectral basis which is analytic at the cylindrical
axis. Second, the non-physical discontinuous boundary conditions at the
cylindrical corners are smoothed using a polynomial approximation to a steep
exponential profile. Third, the nonlinear term is evaluated in such a way as to
eliminate singularities. The resulting pseudo-spectral code is tested using
exact polynomial solutions and the spectral convergence of the coefficients is
demonstrated. Our solutions are shown to agree with exact polynomial solutions
and with previous axisymmetric calculations of vortex breakdown and of
nonaxisymmetric calculations of onset of helical spirals. Parallelization by
azimuthal wavenumber is shown to be highly effective.
",2007-11-22,False
"Poloidal-toroidal decomposition in a finite cylinder. II.
  Discretization, regularization and validation","This research paper presents a numerical method for the poloidal-toroidal decomposition of vector fields in a finite cylinder. The decomposition is performed using a discretization scheme that is regularized to ensure stability and accuracy. The accuracy of the method is validated by comparing the results with analytical solutions and benchmark tests. The paper also discusses the limitations of the method and suggests areas for future research. Overall, this study provides a useful tool for the analysis of vector fields in cylindrical geometries, with potential applications in plasma physics, fluid dynamics, and geophysics.",2007-11-22,True
Peculiar Band Gap Structure of Graphene Nanoribbons,"  Graphene nanoribbons are quasi-one-dimensional meterials with finite width.
Characterizing a wide class of nanoribbons by edge shape and width, we make a
systematic analysis of their electronic properties. The band gap structure of
nanoribbons is shown to exhibit a valley structure with stream-like sequences
of metallic or almost metallic nanoribbons. Among them, all zigzag nanoribbons
are metallic, and armchair nanoribbons are metallic by period of 3. We find
that these stream-like sequences correspond to equi-width curves, and that the
band gap of chiral and armchair nanoribbons oscillate as a function of the
width. Furthermore a possible application of nanoribbons to nanoelectronics is
discussed.
",2007-05-23,False
Peculiar Band Gap Structure of Graphene Nanoribbons,"The paper investigates the band gap structure of graphene nanoribbons (GNRs), which are strips of graphene with varying widths and edge shapes. Using density functional theory calculations, the authors demonstrate that the band gap of GNRs is highly dependent on their width and edge shape. Specifically, GNRs with zigzag edges have a band gap that decreases with increasing width, while those with armchair edges have a constant band gap regardless of width. The authors also show that the band gap of GNRs can be tuned by introducing defects or functional groups. These findings have important implications for the design and optimization of GNR-based electronic devices.",2007-05-23,True
On the gravitational coupling of Hadamard states,"  We study the constraints imposed by the Hadamard condition on the two-point
function of local states of a scalar quantum field conformally coupled to a
gravitational background. We propose a method to assign a stress tensor to the
state-dependent part of the two point function which arises as a conserved
tensor with an anomalous trace. To characterize the local Hadamard states of
physical interest we apply a super-selection rule relating this quantum stress
tensor to the matter stress tensor of a conformal invariant gravitational model
subject to a conformal symmetry breaking term. This implies that the
determination of a Hadamard state may be considered as an integral part of its
gravitational coupling via the back-reaction effect.
",2007-05-23,False
On the gravitational coupling of Hadamard states,"This research paper investigates the gravitational coupling of Hadamard states, which are quantum states commonly used in the study of quantum field theory in curved spacetime. The focus is on understanding how these states interact with gravity and how this interaction can be described mathematically. Specifically, we examine the effect of curvature on the correlation functions of Hadamard states and explore the implications of this effect for the interpretation of the states in the context of quantum gravity. The paper utilizes a combination of analytical and numerical techniques to study the behavior of Hadamard states in different gravitational backgrounds. The findings contribute to the ongoing effort to develop a consistent theory of quantum gravity that can reconcile the principles of quantum mechanics and general relativity.",2007-05-23,True
On the construction of the Hadamard sates in two dimensions,"  The two dimensional analog of the Hadamard state condition is used to specify
the local Hadamard states associated with a linear quantum field coupled to a
two dimensional gravitational background. To characterize a local Hadamard
state corresponding to a physical vacuum state, we apply a superselection rule
in which the state dependent part of the two-point function is determined in
terms of a dynamical scalar field. It implies a basic connection between the
vacuum state and a scalar field coupled to gravity. We study the
characteristics of the Hadamard vacuum state through this superselection rule
using two different background metrics, the two dimensional analog of the
schwarzschild and FRW metric.
",2007-05-23,False
On the construction of the Hadamard sates in two dimensions,"The research paper explores the construction of Hadamard states in two dimensions using the tensor product of one-dimensional Hadamard matrices. The authors provide a detailed analysis of the properties of these states, including their orthogonality and completeness. They also investigate the relationship between the Hadamard states and other quantum states, such as Bell states and GHZ states. The authors conclude that the Hadamard states in two dimensions have significant applications in quantum information processing, including quantum cryptography and quantum teleportation.",2007-05-23,True
Towards a New Standard Model for Black Hole Accretion,"  We briefly review recent developments in black hole accretion disk theory,
emphasizing the vital role played by magnetohydrodynamic (MHD) stresses in
transporting angular momentum. The apparent universality of accretion-related
outflow phenomena is a strong indicator that large-scale MHD torques facilitate
vertical transport of angular momentum. This leads to an enhanced overall rate
of angular momentum transport and allows accretion of matter to proceed at an
interesting rate. Furthermore, we argue that when vertical transport is
important, the radial structure of the accretion disk is modified at small
radii and this affects the disk emission spectrum. We present a simple model
demonstrating how energetic, magnetically-driven outflows modify the emergent
disk emission spectrum with respect to that predicted by standard accretion
disk theory. A comparison of the predicted spectra against observations of
quasar spectral energy distributions suggests that mass accretion rates
inferred using the standard disk model may severely underestimate their true
values.
",2009-06-23,False
Towards a New Standard Model for Black Hole Accretion,"This research paper proposes a new standard model for black hole accretion that accounts for the complex interplay between the accretion disk and the black hole's gravitational field. Using numerical simulations, the authors demonstrate that this model can explain a range of observed phenomena, including the production of jets and the variability of accretion disks. The proposed model also has important implications for our understanding of the growth and evolution of black holes. Overall, this research represents a significant step towards a more comprehensive understanding of black hole accretion.",2009-06-23,True
"RossiXTE monitoring of 4U 1636-53: I. Long-term evolution and kHz
  Quasi-Periodic Oscillations","  We have monitored the atoll-type neutron star low-mass X-ray binary 4U
1636-53 with the Rossi X-Ray Timing Explorer (RXTE) for more than 1.5 years.
Our campaign consisted of short (~2 ks) pointings separated by two days,
regularly monitoring the spectral and timing properties of the source. During
the campaign we observed a clear long-term oscillation with a period of ~30-40
days, already seen in the light curves from the RXTE All-Sky Monitor, which
corresponded to regular transitions between the hard (island) and soft (banana)
states. We detected kHz QPOs in about a third of the observations, most of
which were in the soft (banana) state. The distribution of the frequencies of
the peak identified as the lower kHz QPO is found to be different from that
previously observed in an independent data set. This suggests that the kHz QPOs
in the system shows no intrinsically preferred frequency.
",2009-06-23,False
"RossiXTE monitoring of 4U 1636-53: I. Long-term evolution and kHz
  Quasi-Periodic Oscillations","The article discusses the monitoring of the neutron star 4U 1636-53 using the Rossi X-ray Timing Explorer (RXTE) satellite. The study focuses on the long-term evolution of the system and the kHz quasi-periodic oscillations (QPOs) observed in its X-ray emission. The authors analyze the data from RXTE observations spanning over a decade and conclude that the system's X-ray flux and kHz QPO properties undergo significant changes over time. They also suggest that the kHz QPOs might be associated with the accretion flow around the neutron star, and their evolution could provide insights into the behavior of matter in extreme conditions. Overall, the study highlights the importance of long-term monitoring of X-ray binaries to understand their complex behavior and dynamics.",2009-06-23,True
Total Differential Errors in Two-Port Network Analyser Measurements,"  Since S-parameter measurements without uncertainty cannot claim any
credibility, the uncertainties in full two-port Vector Network Analyser (VNA)
measurements were estimated using total complex differentials (Total
Differential Errors). To express precisely a comparison relation between
complex differential errors, their differential error regions (DERs) were used.
To demonstrate the method in the most accurate case of a direct zero-length
thru, practical results are presented for commonly used Z-parameters of a
simple, two-port, DC resistive T-network, which was built and tested against
frequency with a VNA measurement system extended by two lengthy transmission
lines.
",2015-06-03,False
Total Differential Errors in Two-Port Network Analyser Measurements,"This research paper investigates the sources of errors in two-port network analyzer measurements and their impact on the accuracy of total differential measurements. The paper presents a comprehensive analysis of the differential measurement errors arising from imperfect matching, non-ideal cable transmission, and phase errors. The results indicate that the total differential errors in two-port network analyzer measurements are significant and can adversely affect the accuracy of measurements. The paper concludes with recommendations for minimizing these errors to improve the accuracy of two-port network analyzer measurements for total differential measurements.",2015-06-03,True
"Continuous time random walk, Mittag-Leffler waiting time and fractional
  diffusion: mathematical aspects","  We show the asymptotic long-time equivalence of a generic power law waiting
time distribution to the Mittag-Leffler waiting time distribution,
characteristic for a time fractional CTRW. This asymptotic equivalence is
effected by a combination of ""rescaling"" time and ""respeeding"" the relevant
renewal process followed by a passage to a limit for which we need a suitable
relation between the parameters of rescaling and respeeding. Turning our
attention to spatially 1-D CTRWs with a generic power law jump distribution,
""rescaling"" space can be interpreted as a second kind of ""respeeding"" which
then, again under a proper relation between the relevant parameters leads in
the limit to the space-time fractional diffusion equation. Finally, we treat
the `time fractional drift"" process as a properly scaled limit of the counting
number of a Mittag-Leffler renewal process.
",2008-05-18,False
"Continuous time random walk, Mittag-Leffler waiting time and fractional
  diffusion: mathematical aspects","This research paper explores the mathematical aspects of a continuous time random walk (CTRW) model that incorporates Mittag-Leffler waiting time and fractional diffusion. The CTRW model is a stochastic process that describes the movement of particles in a random environment, while Mittag-Leffler waiting time is a probability distribution that characterizes the time between two successive jumps in the CTRW model. Fractional diffusion is a generalization of classical diffusion that accounts for anomalous transport phenomena, where the mean square displacement of particles grows sublinearly with time. The paper derives analytical expressions for the probability density function and the moments of the CTRW model with Mittag-Leffler waiting time and fractional diffusion, and investigates their asymptotic behavior. The results show that the CTRW model exhibits non-Gaussian and non-Markovian behavior, with long-range correlations and memory effects that are captured by the Mittag-Leffler waiting time and fractional diffusion. The paper discusses the implications of these findings for applications in physics, chemistry, biology, and finance, where CTRW models have been used to model diffusion processes in complex systems.",2008-05-18,True
"Lattice dynamics of the Heisenberg chain coupled to finite frequency
  bond phonons","  The phonon dynamics in a one dimensional Heisenberg spin chain coupled to
finite-frequency bond phonons is studied. We present the first detailed phonon
spectra for these systems using Quantum Monte Carlo. The quantum phase
transition is dominated by a central peak, yet the renormalisation of the main
phonon branch depends strongly on the bare phonon frequency omega_0. The main
branch remains largely unaffected at omega_0 \gsim J, but it softens completely
when omega_0 is low enough. This is an unusual scenario for a structural phase
transition and was observable only on sufficiently large systems. Approaching
the dimerized phase from finite temperature, the lattice dynamics mirrors the
behavior of a three dimensional system. For the efficient measurement of Greens
functions, we introduce a mapping from the stochastic series expansion to
continuous imaginary time.
",2007-05-23,False
"Lattice dynamics of the Heisenberg chain coupled to finite frequency
  bond phonons","This research paper examines the lattice dynamics of a Heisenberg chain coupled to finite frequency bond phonons. By employing a combination of analytical and numerical techniques, the authors investigate the effects of the coupling on the phonon spectrum and the spin dynamics of the Heisenberg chain. They find that the coupling leads to the emergence of a new type of phonon mode, which is strongly coupled to the spin chain and can affect its magnetic properties. The authors also observe interesting phenomena such as the suppression of the spin stiffness and the emergence of a spin-Peierls transition. Overall, this study sheds light on the intricate interplay between lattice vibrations and magnetic correlations in low-dimensional quantum systems.",2007-05-23,True
"Non-uniform convergence of two-photon decay rates for excited atomic
  states","  Two-photon decay rates in simple atoms such as hydrogenlike systems represent
rather interesting fundamental problems in atomic physics. The sum of the
energies of the two emitted photons has to fulfill an energy conservation
condition, the decay takes place via intermediate virtual states, and the total
decay rate is obtained after an integration over the energy of one of the
emitted photons. Here, we investigate cases with a virtual state having an
energy intermediate between the initial and the final state of the decay
process, and we show that due to non-uniform convergence, only a careful
treatment of the singularities infinitesimally displaced from the photon
integration contour leads to consistent and convergent results.
",2013-09-10,False
"Non-uniform convergence of two-photon decay rates for excited atomic
  states","The paper investigates the non-uniform convergence of two-photon decay rates for excited atomic states. The authors demonstrate that the decay rates do not necessarily converge uniformly, and they present a theoretical framework for understanding this phenomenon. They also provide numerical examples to illustrate the non-uniform convergence and show that it can have significant implications for experimental measurements. The paper concludes that careful consideration must be given to the non-uniform convergence of two-photon decay rates when interpreting experimental data and designing future experiments.",2013-09-10,True
"The Fermi-Pasta-Ulam problem: periodic orbits, normal forms and
  resonance overlap criteria","  Fermi, Pasta and Ulam observed, that the excitation of a low frequency normal
mode in a nonlinear acoustic chain leads to localization in normal mode space
on large time scales. Fast equipartition (and thus complete delocalization) in
the Fermi-Pasta-Ulam chain is restored if relevant intensive control parameters
exceed certain threshold values. We compare recent results on periodic orbits
(in the localization regime) and resonant normal forms (in a weak
delocalization regime), and relate them to various resonance overlap criteria.
We show that the approaches quantitatively agree in their estimate of the
localization-delocalization threshold. A key ingredient for this transition are
resonances of overtones.
",2009-11-13,False
"The Fermi-Pasta-Ulam problem: periodic orbits, normal forms and
  resonance overlap criteria","The research paper titled ""The Fermi-Pasta-Ulam problem: periodic orbits, normal forms and resonance overlap criteria"" discusses the famous problem in mathematical physics known as the Fermi-Pasta-Ulam problem. The paper focuses on the study of periodic orbits and normal forms in the context of the problem, and examines the criteria for resonance overlap. The authors use a combination of analytical and numerical methods to study the problem, and derive several key results and conclusions. One of the main themes of the paper is the importance of normal forms in understanding the dynamics of the problem. The authors show that the normal form can be used to identify resonances and predict the behavior of the system. They also derive new resonance overlap criteria that provide a more accurate prediction of the onset of chaos in the system. Overall, the paper provides a detailed analysis of the Fermi-Pasta-Ulam problem and offers important insights into the dynamics of nonlinear systems.",2009-11-13,True
Integrable Systems and Topology of Isospectral Manifolds,"  The well known Liouville-Arnold theorem says that if a level surface of
integrals of an integrable system is compact and connected, then it is a torus.
However, in some important examples of integrable systems the topology of a
level surface of integrals is quite complicated. This is due to the fact that
in these examples the phase space has points where either the Hamiltonian is
singular or the symplectic form is singular or degenerate. In such situations
the Liouville-Arnold theorem does not apply. However, sometimes it is possible
to define the corresponding flow on the whole level surface of integrals and
use this flow to investigate the topology. Tomei (1982) and Fried (1986) used
the Toda lattice to study the topology of the isospectral variety of Jacobi
matrices. We recall these results and we also expose new results concerning the
topology of the isospectral variety of zero-diagonal Jacobi matrices. This
topology is studied using the Volterra system.
",2009-11-13,False
Integrable Systems and Topology of Isospectral Manifolds,"This research paper explores the relationship between integrable systems and the topology of isospectral manifolds. The main objective of this study is to investigate the correspondence between the integrability of a system and the topology of the corresponding isospectral manifold. The paper also aims to determine the ways in which the topology of isospectral manifolds can be used to classify integrable systems. The study utilizes mathematical tools such as algebraic geometry, differential geometry, and topology to achieve these objectives. The key findings of this study include the identification of a connection between the topology of isospectral manifolds and the spectral data of integrable systems. The paper also demonstrates that the topology of isospectral manifolds can be used to classify integrable systems. In conclusion, this research paper reveals the fundamental relationship between integrable systems and the topology of isospectral manifolds, highlighting the potential of this approach in the study of integrable systems.",2009-11-13,True
"Electromagnetic field quantization in a magnetodielectric medium with
  external charges","  The electromagnetic field inside a cubic cavity filled up with a linear
magnetodielectric medium and in the presence of external charges is quantized
by modelling the magnetodielectric medium with two independent quantum fields.
Electric and magnetic polarization densities of the medium are defined in terms
of the ladder operators of the medium and eigenmodes of the cavity. Maxwell and
constitutive equations of the medium together with the equation of motion of
the charged particles have been obtained from the Heisenberg equations using a
minimal coupling scheme. Spontaneous emission of a two level atom embedded in a
magnetodielectric medium is calculated in terms of electric and magnetic
susceptibilities of the medium and the Green function of the cubic cavity as an
application of the model.
",2009-11-13,False
"Electromagnetic field quantization in a magnetodielectric medium with
  external charges","This research paper investigates the process of electromagnetic field quantization in magnetodielectric media with the presence of external charges. The primary focus is on developing a theoretical framework for quantization in such media, as well as examining the behavior of electromagnetic fields in magnetodielectric materials. The study also explores the fundamental principles of electromagnetic theory and their implications for quantization, with an emphasis on the role of external charges. The results of the research provide insights into the nature of electromagnetic fields in magnetodielectric media and their interaction with external charges, with potential applications in a wide range of fields, including materials science and engineering.",2009-11-13,True
Uniqueness and non-uniqueness of chains on half lines,"  We establish a one-to-one correspondence between one-sided and two-sided
regular systems of conditional probabilities on the half-line that preserves
the associated chains and Gibbs measures. As an application, we determine
uniqueness and non-uniqueness regimes in one-sided versions of ferromagnetic
Ising models with long range interactions. Our study shows that the interplay
between chain and Gibbsian theories yields more information than that contained
within the known theory of each separate framework. In particular: (i) A
Gibbsian construction due to Dyson yields a new family of chains with phase
transitions; (ii) these transitions show that a square summability uniqueness
condition of chains is false in the general non-shift-invariant setting, and
(iii) an uniqueness criterion for chains shows that a Gibbsian conjecture due
to Kac and Thompson is false in this half-line setting.
",2007-05-23,False
Uniqueness and non-uniqueness of chains on half lines,"This research paper focuses on the uniqueness and non-uniqueness of chains on half lines. In particular, the study investigates the conditions under which a chain on a half line is unique or non-unique. The paper employs a rigorous mathematical analysis to explore various scenarios that may lead to either uniqueness or non-uniqueness of chains. The findings of this research have significant applications in several fields, including physics, engineering, and mathematics. This study provides valuable insights into the behavior of chains on half lines, which can aid in the development of more accurate models and simulations in various applications.",2007-05-23,True
Dune formation on the present Mars,"  We apply a model for sand dunes to calculate formation of dunes on Mars under
the present Martian atmospheric conditions. We find that different dune shapes
as those imaged by Mars Global Surveyor could have been formed by the action of
sand-moving winds occuring on today's Mars. Our calculations show, however,
that Martian dunes could be only formed due to the higher efficiency of Martian
winds in carrying grains into saltation. The model equations are solved to
study saltation transport under different atmospheric conditions valid for
Mars. We obtain an estimate for the wind speed and migration velocity of
barchan dunes at different places on Mars. From comparison with the shape of
bimodal sand dunes, we find an estimate for the timescale of the changes in
Martian wind regimes.
",2009-11-13,False
Dune formation on the present Mars,"This research paper focuses on the formation of dunes on the present-day Mars. The study investigates the geological and atmospheric conditions that contribute to the formation of dunes, as well as the characteristics of the dunes themselves. By analyzing data from Mars Reconnaissance Orbiter, the research team has identified areas of active dune formation, which can provide insights into the planet's current climate and the potential for future exploration. The study also suggests that the dunes on Mars are more complex than previously thought, with a variety of shapes and sizes. The outcomes of this research can improve our understanding of Mars' geology and atmospheric conditions, which can contribute to future exploration and potentially support the search for life on the planet.",2009-11-13,True
"Set of equations for transient enhanced diffusion in shallow
  ion-implanted layers","  To simulate the transient enhanced diffusion near the surface or interface, a
set of equations describing the impurity diffusion and quasichemical reactions
of dopant atoms and point defects in ion-implanted layers is proposed and
analyzed. The diffusion equations obtained take into account different charge
states of mobile or immobile species and drift the mobile species in the
built-in electric field and field of elastic stresses. The absorption of
self-interstitials on the surface and drift of the defects due to elastic
stresses result in the nonuniform distributions of point defects. It was shown
analytically and by means of numerical calculations that consideration of the
nonuniform defect distributions enables one to explain the phenomenon of
""uphill"" impurity diffusion near the surface during annealing of ion-implanted
layers. The performed calculations of the boron concentration profile after
annealing of a shallow implanted layer agree well with the experimental data
confirming the efficiency of the proposed equations.
",2007-05-23,False
"Set of equations for transient enhanced diffusion in shallow
  ion-implanted layers","This research paper presents a set of equations for modeling transient enhanced diffusion in shallow ion-implanted layers. The model takes into account the effects of implant damage and annealing, and is validated using experimental data. The results show that the model accurately predicts the diffusion behavior in the implanted layers, which can be used to optimize ion implantation processes for semiconductor device fabrication.",2007-05-23,True
"k-dependent SU(4) model of high-temperature superconductivity and its
  coherent-state solutions","  We extend the SU(4) model [1-5] for high-Tc superconductivity to an SU(4)k
model that permits explicit momentum (k) dependence in predicted observables.
We derive and solve gap equations that depend on k, temperature, and doping
from the SU(4)k coherent states, and show that the new SU(4)k model reduces to
the original SU(4) model for observables that do not depend explicitly on
momentum. The results of the SU(4)k model are relevant for experiments such as
ARPES that detect explicitly k-dependent properties. The present SU(4)k model
describes quantitatively the pseudogap temperature scale and may explain why
the ARPES-measured T* along the anti-nodal direction is larger than other
measurements that do not resolve momentum. It also provides an immediate
microscopic explanation for Fermi arcs observed in the pseudogap region. In
addition, the model leads to a prediction that even in the underdoped regime,
there exist doping-dependent windows around nodal points in the k-space, where
antiferromagnetism may be completely suppressed for all doping fractions,
permitting pure superconducting states to exist.
",2009-11-13,False
"k-dependent SU(4) model of high-temperature superconductivity and its
  coherent-state solutions","This research paper presents a k-dependent SU(4) model of high-temperature superconductivity and its coherent-state solutions. The central focus of the study is to investigate the underlying mechanism of high-temperature superconductivity using a unified approach. The key findings suggest that the k-dependent SU(4) model provides an effective description of the high-temperature superconductivity phenomenon. Additionally, the coherent-state solutions reveal the emergence of nontrivial order parameters, which could play a crucial role in understanding the superconductivity mechanism. Overall, this study offers a valuable contribution to the field of condensed matter physics and sheds light on the nature of high-temperature superconductivity.",2009-11-13,True
Einstein's Theory of Gravity in the Presence of Pressure: A Review,"  The mysterious `dark energy' needed to explain the current observations,
poses a serious confrontation between fundamental physics and cosmology. The
present crisis may be an outcome of the (so far untested) prediction of the
general theory of relativity that the pressure of the matter source also
gravitates. In this view, a theoretical analysis reveals some surprising
inconsistencies and paradoxes faced by the energy-stress tensor (in the
presence of pressure) which is used to model the matter content of the
universe, including dark energy.
",2020-05-19,False
Einstein's Theory of Gravity in the Presence of Pressure: A Review,"This research paper provides a comprehensive review of Einstein's theory of gravity in the presence of pressure. The primary focus of the paper is to discuss the impact of pressure on the theory of gravity, including the effects on black holes, neutron stars, and the universe as a whole. The paper concludes that pressure plays a significant role in shaping the behavior of gravity, particularly in extreme environments. It also highlights the need for further research to fully understand the complex interplay between gravity and pressure.",2020-05-19,True
"A Metric for Gradient RG Flow of the Worldsheet Sigma Model Beyond First
  Order","  Tseytlin has recently proposed that an action functional exists whose
gradient generates to all orders in perturbation theory the Renormalization
Group (RG) flow of the target space metric in the worldsheet sigma model. The
gradient is defined with respect to a metric on the space of coupling constants
which is explicitly known only to leading order in perturbation theory, but at
that order is positive semi-definite, as follows from Perelman's work on the
Ricci flow. This gives rise to a monotonicity formula for the flow which is
expected to fail only if the beta function perturbation series fails to
converge, which can happen if curvatures or their derivatives grow large. We
test the validity of the monotonicity formula at next-to-leading order in
perturbation theory by explicitly computing the second-order terms in the
metric on the space of coupling constants. At this order, this metric is found
not to be positive semi-definite. In situations where this might spoil
monotonicity, derivatives of curvature become large enough for higher order
perturbative corrections to be significant.
",2008-11-26,False
"A Metric for Gradient RG Flow of the Worldsheet Sigma Model Beyond First
  Order","The research paper titled ""A Metric for Gradient RG Flow of the Worldsheet Sigma Model Beyond First Order"" presents a new method to calculate the gradient renormalization group (RG) flow of the worldsheet sigma model beyond first order. The sigma model is a mathematical model used to study string theory and other related fields. The authors propose a new metric that captures the non-perturbative effects of the RG flow and use it to calculate the RG flow of the sigma model up to second order. The main finding of the paper is that the new metric provides a more accurate description of the RG flow compared to previous methods. The authors also discuss the implications of their results for string theory and suggest possible directions for future research. Overall, the paper contributes to our understanding of the non-perturbative aspects of the RG flow in the sigma model and has potential applications in various areas of theoretical physics.",2008-11-26,True
"Enhancement of Noisy Planar Nuclear Medicine Images using Mean Field
  Annealing","  Nuclear medicine (NM) images inherently suffer from large amounts of noise
and blur. The purpose of this research is to reduce the noise and blur while
maintaining image integrity for improved diagnosis. The proposed solution is to
increase image quality after the standard pre- and post-processing undertaken
by a gamma camera system. Mean Field Annealing (MFA) is the image processing
technique used in this research. It is a computational iterative technique that
makes use of the Point Spread Function (PSF) and the noise associated with the
NM image. MFA is applied to NM images with the objective of reducing noise
while not compromising edge integrity. Using a sharpening filter as a
post-processing technique (after MFA) yields image enhancement of planar NM
images.
",2007-05-23,False
"Enhancement of Noisy Planar Nuclear Medicine Images using Mean Field
  Annealing","This research paper aims to improve the quality of noisy planar nuclear medicine images using a statistical method called mean field annealing. The study proposes a novel approach that utilizes a probabilistic model to estimate the underlying image from the noisy data. The algorithm was applied to simulated and real-world datasets, and the results were compared with other state-of-the-art methods. The findings show that mean field annealing can significantly enhance the image quality, especially in low signal-to-noise ratio scenarios. The study concludes that the proposed method can be a valuable tool for improving the diagnostic accuracy of planar nuclear medicine images.",2007-05-23,True
Conductance Spectroscopy of Spin-triplet Superconductors,"  We propose a novel experiment to identify the symmetry of superconductivity
on the basis of theoretical results for differential conductance of a normal
metal connected to a superconductor. The proximity effect from the
superconductor modifies the conductance of the remote current depending
remarkably on the pairing symmetry: spin-singlet or spin-triplet. The clear-cut
difference in the conductance is explained by symmetry of Cooper pairs in a
normal metal with respect to frequency. In the spin-triplet case, the anomalous
transport is realized due to an odd-frequency symmetry of Cooper pairs.
",2007-08-13,False
Conductance Spectroscopy of Spin-triplet Superconductors,"The paper titled ""Conductance Spectroscopy of Spin-triplet Superconductors"" discusses the use of conductance spectroscopy to study the properties of spin-triplet superconductors. The authors explain the concept of spin-triplet pairing and how it differs from conventional, spin-singlet pairing in superconductors. They then describe how conductance spectroscopy can be used to probe the energy gap and Andreev reflection in spin-triplet superconductors.

The authors present experimental data on the conductance spectra of several spin-triplet superconductors, including Sr2RuO4 and UCoGe. They compare the results to theoretical predictions and discuss the implications for understanding the nature of spin-triplet superconductivity.

Overall, the paper provides a detailed overview of the use of conductance spectroscopy in studying spin-triplet superconductors and sheds light on the unique properties of these materials. The authors conclude that conductance spectroscopy is a powerful tool for investigating the unconventional superconductivity of spin-triplet materials.",2007-08-13,True
"On the refractive index for a nonmagnetic two-component medium:
  resolution of a controversy","  The refractive index of a dielectric medium comprising both passive and
inverted components in its permittivity was determined using two methods: (i)
in the time domain, a finite-difference algorithm to compute the
frequency-domain reflectance from reflection data for a pulsed plane wave that
is normally incident on a dielectric half-space, and (ii) in the frequency
domain, the deflection of an obliquely incident Gaussian beam on transmission
through a dielectric slab. The dielectric medium was found to be an active
medium with a negative real part for its refractive index. Thereby, a recent
controversy in the scientific literature was resolved.
",2007-12-07,False
"On the refractive index for a nonmagnetic two-component medium:
  resolution of a controversy","This research paper aims to resolve a long-standing controversy regarding the refractive index for a nonmagnetic two-component medium. The study investigates the theoretical and experimental aspects of the refractive index and proposes a new methodology for its calculation. The results of the research show that the refractive index for a nonmagnetic two-component medium can be accurately determined using the proposed methodology. The findings of this study have significant implications for various fields, including optics, materials science, and engineering.",2007-12-07,True
"Exploring cloudy gas accretion as a source of interstellar turbulence in
  the outskirts of disks","  High--resolution 2D--MHD numerical simulations have been carried out to
investigate the effects of continuing infall of clumpy gas in extended HI
galactic disks. Given a certain accretion rate, the response of the disk
depends on its surface gas density and temperature. For Galactic conditions at
a galactocentric distance of ~20 kpc, and for mass accretion rates consistent
with current empirical and theoretical determinations in the Milky Way, the
rain of compact high velocity clouds onto the disk can maintain transonic
turbulent motions in the warm phase (~2500 K) of HI. Hence, the HI line width
is expected to be ~6.5 km/s for a gas layer at 2500 K, if infall were the only
mechanism of driving turbulence. Some statistical properties of the resulting
forcing flow are shown in this Letter. The radial dependence of the gas
velocity dispersion is also discussed.
",2009-11-13,False
"Exploring cloudy gas accretion as a source of interstellar turbulence in
  the outskirts of disks","This research paper explores the potential role of cloudy gas accretion as a source of interstellar turbulence in the outer regions of disks. Using numerical simulations, we investigate the behavior of the turbulent flow generated by the interaction of cloudy gas with the surrounding interstellar medium. Our results suggest that cloudy gas accretion can indeed contribute to the generation of turbulence in the outskirts of disks, with implications for the transport of material and the formation of stars in these regions. We discuss the implications of our findings for current models of disk evolution and suggest avenues for future observational and theoretical work in this area.",2009-11-13,True
"High-Resolution Scanning Tunneling Microscopy Imaging of Mesoscopic
  Graphene Sheets on an Insulating Surface","  We present scanning tunneling microscopy (STM) images of single-layer
graphene crystals examined under ultrahigh vacuum conditions. The samples, with
lateral dimensions on the micron scale, were prepared on a silicon dioxide
surface by direct exfoliation of single crystal graphite. The single-layer
films were identified using Raman spectroscopy. Topographic images of
single-layer samples display the honeycomb structure expected for the full
hexagonal symmetry of an isolated graphene monolayer. The absence of observable
defects in the STM images is indicative of the high quality of these films.
Crystals comprised of a few layers of graphene were also examined. They
exhibited dramatically different STM topography, displaying the reduced
three-fold symmetry characteristic of the surface of bulk graphite.
",2009-11-13,False
"High-Resolution Scanning Tunneling Microscopy Imaging of Mesoscopic
  Graphene Sheets on an Insulating Surface","This research paper presents high-resolution scanning tunneling microscopy (STM) imaging of mesoscopic graphene sheets on an insulating surface. The study demonstrates the ability to image graphene sheets with atomic resolution and high spatial resolution, allowing for detailed analysis of the graphene's morphology and electronic properties. The results show that the graphene sheets exhibit a high degree of structural stability and that their electronic properties are strongly influenced by the underlying insulating surface. The study provides new insights into the behavior of mesoscopic graphene sheets and highlights the potential of STM as a powerful tool for investigating the properties of two-dimensional materials. These findings have important implications for the development of novel graphene-based electronic devices and could contribute to the advancement of nanotechnology.",2009-11-13,True
"A Bell-Evans-Polanyi principle for molecular dynamics trajectories and
  its implications for global optimization","  The Bell-Evans-Polanyi principle that is valid for a chemical reaction that
proceeds along the reaction coordinate over the transition state is extended to
molecular dynamics trajectories that in general do not cross the dividing
surface between the initial and the final local minima at the exact transition
state. Our molecular dynamics Bell-Evans-Polanyi principle states that low
energy molecular dynamics trajectories are more likely to lead into the basin
of attraction of a low energy local minimum than high energy trajectories. In
the context of global optimization schemes based on molecular dynamics our
molecular dynamics Bell-Evans-Polanyi principle implies that using low energy
trajectories one needs to visit a smaller number of distinguishable local
minima before finding the global minimum than when using high energy
trajectories.
",2009-11-13,False
"A Bell-Evans-Polanyi principle for molecular dynamics trajectories and
  its implications for global optimization","This research paper proposes a new principle, called the Bell-Evans-Polanyi (BEP) principle, which can be applied to molecular dynamics trajectories. The BEP principle states that the activation energy for a reaction can be estimated from the minimum energy along the intrinsic reaction coordinate. The paper shows that this principle can be used to guide global optimization methods for finding the lowest energy conformations of molecules. The authors demonstrate the efficacy of this approach on several molecular systems and conclude that the BEP principle can provide a valuable tool for accelerating global optimization algorithms in computational chemistry.",2009-11-13,True
"Characteristics of Switchable Superconducting Flux Transformer with DC
  Superconducting Quantum Interference Device","  We have investigated the flux transfer characteristics of a switchable flux
transformer comprising a superconducting loop and a DC superconducting quantum
interference device (DC-SQUID). This system can be used to couple multiple flux
qubits with a controllable coupling strength. Its characteristics were measured
using a flux input coil and a DC-SQUID for readout coupled to the transformer
loop in a dilution refrigerator. The observed characteristics are consistent
with the calculation results. We have demonstrated the reversal of the slope of
the characteristics and the complete switching off of the transformer, which
are useful features for its application as a controllable coupler for flux
qubits.
",2007-05-23,False
"Characteristics of Switchable Superconducting Flux Transformer with DC
  Superconducting Quantum Interference Device","This research paper discusses the characteristics of a switchable superconducting flux transformer (SSFT) with a DC superconducting quantum interference device (SQUID). The SSFT has been designed to operate in two modes: the transformer mode and the inductor mode. In the transformer mode, the SSFT behaves as a step-up transformer, while in the inductor mode, it behaves as an inductor. The SSFT has been fabricated using YBa2Cu3O7 (YBCO) thin films. The results show that the SSFT has a high coupling coefficient and a low self-inductance in the transformer mode, and a high self-inductance in the inductor mode. The SSFT also exhibits a large magnetic flux modulation range and a low flux noise level. These characteristics make the SSFT suitable for applications in high-sensitivity magnetic field measurements and superconducting electronics. The study concludes that the SSFT with a DC SQUID can be a potential candidate for various superconducting devices and systems.",2007-05-23,True
Simulation via Direct Computation of Partition Functions,"  In this paper, we demonstrate the efficiency of simulations via direct
computation of the partition function under various macroscopic conditions,
such as different temperatures or volumes. The method can compute partition
functions by flattening histograms, through the Wang-Landau recursive scheme,
outside the energy space. This method offers a more general and flexible
framework for handling various types of ensembles, especially the ones in which
computation of the density of states is not convenient. It can be easily scaled
to large systems, and it is flexible in incorporating Monte Carlo cluster
algorithms or molecular dynamics. High efficiency is shown in simulating large
Ising models, in finding ground states of simple protein models, and in
studying the liquid-vapor phase transition of a simple fluid. The method is
very simple to implement and we expect it to be efficient in studying complex
systems with rugged energy landscapes, e.g., biological macromolecules.
",2011-11-09,False
Simulation via Direct Computation of Partition Functions,"The research paper titled ""Simulation via Direct Computation of Partition Functions"" explores the use of Monte Carlo simulation to calculate partition functions, which are important in statistical physics and chemistry. The authors propose a new method, called the direct calculation method, which eliminates the need for importance sampling and provides accurate results for large systems. The key finding of the study is that the direct calculation method can be used to efficiently calculate partition functions for systems of various sizes and complexities. The authors conclude that this method has the potential to significantly improve the accuracy and efficiency of Monte Carlo simulations in the field of statistical physics.",2011-11-09,True
"Preferential Detachment in Broadcast Signaling Networks: Connectivity
  and Cost Trade-off","  We consider a network of nodes distributed in physical space without physical
links communicating through message broadcasting over specified distances.
Typically, communication using smaller distances is desirable due to savings in
energy or other resources. We introduce a network formation mechanism to enable
reducing the distances while retaining connectivity. Nodes, which initially
transmit signals at a prespecified maximum distance, subject links to
preferential detachment by autonomously decreasing their transmission radii
while satisfying conditions of zero communication loss and fixed maximum
node-hopping distance for signaling. Applied to networks with various spatial
topologies, we find cost reductions as high as 90% over networks that are
restricted to have all nodes with equal transmission distance.
",2009-11-13,False
"Preferential Detachment in Broadcast Signaling Networks: Connectivity
  and Cost Trade-off","The research paper titled ""Preferential Detachment in Broadcast Signaling Networks: Connectivity and Cost Trade-off"" investigates how the preferential attachment mechanism affects the connectivity and cost of broadcast signaling networks. The study uses simulations to model the network growth process and evaluate its impact on network structure. The main finding of the study is that preferential attachment can lead to high connectivity but also increases the cost of maintaining the network. The paper suggests that a balance between connectivity and cost is necessary to optimize the network's performance. The study's conclusion highlights the importance of understanding the underlying mechanisms that govern network growth to design efficient and effective broadcast signaling networks.",2009-11-13,True
"Two Dimensional Quantum Well of Gluons in Color Ferromagnetic Quark
  Matter","  We have recently pointed out that color magnetic field is generated in dense
quark matter, i.e. color ferromagnetic phase of quark matter. Using light cone
quantization, we show that gluons occupying the lowest Landau level under the
color magnetic field effectively form a two dimensional quantum well (layer),
in which infinitely many zero modes of the gluons are present. We discuss that
the zero modes of the gluons form a quantum Hall state by interacting
repulsively with each other, just as electrons do in semiconductors. Such a
ferromagnetic quark matter with the layer structure of the gluons is a possible
origin of extremely strong magnetic field observed in magnetars.
",2007-05-23,False
"Two Dimensional Quantum Well of Gluons in Color Ferromagnetic Quark
  Matter","This research paper investigates the behavior of gluons in a two-dimensional quantum well of color ferromagnetic quark matter. The study uses lattice QCD simulations to analyze the gluon condensates and the spectrum of excitations. The results suggest that the gluon condensates are enhanced in the presence of color ferromagnetic quark matter, and the spectrum of excitations shows a gap. These findings provide insights into the strong interaction dynamics of quark-gluon plasma and may have implications for the study of high-energy heavy-ion collisions.",2007-05-23,True
A discrete computer network model with expanding dimensions,"  Complex networks with expanding dimensions are studied, where the networks
may be directed and weighted, and network nodes are varying in discrete time in
the sense that some new nodes may be added and some old nodes may be removed
from time to time. A model of such networks in computer data transmission is
discussed. Each node on the network has fixed dimensionality, while the
dimension of the whole network is defined by the total number of nodes. Based
on the spectacular properties of data transmission on computer networks, some
new concepts of stable and unstable networks differing from the classical
Lyapunov stability are defined. In particular, a special unstable network
model, called devil network, is introduced and discussed. It is further found
that a variety of structures and connection weights affects the network
stability substantially. Several criteria on stability, instability, and devil
network are established for a rather general class of networks, where some
conditions are actually necessary and sufficient. Mathematically, this paper
makes a first attempt to rigorously formulate a fundamental issue of modeling
discrete linear time-varying systems with expanding dimensions and study their
basic stability property.
",2007-05-23,False
A discrete computer network model with expanding dimensions,"This research paper presents a new discrete computer network model with expanding dimensions. The model captures the growth of a network over time, allowing for the addition of new nodes and edges as the network expands. The model is based on a dynamic graph structure and includes a set of rules for adding new nodes and edges. We conduct experiments to validate the model and demonstrate its ability to capture the dynamics of real-world networks. We also derive a set of theoretical results, including the degree distribution and clustering coefficient, which can be used to analyze the properties of the network as it expands. Our results show that the model accurately captures the behavior of real-world networks, and provides a useful tool for studying the growth and evolution of complex systems.",2007-05-23,True
The Multiobjective Optimization of a Prismatic Drive,"  The multiobjective optimization of Slide-o-Cam is reported in this paper.
Slide-o-Cam is a cam mechanism with multiple rollers mounted on a common
translating follower. This transmission provides pure-rolling motion, thereby
reducing the friction of rack-and-pinions and linear drives. A Pareto frontier
is obtained by means of multiobjective optimization. This optimization is based
on three objective functions: (i) the pressure angle, which is a suitable
performance index for the transmission because it determines the amount of
force transmitted to the load vs. that transmitted to the machine frame; (ii)
the Hertz pressure used to evaluate the stresses produced on the contact
surface between cam and roller; and (iii) the size of the mechanism,
characterized by the number of cams and their width.
",2007-05-23,False
The Multiobjective Optimization of a Prismatic Drive,"This research paper focuses on the multiobjective optimization of a prismatic drive. The study aims to identify the optimal combination of design parameters that would simultaneously satisfy multiple performance objectives. The proposed methodology is based on the integration of a genetic algorithm and a finite element analysis. The results show that the optimized prismatic drive design can achieve significant improvements in both its static and dynamic performance attributes. The critical outcomes of this study include a better understanding of the complex interaction between design parameters, the development of an efficient optimization methodology for prismatic drives, and the identification of the optimal design for multiobjective optimization. These findings have significant implications for the design and optimization of prismatic drives in various applications.",2007-05-23,True
Environment Dependent Charge Potential for Water,"  We present a new interatomic potential for water captured in a
charge-transfer embedded atom method (EAM) framework. The potential accounts
for explicit, dynamical charge transfer in atoms as a function of the local
chemical environment. As an initial test of the charge-transfer EAM approach
for a molecular system, we have constructed a relatively simple version of the
potential and examined its ability to model the energetics of small water
clusters. The excellent agreement between our results and current experimental
and higher-level quantum computational data signifies a successful first step
towards developing a unified charge-transfer potential capable of accurately
describing the polymorphs, dynamics, and complex thermodynamic behavior of
water.
",2007-05-23,False
Environment Dependent Charge Potential for Water,"This research paper presents an environment-dependent charge potential (EDCP) model for water that considers the influence of the surrounding environment on the charge distribution of water molecules. The EDCP model is based on a polarizable force field and takes into account the electrostatic polarization and dispersion interactions between water molecules and their surroundings. The EDCP model was found to accurately predict the properties of water in different environments, such as bulk water, ice, and water near a charged surface. The results suggest that the EDCP model can provide a more accurate description of water behavior in various environments and could potentially lead to the development of more efficient computational models for studying complex systems involving water.",2007-05-23,True
A real convexity theorem for quasi-hamiltonian actions,"  The main result of this paper is a quasi-hamiltonian analogue of a special
case of the O'Shea-Sjamaar convexity theorem for usual momentum maps. We denote
by U a simply connected compact connected Lie group and we fix an involutive
automorphism of maximal rank on this Lie group (such an automorphism always
exists). We then denote by M a quasi-hamiltonian U-space and we prove that the
image under the momentum map of the fixed-point set of a form-reversing
compatible involution of M is a convex polytope, which is in fact equal to the
full momentum polytope. This theorem was announced in arXiv:math/0609517v1. As
an application, we obtain an example of lagrangian subspace in representation
spaces of surface groups.
",2007-05-23,False
A real convexity theorem for quasi-hamiltonian actions,"This research paper presents a new real convexity theorem for quasi-Hamiltonian actions, which provides a framework for studying the geometry of symplectic manifolds. The theorem is proven using a combination of geometric and algebraic techniques, and its implications are discussed in the context of several examples. The primary theme of the paper is to establish a rigorous mathematical foundation for studying quasi-Hamiltonian actions and to demonstrate the usefulness of the real convexity theorem in this context. The essential finding of the paper is that the real convexity theorem provides a powerful tool for analyzing the geometric properties of quasi-Hamiltonian actions, which has important implications for understanding the behavior of physical systems in symplectic manifolds. The paper concludes with a discussion of future directions for research in this area.",2007-05-23,True
Coherent dynamics of photoinduced nucleation processes,"  We study the dynamics of initial nucleation processes of photoinduced
structural change of molecular crystals. In order to describe the nonadiabatic
transition in each molecule, we employ a model of localized electrons coupled
with a fully quantized phonon mode, and the time-dependent Schr\""odinger
equation for the model is numerically solved. We found a minimal model to
describe the nucleation induced by injection of an excited state of a single
molecule in which multiple types of intermolecular interactions are required.
In this model coherently driven molecular distortion plays an important role in
the successive conversion of electronic states which leads to photoinduced
cooperative phenomena.
",2009-11-13,False
Coherent dynamics of photoinduced nucleation processes,This research paper explores the coherent dynamics of photoinduced nucleation processes in a wide range of materials. The primary focus is on understanding the nucleation process and the role of coherence in it. The study employs a combination of experimental and theoretical approaches to analyze the dynamics of nucleation. The findings suggest that coherence plays a crucial role in the nucleation process and affects the nucleation rate and size distribution of the nuclei. The study concludes that a better understanding of the coherence effects in nucleation can lead to the optimization of materials for various applications.,2009-11-13,True
Tuning the shape of semiconductor microstadium laser,"  We presented a detailed experimental study on lasing in GaAs microstadium
with various shapes. Unlike most deformed microcavities, the lasing threshold
varies non-monotonically with the major-to-minor-axis ratio of the stadium.
Under spatially uniform optical pumping, the first lasing mode corresponds to a
high-quality scar mode consisting of several unstable periodic orbits. By
tuning the shape of GaAs stadium, we are able to minimize the lasing threshold.
This work demonstrates the possibility of controlling chaotic microcavity
laser.
",2007-05-23,False
Tuning the shape of semiconductor microstadium laser,"This research paper focuses on the tuning of the shape of a semiconductor microstadium laser. The study investigates the impact of changes in the geometry of the microstadium on its lasing properties. The research team utilizes simulations to explore the effects of various design parameters such as the radius and width of the stadium. The results show that the shape of the microstadium has a significant impact on the laser's performance, particularly in terms of its threshold current density and output power. The conclusions of the study suggest that tuning the shape of the microstadium is a promising approach for optimizing the performance of semiconductor lasers.",2007-05-23,True
Gauge Mediation with D-term SUSY Breaking,"  We construct a gauge-mediation model with a D-term supersymmetry (SUSY)
breaking. R-symmetry breaking necessary for generating the SUSY standard-model
gaugino masses is given by gaugino condensation of a strongly coupled gauge
theory in the hidden sector. The energy scale of the strong dynamics of the
hidden sector gauge theory should be around the messenger mass scale M, or
otherwise perturbative calculations would be reliable and would lead to
negative soft mass squared for squarks and sleptons. Thus, all the mass scales
are controlled by a virtually single parameter, \sqrt{D}/M. This model covers a
very wide range of gravitino mass, m_{3/2} \simeq 1 eV--100 TeV. Possible
embeddings of the model in string theory are also discussed.
",2008-11-26,False
Gauge Mediation with D-term SUSY Breaking,"The research paper ""Gauge Mediation with D-term SUSY Breaking"" focuses on exploring the effects of D-term supersymmetry (SUSY) breaking in gauge-mediated SUSY breaking scenarios. The study presents a comprehensive analysis of the resulting mass spectra for both the Standard Model and the Minimal Supersymmetric Standard Model (MSSM) and identifies the regions of parameter space where the D-term contributions are significant. The remarkable finding of the study is that D-term SUSY breaking can significantly alter the mass spectra of the MSSM, leading to non-standard phenomenology that can be probed at future collider experiments. The study concludes that incorporating D-term SUSY breaking in gauge mediation scenarios can lead to a richer and more diverse set of phenomenological signatures that can shed light on the fundamental nature of supersymmetry.",2008-11-26,True
"Infinite loop superalgebras of the Dirac theory on the Euclidean
  Taub-NUT space","  The Dirac theory in the Euclidean Taub-NUT space gives rise to a large
collection of conserved operators associated to genuine or hidden symmetries.
They are involved in interesting algebraic structures as dynamical algebras or
even infinite-dimensional algebras or superalgebras. One presents here the
infinite-dimensional superalgebra specific to the Dirac theory in manifolds
carrying the Gross-Perry-Sorkin monopole. It is shown that there exists an
infinite-dimensional superalgebra that can be seen as a twisted loop
superalgebra.
",2008-11-26,False
"Infinite loop superalgebras of the Dirac theory on the Euclidean
  Taub-NUT space","The research paper titled ""Infinite loop superalgebras of the Dirac theory on the Euclidean Taub-NUT space"" focuses on the study of infinite-dimensional loop algebras and their relation to the Dirac theory on the Euclidean Taub-NUT space. The main objective of the study is to understand the algebraic structure of the loop superalgebras and their representation theory. The researchers use a combination of mathematical techniques such as Lie theory, representation theory, and algebraic topology to achieve their objectives.

The study shows that the loop superalgebras associated with the Dirac theory on the Euclidean Taub-NUT space have a rich algebraic structure, which can be understood through their representation theory. The researchers demonstrate that the infinite-dimensional loop algebras can be decomposed into irreducible representations, which are related to the topology of the underlying space. They also show that the loop superalgebras have a natural action on certain cohomology groups, which provides a connection between algebra and topology.

The study concludes that the infinite loop superalgebras of the Dirac theory on the Euclidean Taub-NUT space have a rich algebraic structure, which is closely related to the topology of the underlying space. The researchers suggest that their findings can have important implications for the study of other physical theories and mathematical structures.",2008-11-26,True
Demixing and orientational ordering in mixtures of rectangular particles,"  Using scaled-particle theory for binary mixtures of two-dimensional hard
particles with rotational freedom, we analyse the stability of nematic phases
and the demixing phase behaviour of a variety of mixtures, focussing on cases
where at least one of the components consists of hard rectangles or hard
squares. A pure fluid of hard rectangles may exhibit, aside from the usual
uniaxial nematic phase, an additional (tetratic) oriented phase, possessing two
directors, which is the analogue of the biaxial or cubatic phases in three-
dimensional fluids. There is computer simulation evidence that the tetratic
phase might be stable with respect to phases with spatial order for rectangles
with low aspect ratios. As hard rectangles are mixed with other particles not
possessing stable tetratic order by themselves, the tetratic phase is
destabilised, via a first- or second-order phase transition, to uniaxial
nematic or isotropic phases; for hard rectangles of low aspect ratio tetratic
order persists in a relatively large range of volume fractions. The order of
these transitions depends on the particle geometry, dimensions and
thermodynamic conditions of the mixture. The second component of the mixture
has been chosen to be hard discs or disco-rectangles, the geometry of which is
different from that of rectangles, leading to packing frustration and demixing
behaviour, or simply rectangles of different aspect ratio. These mixtures may
be good candidates for observing thermodynamically stable tetratic phases in
monolayers of hard particles. Finally, demixing between fluid
(isotropic--tetratic or tetratic--tetratic) phases is seen to occur in mixtures
of hard squares of different sizes when the size ratio is sufficiently large.
",2009-11-13,False
Demixing and orientational ordering in mixtures of rectangular particles,"This research paper investigates the demixing and orientational ordering of mixtures of rectangular particles. The main objectives of this study are to understand the effect of particle shape and size on demixing and to explore the emergence of orientational order in the system. The research findings demonstrate that particle shape and size play a critical role in the demixing process, with larger particles exhibiting stronger demixing tendencies. Additionally, the study reveals that orientational ordering in the system is influenced by the presence of both size and shape asymmetry. Overall, this research contributes to a better understanding of the fundamental physics of particle mixtures and has potential implications for the design of functional materials.",2009-11-13,True
Wave interference effect on polymer microstadium laser,"  We investigate the lasing modes in fully chaotic polymer microstadiums under
optical pumping. The lasing modes are regularly spaced in frequency, and their
amplitudes oscillate with frequency. Our numerical simulations reveal that the
lasing modes are multi-orbit scar modes. The interference of partial waves
propagating along the constituent orbits results in local maxima of quality
factor at certain frequencies. The observed modulation of lasing mode amplitude
with frequency results from the variation of quality factor, which provides the
direct evidence of wave interference effect in open chaotic microcavities.
",2009-11-13,False
Wave interference effect on polymer microstadium laser,"This research paper investigates the effect of wave interference on the performance of a polymer microstadium laser. The primary theme focuses on the impact of the interference on the laser's output power, quality factor, and threshold. The study found that the wave interference significantly affects the laser's characteristics, indicating the need for precise control over the laser's dimensions and positioning. The research concludes that wave interference can be utilized to enhance the laser's performance and tailor its emission properties for specific applications.",2009-11-13,True
"Relativistic Tennis with Photons: Demonstration of Frequency Upshifting
  by a Relativistic Flying Mirror through Two Colliding Laser Pulses","  Since the advent of chirped pulse amplification1 the peak power of lasers has
grown dramatically and opened the new branch of high field science, delivering
the focused irradiance, electric fields of which drive electrons into the
relativistic regime. In a plasma wake wave generated by such a laser,
modulations of the electron density naturally and robustly take the shape of
paraboloidal dense shells, separated by evacuated regions, moving almost at the
speed of light. When we inject another counter-propagating laser pulse, it is
partially reflected from the shells, acting as relativistic flying
(semi-transparent) mirrors, producing an extremely time-compressed
frequency-multiplied pulse which may be focused tightly to the diffraction
limit. This is as if the counterstreaming laser pulse bounces off a
relativistically swung tennis racket, turning the ball of the laser photons
into another ball of coherent X-ray photons but with a form extremely
relativistically compressed to attosecond and zeptosecond levels. Here we
report the first demonstration of the frequency multiplication detected from
the reflection of a weak laser pulse in the region of the wake wave generated
by the driver pulse in helium plasma. This leads to the possibility of very
strong pulse compression and extreme coherent light intensification. This
Relativistic Tennis with photon beams is demonstrated leading to the
possibility toward reaching enormous electromagnetic field intensification and
finally approaching the Schwinger field, toward which the vacuum nonlinearly
warps and eventually breaks, producing electron-positron pairs.
",2013-05-29,False
"Relativistic Tennis with Photons: Demonstration of Frequency Upshifting
  by a Relativistic Flying Mirror through Two Colliding Laser Pulses","The research paper titled ""Relativistic Tennis with Photons: Demonstration of Frequency Upshifting by a Relativistic Flying Mirror through Two Colliding Laser Pulses"" explores the concept of using a relativistic flying mirror to upshift the frequency of photons. The method involves colliding two laser pulses, resulting in a relativistic flying mirror that reflects the incident photons and upshifts their frequency. The study found that the frequency upshifting effect is observable and can be used in various applications such as high-energy physics and astrophysics. Overall, the research provides a new way to manipulate photons and could lead to advancements in photonics technology.",2013-05-29,True
Modelling long-term trends in lunar exposure to the Earth's plasmasheet,"  This paper shows how the exposure of the Moon to the Earth's plasmasheet is
subject to decadal variations due to lunar precession. The latter is a key
property of the Moon's apparent orbit around the Earth - the nodes of that
orbit precess around the ecliptic, completing one revolution every 18.6 years.
This precession is responsible for a number of astronomical phenomena, e.g. the
year to year drift of solar and lunar eclipse periods. It also controls the
ecliptic latitude at which the Moon crosses the magnetotail and thus the number
and duration of lunar encounters with the plasmasheet. This paper presents a
detailed model of those encounters and applies it to the period 1960 to 2030.
This shows that the total lunar exposure to the plasmasheet will vary from 10
hours per month at a minimum of the eighteen-year cycle rising to 40 hours per
month at the maximum. These variations could have a profound impact on the
accumulation of charge due plasmasheet electrons impacting the lunar surface.
Thus we should expect the level of lunar surface charging to vary over the
eighteen-year cycle. The literature contains reports that support this: several
observations made during the cycle maximum of 1994-2000 are attributed to
bombardment and charging of the lunar surface by plasmasheet electrons. Thus we
conclude that lunar surface charging will vary markedly over an eighteen-year
cycle driven by lunar precession. It is important to interpret lunar
environment measurements in the context of this cycle and to allow for the
cycle when designing equipment for deployment on the lunar surface. This is
particularly important in respect of developing plans for robotic exploration
on the lunar surface during the next cycle maximum of 2012-19.
",2015-05-13,False
Modelling long-term trends in lunar exposure to the Earth's plasmasheet,"This research paper aims to investigate and model the long-term trends in lunar exposure to the Earth's plasmasheet. The plasmasheet is a region of the Earth's magnetosphere where plasma particles are trapped and accelerated by the Earth's magnetic field. These particles interact with the lunar surface, causing a range of effects, including surface charging, sputtering, and erosion. The study will use data from various spacecraft missions, including the Lunar Prospector and Lunar Reconnaissance Orbiter, to model the plasmasheet's behavior over several decades. The research will provide insights into the long-term effects of the Earth's magnetosphere on the lunar surface, which could have implications for future lunar missions and exploration.",2015-05-13,True
"Synchronization of Excitatory Neurons with Strongly Heterogeneous Phase
  Responses","  In many real-world oscillator systems, the phase response curves are highly
heterogeneous. However, dynamics of heterogeneous oscillator networks has not
been seriously addressed. We propose a theoretical framework to analyze such a
system by dealing explicitly with the heterogeneous phase response curves. We
develop a novel method to solve the self-consistent equations for order
parameters by using formal complex-valued phase variables, and apply our theory
to networks of in vitro cortical neurons. We find a novel state transition that
is not observed in previous oscillator network models.
",2009-11-13,False
"Synchronization of Excitatory Neurons with Strongly Heterogeneous Phase
  Responses","This research paper investigates the synchronization of excitatory neurons with heterogeneous phase responses. The primary theme of the paper is to understand how strongly heterogeneous phase responses affect the synchronization of neuronal networks. The study finds that the degree of heterogeneity in phase response significantly impacts the synchronization behavior of the neurons, and the synchronization can be improved by adjusting the strength and timing of excitatory inputs. The research concludes that understanding the underlying mechanisms of synchronization in heterogeneous networks can have important implications for developing therapeutic strategies for neurological disorders.",2009-11-13,True
Synchrotron Radiation in the Standard Model Extension,"  We obtain a system of exact solutions of the Dirac equation for an electron
moving in a constant homogeneous external magnetic field with account of its
vacuum magnetic moment and assumed Lorentz invariance violation in the minimal
CPT-odd form in the framework of the Standard Model Extension. Using these
solutions, characteristics of the particle synchrotron radiation are
calculated, and possible observable effects caused by the Lorentz non-invariant
interaction are described. We demonstrate that the angular distribution of the
radiation has specific asymmetry, which can be explained as a consequence of
non-conservation of transversal electron polarization in the presence of a
background Lorentz non-invariant condensate field.
",2008-11-26,False
Synchrotron Radiation in the Standard Model Extension,"The Standard Model Extension (SME) is an extension of the Standard Model of particle physics that includes Lorentz violation. Synchrotron radiation is the emission of electromagnetic radiation by charged particles moving through a magnetic field. This paper focuses on the calculation of synchrotron radiation within the context of the SME. The authors find that the presence of Lorentz violation affects the energy spectrum and polarization of the emitted radiation. They also discuss the potential for using synchrotron radiation to test for Lorentz violation in the SME. Overall, the paper provides a theoretical framework for studying synchrotron radiation in the context of the SME and highlights the potential for using synchrotron radiation experiments to test for Lorentz violation.",2008-11-26,True
A Review of Maser Polarization and Magnetic Fields,"  Through polarization observations masers are unique probes of the magnetic
field in a variety of different astronomical objects, with the different maser
species tracing different physical conditions. In recent years maser
polarization observations have provided insights in the magnetic field strength
and morphology in, among others, the envelopes around evolved stars, Planetary
Nebulae (PNe), massive star forming regions and supernova remnants. More
recently, maser observations have even been used to determine the magnetic
field in megamaser galaxies. This review will present an overview of maser
polarization observations and magnetic field determinations of the last several
years and discuss the implications of the magnetic field measurements for
several important fields of study, such as aspherical PNe creation and massive
star formation.
",2009-11-13,False
A Review of Maser Polarization and Magnetic Fields,"This review paper focuses on the current understanding of maser polarization and its relation to magnetic fields. It highlights the significant progress that has been made in recent years in observing and interpreting polarization in different maser types, including water, OH, and methanol masers. The paper also discusses the use of maser polarization as a diagnostic tool for studying magnetic fields in different astrophysical environments, such as star-forming regions and evolved stars. The review concludes with an outlook on the future prospects for maser polarization observations and their potential implications for understanding the magnetic universe.",2009-11-13,True
Ds0*(2317) and Ds1(2460) mesons in two-body B-meson decays,"  We analyze the branching ratios of B to D(*) + Ds0*(Ds1) decays using the
factorization hypothesis. The B to D(*) transition form factors are taken from
a model-independent analysis done by Caprini, Lellouch and Neubert based on
heavy quark spin symmetry and dispersive constraints, including short-distance
and power corrections. The leptonic decay constants fDs0* and fDs1 are
calculated assuming a molecular structure for the Ds0* and Ds1 mesons. The
calculated branching ratios of B-meson two-body decays are compared with
experimental data and other theoretical results.
",2008-11-26,False
Ds0*(2317) and Ds1(2460) mesons in two-body B-meson decays,"This research paper aims to investigate the role of Ds0*(2317) and Ds1(2460) mesons in two-body B-meson decays. The study is motivated by the recent discovery of these mesons and their potential impact on the decay processes of B mesons. Using data collected by the LHCb experiment, the paper analyzes the branching fractions and angular distributions of two-body B-meson decays involving Ds0*(2317) and Ds1(2460) mesons. The results provide new insights into the properties of these mesons and their contribution to B-meson decays. The findings have implications for the understanding of the strong interaction and the Standard Model of particle physics.",2008-11-26,True
Electrostatic Interactions of Asymmetrically Charged Membranes,"  We predict the nature (attractive or repulsive) and range (exponentially
screened or long-range power law) of the electrostatic interactions of
oppositely charged and planar plates as a function of the salt concentration
and surface charge densities (whose absolute magnitudes are not necessarily
equal). An analytical expression for the crossover between attractive and
repulsive pressure is obtained as a function of the salt concentration. This
condition reduces to the high-salt limit of Parsegian and Gingell where the
interaction is exponentially screened and to the zero salt limit of Lau and
Pincus in which the important length scales are the inter-plate separation and
the Gouy-Chapman length. In the regime of low salt and high surface charges we
predict - for any ratio of the charges on the surfaces - that the attractive
pressure is long-ranged as a function of the spacing. The attractive pressure
is related to the decrease in counter-ion concentration as the inter-plate
distance is decreased. Our theory predicts several scaling regimes with
different scaling expressions for the pressure as function of salinity and
surface charge densities. The pressure predictions can be related to surface
force experiments of oppositely charged surfaces that are prepared by coating
one of the mica surfaces with an oppositely charged polyelectrolyte.
",2012-01-31,False
Electrostatic Interactions of Asymmetrically Charged Membranes,"This research paper investigates the electrostatic interactions between asymmetrically charged membranes. The study reveals that the interaction between oppositely charged membranes is stronger than that of similarly charged membranes, and membrane asymmetry enhances this effect. Furthermore, the researchers discovered a critical charge ratio at which the electrostatic interactions become repulsive. The findings provide insight into membrane-membrane interactions and have implications for various biological and technological applications.",2012-01-31,True
"Origin of the early-type R stars: a binary-merger solution to a
  century-old problem?","  The early-R stars are carbon-rich K-type giants. They are enhanced in C12,
C13 and N14, have approximately solar oxygen, magnesium isotopes, s-process and
iron abundances, have the luminosity of core-helium burning stars, are not
rapid rotators, are members of the Galactic thick disk and, most peculiarly of
all, are all single stars. Conventional single-star stellar evolutionary models
cannot explain such stars, but mergers in binary systems have been proposed to
explain their origin.
  We have synthesized binary star populations to calculate the number of merged
stars with helium cores which could be early-R stars. We find many possible
evolutionary channels. The most common of which is the merger of a helium white
dwarf with a hydrogen-burning red giant branch star during a common envelope
phase followed by a helium flash in a rotating core which mixes carbon to the
surface. All the channels together give ten times more early-R stars than we
require to match recent Hipparcos observations - we discuss which channels are
likely to be the true early-R stars and which are not. For the first time we
have constructed a viable model of the early-R stars with which we can test
some of our ideas regarding common envelope evolution in giants, stellar
mergers, rotation, the helium flash and the origin of the early-R stars.
",2009-11-13,False
"Origin of the early-type R stars: a binary-merger solution to a
  century-old problem?","The origin of early-type R stars has been a century-old problem in astrophysics. In this research paper, we propose a binary-merger solution to this problem. The main objective of this study is to investigate whether binary-merger events could explain the observed properties of early-type R stars. We present detailed hydrodynamical simulations of binary-merger events, and we compare the results to the properties of early-type R stars. Our simulations show that binary-merger events can reproduce the observed properties of early-type R stars, including their enhanced surface abundances and pulsational behavior. We also find that the merger process can lead to the formation of rapidly rotating stars, which could explain the high projected rotational velocities observed in some early-type R stars. Our study provides a new and promising explanation for the origin of early-type R stars and suggests that binary-merger events could play an important role in the evolution of massive stars.",2009-11-13,True
C-symmetric quantization of fields leading to a natural normal ordering,"  At the quantization of fields, due to the non-linear character of the time
reversal, the creation-annihilation operators for the negative frequency modes
should be replaced to the operators of antiparticles not directly in the field
operators, but in the operator products. For the standard minimal Lagrangians
(asymmetrical under the complex conjugated fields) it is shown that the charge
conjugation (C-) symmetry conditions for the Hamiltonian and the charge
operator lead to the identities for the operator products allowing one to
replace the negative frequency operator products to the positive frequency
ones. At the same time the operators in observables become normal ordered and
the zero-point energy does not appear. Only the symmetrized under the field
operators Lagrangians lead to the zero-point energy. The confrontation by the
experiments of the such C-symmetric quantization of fields and the solution
some of the vacuum energy problems are discussed.
",2007-06-13,False
C-symmetric quantization of fields leading to a natural normal ordering,"The research paper ""C-symmetric quantization of fields leading to a natural normal ordering"" aims to present a new method of quantization that results in a natural normal ordering. The normal ordering is a mathematical operation that separates creation and annihilation operators in expressions of quantum field theory. The new method proposed in this paper is based on the C-symmetry, which is an important symmetry in quantum field theory. 

The paper also discusses the problems with traditional methods of normal ordering and how the new method can overcome those issues. The authors present various examples to demonstrate the effectiveness of the new method. 

In conclusion, the research paper proposes a new method of quantization that leads to a natural normal ordering. The method is based on the C-symmetry and can overcome the issues with traditional methods. The authors believe that this method can have important implications for quantum field theory and related fields.",2007-06-13,True
How to release Frege's system from Russell's antinomy,"  The conditions for proper definitions in mathematics are given, in terms of
the theory of definition, on the basis of the criterions of eliminability and
non-creativity. As a definition, Russell's antinomy is a violation of the
criterion of eliminability (Behmann, 1931; Bochvar, 1943). Following the path
of the criterion of non-creativity, this paper develops a new analysis of
Comprehension schema and, as a consequence, proof that Russell's antinomy
argumentation, despite the words of Frege himself, does not hold in
Grundgesetze der Arithmetik. According to Basic Law (III), the class of classes
not belonging to themselves is a class defined by a function which can not take
as argument its own course of value. In other words, the class of classes not
belonging to themselves is a class whose classes are not identical to the class
itself.
",2007-05-23,False
How to release Frege's system from Russell's antinomy,"This research paper explores the problem of Russell's antinomy in Frege's system of logic and proposes a solution to release it. The main objective is to provide a consistent and coherent framework for Frege's system without the paradoxes that arise from Russell's antinomy. The paper first discusses the historical context and the significance of the problem, and then presents the proposed solution using the concept of hierarchy. The key findings of this research paper demonstrate that by introducing a hierarchy of types, it is possible to avoid the contradictions that arise from Russell's antinomy while preserving the core principles of Frege's system. The conclusion of this research paper emphasizes the importance of revisiting foundational issues in logic and mathematics and offers a new perspective on the relationship between Frege's system and Russell's antinomy.",2007-05-23,True
The role of elastic stresses on leaf venation morphogenesis,"  We explore the possible role of elastic mismatch between epidermis and
mesophyll as a driving force for the development of leaf venation. The current
prevalent 'canalization' hypothesis for the formation of veins claims that the
transport of the hormone auxin out of the leaves triggers cell differentiation
to form veins. Although there is evidence that auxin plays a fundamental role
in vein formation, the simple canalization mechanism may not be enough to
explain some features observed in the vascular system of leaves, in particular,
the abundance of vein loops. We present a model based on the existence of
mechanical instabilities that leads very naturally to hierarchical patterns
with a large number of closed loops. When applied to the structure of high
order veins, the numerical results show the same qualitative features as actual
venation patterns and, furthermore, have the same statistical properties. We
argue that the agreement between actual and simulated patterns provides strong
evidence for the role of mechanical effects on venation development.
",2008-05-02,False
The role of elastic stresses on leaf venation morphogenesis,"This research paper aims to investigate the role of elastic stresses in the development of leaf venation patterns. Leaf venation plays a crucial role in plant physiology as it facilitates the transport of water, nutrients, and sugars throughout the leaf. However, the mechanisms that regulate the formation of venation patterns are not fully understood. In this study, we hypothesize that elastic stresses, resulting from differential growth rates in different regions of the leaf, play a significant role in the development of venation patterns. We will use computational simulations to model the growth and development of leaves under different elastic stress conditions. We will also examine the venation patterns of actual leaves under different experimental conditions. Our results will provide insights into the mechanisms that regulate leaf venation morphogenesis and could contribute to the development of more efficient plant engineering techniques.",2008-05-02,True
Soliton-fermion systems and stabilised vortex loops,"  In several self-coupled quantum field theories when treated in semi-classical
limit one obtains solitonic solutions determined by topology of the boundary
conditions. Such solutions, e.g. magnetic monopole in unified theories
\cite{Hooft1974} \cite{Polyakov1974} or the skyrme model of hadrons have been
proposed as possible non-perturbative bound states which remain stable due to
topological quantum numbers. Furthermore when fermions are introduced, under
certain conditions one obtains zero-energy solutions
\cite{Vega1978}\cite{Jackiw1981} for the Dirac equations localised on the
soliton. An implication of such zero-modes is induced fermion number
\cite{Jackiw1977} carried by the soliton.
",2007-05-23,False
Soliton-fermion systems and stabilised vortex loops,"This research paper investigates the dynamics of soliton-fermion systems and their interaction with stabilised vortex loops. We employ a combination of analytical and numerical methods to study the behaviour of these systems under various conditions. Our results demonstrate that the presence of fermions can significantly affect the stability and lifetime of vortex loops. Furthermore, we find that the interaction between solitons and fermions can lead to the formation of complex structures such as vortex rings and soliton-fermion composites. Additionally, we show that the energy transfer between solitons and fermions can have important implications for the behaviour of the system. Overall, our findings provide new insights into the physics of soliton-fermion systems and their interaction with vortex loops, with potential applications in fields such as condensed matter physics and cosmology.",2007-05-23,True
Game-Theoretic Power Control in Impulse Radio UWB Wireless Networks,"  In this paper, a game-theoretic model for studying power control for wireless
data networks in frequency-selective multipath environments is analyzed. The
uplink of an impulse-radio ultrawideband system is considered. The effects of
self-interference and multiple-access interference on the performance of Rake
receivers are investigated for synchronous systems. Focusing on energy
efficiency, a noncooperative game is proposed in which users in the network are
allowed to choose their transmit powers to maximize their own utilities, and
the Nash equilibrium for the proposed game is derived. It is shown that, due to
the frequency selective multipath, the noncooperative solution is achieved at
different signal-to-interference-plus-noise ratios, respectively of the channel
realization. A large-system analysis is performed to derive explicit
expressions for the achieved utilities. The Pareto-optimal (cooperative)
solution is also discussed and compared with the noncooperative approach.
",2007-07-13,False
Game-Theoretic Power Control in Impulse Radio UWB Wireless Networks,"This research paper proposes a game-theoretic approach for power control in Impulse Radio Ultra Wideband (IR-UWB) wireless networks. The objective is to minimize the energy consumption of the network while ensuring a certain level of Quality of Service (QoS) for the users. The proposed algorithm is based on a non-cooperative game where each user autonomously adjusts its transmit power based on the channel conditions and the actions of the other users. The Nash equilibrium of the game is shown to exist and be unique under mild assumptions. Simulation results show that the proposed algorithm outperforms the traditional fixed power allocation schemes in terms of energy efficiency and fairness. The paper concludes that game theory can be a promising tool for power control in IR-UWB networks, providing a balance between energy efficiency and QoS.",2007-07-13,True
Extrasolar planet taxonomy: a new statistical approach,"  In this paper we present the guidelines for an extrasolar planet taxonomy.
The discovery of an increasing number of extrasolar planets showing a vast
variety of planetary parameters, like Keplerian orbital elements and
environmental parameters, like stellar masses, spectral types, metallicity
etc., prompts the development of a planetary taxonomy. In this work via
principal component analysis followed by hierarchical clustering analysis, we
report the definition of five robust groups of planets. We also discuss the
physical relevance of such analysis, which may provide a valid basis for
disentangling the role of the several physical parameters involved in the
processes of planet formation and subsequent evolution. For instance, we were
able to divide the hot Jupiters into two main groups on the basis of their
stellar masses and metallicities. Moreover, for some groups, we find strong
correlations between metallicity, semi-major axis and eccentricity. The
implications of these findings are discussed.
",2009-06-23,False
Extrasolar planet taxonomy: a new statistical approach,"The search for extrasolar planets has yielded a wealth of information about the variety and distribution of planetary systems throughout the universe. However, the sheer volume of data can make it difficult to identify patterns and classify different types of planets. In this paper, we present a new statistical approach to extrasolar planet taxonomy that is designed to capture the most important features of these systems. Our method uses a combination of clustering and principal component analysis to group planets according to their physical properties, such as mass, radius, and orbital period. We apply this method to a large sample of confirmed planets and show that it is able to identify distinct groups of planets that are consistent with previous taxonomies. Our approach also allows us to quantify the degree of similarity between different planetary systems and to identify outliers that may be of particular interest. Overall, our results demonstrate the usefulness of a statistical approach to extrasolar planet taxonomy and highlight the need for continued refinement and improvement of these methods as more data becomes available.",2009-06-23,True
Network Structure of Protein Folding Pathways,"  The classical approach to protein folding inspired by statistical mechanics
avoids the high dimensional structure of the conformation space by using
effective coordinates. Here we introduce a network approach to capture the
statistical properties of the structure of conformation spaces. Conformations
are represented as nodes of the network, while links are transitions via
elementary rotations around a chemical bond. Self-avoidance of a polypeptide
chain introduces degree correlations in the conformation network, which in turn
lead to energy landscape correlations. Folding can be interpreted as a biased
random walk on the conformation network. We show that the folding pathways
along energy gradients organize themselves into scale free networks, thus
explaining previous observations made via molecular dynamics simulations. We
also show that these energy landscape correlations are essential for recovering
the observed connectivity exponent, which belongs to a different universality
class than that of random energy models. In addition, we predict that the
exponent and therefore the structure of the folding network fundamentally
changes at high temperatures, as verified by our simulations on the AK peptide.
",2007-05-23,False
Network Structure of Protein Folding Pathways,"Protein folding is a complex process that is critical for the proper functioning of biological systems. Understanding the network structure of protein folding pathways can provide valuable insights into the mechanisms underlying this process. In this paper, we review recent advances in the field of protein folding and explore the network structure of folding pathways. We examine the role of network motifs, community structure, and other network properties in shaping folding pathways. Additionally, we discuss the implications of network structure for protein design and engineering, as well as potential applications in drug discovery. Our findings suggest that a network-based approach can provide a powerful framework for understanding protein folding and its role in biological systems.",2007-05-23,True
A near-infrared/optical/X-ray survey in the centre of sigma Orionis,"  Because of the intense brightness of the OB-type multiple star system sigma
Ori, the low-mass stellar and substellar populations close to the centre of the
very young sigma Orionis cluster is poorly know. I present an IJHKs survey in
the cluster centre, able to detect from the massive early-type stars down to
cluster members below the deuterium burning mass limit. The near-infrared and
optical data have been complemented with X-ray imaging. Ten objects have been
found for the first time to display high-energy emission. Previously known
stars with clear spectroscopic youth indicators and/or X-ray emission define a
clear sequence in the I vs. I-Ks diagram. I have found six new candidate
cluster members that follow this sequence. One of them, in the magnitude
interval of the brown dwarfs in the cluster, displays X-ray emission and a very
red J-Ks colour, indicative of a disc. Other three low-mass stars have excesses
in the Ks band as well. The frequency of X-ray emitters in the area is 80+/-20
%. The spatial density of stars is very high, of up to 1.6+/-0.1 arcmin-2.
There is no indication of lower abundance of substellar objects in the cluster
centre. Finally, I also report two cluster stars with X-ray emission located at
only 8000-11000 AU to sigma Ori AB, two sources with peculiar colours and an
object with X-ray emission and near-infrared magnitudes similar to those of
previously-known substellar objects in the cluster.
",2009-11-13,False
A near-infrared/optical/X-ray survey in the centre of sigma Orionis,"The research paper titled ""A near-infrared/optical/X-ray survey in the centre of sigma Orionis"" aimed to investigate the central region of the sigma Orionis star-forming cluster and study the properties of its young stellar population. The survey used data from near-infrared, optical, and X-ray observations to identify and classify stars in the region.

The study found a total of 1,719 stars in the central region of sigma Orionis, with most of them being young stars. The researchers also identified several subclusters within the region, each with its own distinct properties. Additionally, they found evidence of ongoing star formation in the region.

The X-ray observations revealed that many of the young stars in the region are highly active, exhibiting strong X-ray emission. The study also identified several X-ray sources that are likely to be young brown dwarfs, which are low-mass objects that are too small to sustain nuclear fusion in their cores.

Overall, the study provides important insights into the properties of young stars and star-forming regions, and the results will be useful for future studies of sigma Orionis and other similar star-forming regions.",2009-11-13,True
"Satisfiability Parsimoniously Reduces to the Tantrix(TM) Rotation Puzzle
  Problem","  Holzer and Holzer (Discrete Applied Mathematics 144(3):345--358, 2004) proved
that the Tantrix(TM) rotation puzzle problem is NP-complete. They also showed
that for infinite rotation puzzles, this problem becomes undecidable. We study
the counting version and the unique version of this problem. We prove that the
satisfiability problem parsimoniously reduces to the Tantrix(TM) rotation
puzzle problem. In particular, this reduction preserves the uniqueness of the
solution, which implies that the unique Tantrix(TM) rotation puzzle problem is
as hard as the unique satisfiability problem, and so is DP-complete under
polynomial-time randomized reductions, where DP is the second level of the
boolean hierarchy over NP.
",2008-06-09,False
"Satisfiability Parsimoniously Reduces to the Tantrix(TM) Rotation Puzzle
  Problem","This research paper explores the relationship between satisfiability and the Tantrix(TM) rotation puzzle problem, demonstrating that the former can be parsimoniously reduced to the latter. Through this reduction, the authors provide new insights into the complexity of both problems and suggest that the Tantrix(TM) puzzle may be an effective tool for studying NP-complete problems. The paper concludes by highlighting the potential for further research in this area and the implications for the broader field of computer science.",2008-06-09,True
Meson and glueball spectra with the relativistic flux tube model,"  The mass spectra of heavy and light mesons is computed within the framework
of the relativistic flux tube model. A good agreement with the experimental
data is obtained provided that the flux tube contributions, including
retardation and spin-orbit effects, are supplemented by a one-gluon-exchange
potential, a quark self-energy term and instanton-induced interactions. No
arbitrary constant is needed to fit the absolute scale of the mass spectra, and
the different parameters are fitted on lattice QCD in order to strongly
restrict the arbitrariness of our model. The relevance of the present approach
is discussed in the case of glueballs, and the glueball spectrum we compute is
compared to the lattice QCD one. Finally, we make connections between the
results of our model and the nature of some newly discovered experimental
states such as the f_0(1810), X(3940), Y(3940), etc.
",2008-11-26,False
Meson and glueball spectra with the relativistic flux tube model,"The relativistic flux tube model is used to study the meson and glueball spectra. The model assumes that quarks are connected by a relativistic flux tube, and the energy levels of the system are obtained by solving the Schrdinger equation. Results show that the model reproduces the experimental meson spectrum and predicts the existence of glueballs. The study also suggests a possible method for distinguishing between mesons and glueballs through their decay modes. Overall, the relativistic flux tube model provides a framework for understanding the properties of hadrons and their interactions.",2008-11-26,True
"Precise manipulation of a Bose-Einstein condensate using Bragg
  interactions","  The use of off-resonant standing light waves to manipulate ultracold atoms is
investigated. Previous work has illustrated that optical pulses can provide
efficient beam-splitting and reflection operations for atomic wave packets. The
performance of these operations is characterized experimentally using
Bose-Einstein condensates confined in a weak magnetic trap. Under optimum
conditions, fidelities of up to 0.99 for beam splitting and 0.98 for reflection
are observed, and splitting operations of up to third order are achieved. The
dependence of the operations on light intensity and atomic velocity is measured
and found to agree well with theoretical estimates.
",2007-06-19,False
"Precise manipulation of a Bose-Einstein condensate using Bragg
  interactions","This research paper explores the use of Bragg interactions for the manipulation of Bose-Einstein condensates. The study demonstrates how precise control over the position and velocity of the condensate can be achieved through the use of Bragg pulses. Furthermore, the paper presents evidence that the technique can be used to create complex interference patterns and potentially useful in quantum information processing. The findings suggest that Bragg interactions provide a powerful tool for the manipulation of ultra-cold atomic systems.",2007-06-19,True
Charging of a quantum dot coupled to Luttinger liquid leads,"  Luttinger liquid behavior of one-dimensional correlated electron systems is
characterized by power-law scaling of a variety of physical observables with
exponents determined by a single interaction dependent parameter K. We suggest
a setup to study Luttinger liquid behavior in quantum wires which allows to
determine K from two independent measurements: resonant transport through a
quantum dot embedded in the wire and the charge on the dot. Consistency of the
two measured values of K for a single probe would provide strong experimental
evidence for the Luttinger liquid paradigm.
",2007-10-23,False
Charging of a quantum dot coupled to Luttinger liquid leads,"This research paper focuses on investigating the charging behavior of a quantum dot coupled to Luttinger liquid leads. The study employs a theoretical approach to analyze the electron transport properties of the system and explores the effects of Coulomb interactions on the charging dynamics. The results reveal that the charging energy of the quantum dot is significantly influenced by the coupling strength and the Luttinger parameter of the leads. Furthermore, the study indicates that the charging process can be controlled by tuning the gate voltage and the magnetic field. The findings of this research provide valuable insights into the physics of charge transport in quantum dot systems and can be useful in the development of future quantum devices.",2007-10-23,True
"Variable-Rate Distributed Source Coding in the Presence of Byzantine
  Sensors","  The distributed source coding problem is considered when the sensors, or
encoders, are under Byzantine attack; that is, an unknown number of sensors
have been reprogrammed by a malicious intruder to undermine the reconstruction
at the fusion center. Three different forms of the problem are considered. The
first is a variable-rate setup, in which the decoder adaptively chooses the
rates at which the sensors transmit. An explicit characterization of the
variable-rate minimum achievable sum rate is stated, given by the maximum
entropy over the set of distributions indistinguishable from the true source
distribution by the decoder. In addition, two forms of the fixed-rate problem
are considered, one with deterministic coding and one with randomized coding.
The achievable rate regions are given for both these problems, with a larger
region achievable using randomized coding, though both are suboptimal compared
to variable-rate coding.
",2007-07-13,False
"Variable-Rate Distributed Source Coding in the Presence of Byzantine
  Sensors",This research paper focuses on developing a variable-rate distributed source coding scheme that can effectively deal with Byzantine sensors in wireless sensor networks. The proposed scheme employs a novel distortion metric to identify the faulty sensors and excludes them from the decoding process. Simulation results demonstrate that the proposed scheme achieves significant improvements in the reconstruction quality compared to existing methods. The findings of this research can lead to the development of more reliable and efficient distributed source coding schemes for wireless sensor networks in the presence of Byzantine sensors.,2007-07-13,True
"Relic abundance of dark matter in universal extra dimension models with
  right-handed neutrinos","  Relic abundance of dark matter is investigated in the framework of universal
extra dimension models with right-handed neutrinos. These models are free from
the serious Kaluza-Klein (KK) graviton problem that the original universal
extra dimension model has. The first KK particle of the right-handed neutrino
is a candidate for dark matter in this framework, and its relic abundance is
determined by three processes, (1) the decay of the KK photon into the first KK
right-handed neutrino in the late universe, (2) production of the first KK
right-handed neutrino from the thermal bath in the early universe, and (3) the
decay of higher KK right-handed neutrinos into the first KK right-handed
neutrino in the late universe. When ordinary neutrino masses are large enough
such as the degenerate mass spectrum case, the last process contribute to the
abundance significantly, even if the reheating temperature is low. The scale of
the extra dimension consistent with cosmological observations can be 500 GeV in
the minimal setup of universal extra dimension models with right-handed
neutrinos.
",2008-11-26,False
"Relic abundance of dark matter in universal extra dimension models with
  right-handed neutrinos","This research paper investigates the relic abundance of dark matter in Universal Extra Dimension (UED) models with right-handed neutrinos. We examine the impact of the extra dimension on the production and decay of the right-handed neutrinos, which are a crucial component in the generation of the observed baryon asymmetry. Our findings reveal that UED models with right-handed neutrinos can produce the correct dark matter relic abundance, and that the observed baryon asymmetry can be generated through leptogenesis. These results have significant implications for the search for dark matter and the study of the origin of matter in the universe.",2008-11-26,True
"Performance Comparison of Energy-Efficient Power Control for CDMA and
  Multiuser UWB Networks","  This paper studies the performance of a wireless data network using
energy-efficient power control techniques when different multiple access
schemes, namely direct-sequence code division multiple access (DS-CDMA) and
impulse-radio ultrawideband (IR-UWB), are considered. Due to the large
bandwidth of the system, the multipath channel is assumed to be
frequency-selective. By making use of noncooperative game-theoretic models and
large-system analysis tools, explicit expressions for the achieved utilities at
the Nash equilibrium are derived in terms of the network parameters. A measure
of the loss of DS-CDMA with respect to IR-UWB is proposed, which proves
substantial equivalence between the two schemes. Simulation results are
provided to validate the analysis.
",2007-07-13,False
"Performance Comparison of Energy-Efficient Power Control for CDMA and
  Multiuser UWB Networks","Wireless communication has become an inseparable part of our daily life, and energy efficiency has become a critical concern in wireless networks. In this paper, we investigate the performance comparison of energy-efficient power control for Code Division Multiple Access (CDMA) and Multiuser Ultra-Wide Band (UWB) networks. We first introduce the power control schemes in both networks and then analyze the energy efficiency metrics, including energy consumption, spectral efficiency, and outage probability. Simulation results show that the UWB network outperforms the CDMA network in terms of energy efficiency metrics under different traffic loads and channel conditions. Furthermore, we investigate the impact of the number of users, spreading factor, and target data rate on the energy efficiency of both networks. Our analysis provides insights into the design of energy-efficient wireless networks and can be used as a reference for future research in this field.",2007-07-13,True
Stability of spinor Fermi gases in tight waveguides,"  The two and three-body correlation functions of the ground state of an
optically trapped ultracold spin-1/2 Fermi gas (SFG) in a tight waveguide (1D
regime) are calculated in the plane of even and odd-wave coupling constants,
assuming a 1D attractive zero-range odd-wave interaction induced by a 3D p-wave
Feshbach resonance, as well as the usual repulsive zero-range even-wave
interaction stemming from 3D s-wave scattering. The calculations are based on
the exact mapping from the SFG to a ``Lieb-Liniger-Heisenberg'' model with
delta-function repulsions depending on isotropic Heisenberg spin-spin
interactions, and indicate that the SFG should be stable against three-body
recombination in a large region of the coupling constant plane encompassing
parts of both the ferromagnetic and antiferromagnetic phases. However, the
limiting case of the fermionic Tonks-Girardeau gas (FTG), a spin-aligned 1D
Fermi gas with infinitely attractive p-wave interactions, is unstable in this
sense. Effects due to the dipolar interaction and a Zeeman term due to a
resonance-generating magnetic field do not lead to shrinkage of the region of
stability of the SFG.
",2009-11-13,False
Stability of spinor Fermi gases in tight waveguides,"This research paper investigates the stability of spinor Fermi gases in tight waveguides by analyzing the behavior of the system under different conditions. The authors use a combination of theoretical and numerical methods to study the stability of the system, and they find that the behavior of the system is highly dependent on the interactions between the particles. Specifically, they find that repulsive interactions tend to stabilize the system, while attractive interactions can lead to the formation of unstable modes. The authors also explore the effects of spin-orbit coupling on the stability of the system, finding that it can have a significant impact on the behavior of the system under certain conditions. Overall, the authors conclude that the stability of spinor Fermi gases in tight waveguides is a complex and multifaceted problem that requires careful consideration of a number of different factors.",2009-11-13,True
On spacetime coordinates in special relativity,"  Starting with two light clocks to derive time dilation expression, as many
textbooks do, and then adding a third one, we work on relativistic spacetime
coordinates relations for some simple events as emission, reflection and return
of light pulses. Besides time dilation, we get, in the following order, Doppler
k-factor, addition of velocities, length contraction, Lorentz Transformations
and spacetime interval invariance. We also use Minkowski spacetime diagram to
show how to interpret some few events in terms of spacetime coordinates in
three different inertial frames.
",2007-05-23,False
On spacetime coordinates in special relativity,This research paper explores the concept of spacetime coordinates in special relativity theory. The primary theme of the study is to investigate the fundamental principles of spacetime and the implications of time dilation and length contraction. The paper provides significant findings on the importance of understanding the relationship between space and time in explaining the behavior of objects in motion. The conclusion drawn from this study is that the understanding of spacetime coordinates is essential in comprehending the laws of physics and developing new technologies such as GPS systems.,2007-05-23,True
Universal derived equivalences of posets,"  By using only combinatorial data on two posets X and Y, we construct a set of
so-called formulas. A formula produces simultaneously, for any abelian category
A, a functor between the categories of complexes of diagrams over X and Y with
values in A. This functor induces a triangulated functor between the
corresponding derived categories.
  This allows us to prove, for pairs X, Y of posets sharing certain common
underlying combinatorial structure, that for any abelian category A, regardless
of its nature, the categories of diagrams over X and Y with values in A are
derived equivalent.
",2007-06-25,False
Universal derived equivalences of posets,"This research paper examines the concept of universal derived equivalences of posets, which involves constructing and analyzing certain categories of posets. The paper presents a novel approach to understanding the relationships between these categories, and provides a number of significant outcomes and conclusions regarding the nature of derived equivalences in posets. Specifically, the paper demonstrates how certain properties of posets can be used to construct universal derived equivalences, and explores the implications of these equivalences for various fields of mathematics. Overall, this research contributes valuable insights into the structure and behavior of posets, and sheds new light on the fundamental principles of derived equivalences.",2007-06-25,True
The period map for cubic fourfolds,"  The period map for cubic fourfolds takes values in a locally symmetric
variety of orthogonal type of dimension 20. We determine the image of this
period map (thus confirming a conjecture of Hassett) and give at the same time
a new proof of the theorem of Voisin that asserts that this period map is an
open embedding. An algebraic version of our main result is an identification of
the algebra of SL(6)-invariant polynomials on the space of cubic forms in 6
complex variables with a certain algebra of meromorphic automorphic forms on a
symmetric domain of orthogonal type of dimension 20. We also describe the
stratification of the moduli space of semistable cubic fourfolds in terms of a
Dynkin-Vinberg diagram.
",2007-05-23,False
The period map for cubic fourfolds,"This paper explores the period map for cubic fourfolds, a mathematical tool used to study the geometry of these complex objects. We prove that the period map is a locally closed immersion and use it to investigate the birational geometry of cubic fourfolds. Our analysis leads to the discovery of new families of cubic fourfolds and their properties. These findings provide insight into the structure and behavior of these objects, with potential implications for related areas of mathematics such as algebraic geometry and topology.",2007-05-23,True
An Independent Evaluation of Subspace Face Recognition Algorithms,"  This paper explores a comparative study of both the linear and kernel
implementations of three of the most popular Appearance-based Face Recognition
projection classes, these being the methodologies of Principal Component
Analysis, Linear Discriminant Analysis and Independent Component Analysis. The
experimental procedure provides a platform of equal working conditions and
examines the ten algorithms in the categories of expression, illumination,
occlusion and temporal delay. The results are then evaluated based on a
sequential combination of assessment tools that facilitate both intuitive and
statistical decisiveness among the intra and interclass comparisons. The best
categorical algorithms are then incorporated into a hybrid methodology, where
the advantageous effects of fusion strategies are considered.
",2007-05-23,False
An Independent Evaluation of Subspace Face Recognition Algorithms,"This research paper presents an independent evaluation of subspace face recognition algorithms, focusing on their accuracy and efficiency. The evaluation is conducted on a benchmark dataset using various performance metrics, including recognition rate, false acceptance rate, and execution time. The results show that certain subspace algorithms outperform others in terms of accuracy and efficiency. Additionally, the study highlights the importance of carefully selecting the appropriate algorithm for a given application. Overall, this research provides valuable insights and guidance for researchers and practitioners working on face recognition systems.",2007-05-23,True
Search for color charge dependence of energy loss at RHIC,"  The non-Abelian feature of quantum chromodynamics (QCD) results in the gluons
losing more energy than quarks in the medium formed in high energy heavy-ion
collisions. Experimental results in p+p collisions when compared to NLO pQCD
calculations show that at high transverse momentum (pT) the produced
protons+anti-protons are dominantly from gluon jets and charged pions have
substantial contribution from quark jets. If such a scenario is applied to
heavy-ion collisions at RHIC, one would expect the difference in quark and
gluon energy loss to have an effect on measured observables, such as high pT
pbar(p)/pi ratios and the nuclear modification factor for various particles
species. We discuss the experimental results and some possible future
measurements.
",2007-05-23,False
Search for color charge dependence of energy loss at RHIC,"The research paper titled ""Search for color charge dependence of energy loss at RHIC"" aimed to investigate the dependence of energy loss on the color charge of quarks and gluons in heavy-ion collisions at the Relativistic Heavy Ion Collider (RHIC). The study utilized data from collisions between gold ions and protons at different energies and impact parameters. The main objective was to test the hypothesis of jet quenching, which predicts that quarks and gluons with larger color charges will lose more energy as they traverse the quark-gluon plasma (QGP).

The study found no evidence of color charge dependence of energy loss in the QGP produced at RHIC. The data were consistent with the hypothesis of jet quenching, indicating that all partons lose energy as they traverse the QGP, regardless of their color charge. The findings provide important insights into the nature of the QGP and the mechanisms of jet quenching, which have important implications for the study of high-energy nuclear collisions.

In conclusion, the study demonstrated that the energy loss in the QGP produced at RHIC does not depend on the color charge of the partons, providing important constraints on theoretical models of jet quenching and the QGP. The results contribute to a better understanding of the properties of the QGP and the dynamics of high-energy nuclear collisions.",2007-05-23,True
Microscopic origin of Magnetic Ferroelectrics in Nonlinear Multiferroics,"  A simple but general microscopic mechanism to understand the interplay
between the electric and magnetic degrees of freedom is developed. Within this
mechanism, the magnetic structure generates an electric current which induce an
counterbalance electric current from the spin orbital coupling. When the
magnetic structure is described by a single order parameter, the electric
polarization is determined by the single spin orbital coupling parameter, and
the material is predicted to be a half insulator. This mechanism provides a
simple estimation of the value of ferroelectricity and sets a physical
limitation as well.
",2009-11-13,False
Microscopic origin of Magnetic Ferroelectrics in Nonlinear Multiferroics,This research paper explores the microscopic origin of magnetic ferroelectrics in nonlinear multiferroics. The primary theme of the paper is to investigate the relationship between magnetism and ferroelectricity at a microscopic level. The paper also aims to understand the underlying physics of nonlinear multiferroics and their potential applications. The essential findings of the paper suggest that the coupling between magnetic and ferroelectric order parameters arises from the spin-orbit coupling and the lattice distortion. The paper concludes that the understanding of the microscopic origin of magnetic ferroelectrics in nonlinear multiferroics can lead to the development of new materials with enhanced multifunctionality for technological applications.,2009-11-13,True
"On Isotropic Sets of Points in the Plane. Application to the Design of
  Robot Archirectures","  Various performance indices are used for the design of serial manipulators.
One method of optimization relies on the condition number of the Jacobian
matrix. The minimization of the condition number leads, under certain
conditions, to isotropic configurations, for which the roundoff-error
amplification is lowest. In this paper, the isotropy conditions, introduced
elsewhere, are the motivation behind the introduction of isotropic sets of
points. By connecting together these points, we define families of isotropic
manipulators. This paper is devoted to planar manipulators, the concepts being
currently extended to their spatial counterparts. Furthermore, only
manipulators with revolute joints are considered here.
",2007-05-23,False
"On Isotropic Sets of Points in the Plane. Application to the Design of
  Robot Archirectures","This research paper explores the concept of isotropic sets of points in the plane and their potential application to the design of robot architectures. Isotropic sets of points refer to a collection of points that exhibit symmetry and uniformity in all directions. The paper investigates the properties and characteristics of isotropic sets and proposes their use in designing robot architectures that can move and operate efficiently in any direction. The study includes mathematical analyses and simulations to demonstrate the effectiveness of isotropic sets in improving robot mobility and performance. The findings of this research can have significant implications in the field of robotics, particularly in the development of robots that can navigate complex environments with ease.",2007-05-23,True
"The Kinematic Analysis of a Symmetrical Three-Degree-of-Freedom Planar
  Parallel Manipulator","  Presented in this paper is the kinematic analysis of a symmetrical
three-degree-of-freedom planar parallel manipulator. In opposite to serial
manipulators, parallel manipulators can admit not only multiple inverse
kinematic solutions, but also multiple direct kinematic solutions. This
property produces more complicated kinematic models but allows more flexibility
in trajectory planning. To take into account this property, the notion of
aspects, i.e. the maximal singularity-free domains, was introduced, based on
the notion of working modes, which makes it possible to separate the inverse
kinematic solutions. The aim of this paper is to show that a non-singular
assembly-mode changing trajectory exist for a symmetrical planar parallel
manipulator, with equilateral base and platform triangle.
",2007-05-23,False
"The Kinematic Analysis of a Symmetrical Three-Degree-of-Freedom Planar
  Parallel Manipulator",This research paper presents a kinematic analysis of a symmetrical three-degree-of-freedom planar parallel manipulator. The central focus is on analyzing the manipulator's motion and its workspace. The key findings of the study include the manipulator's ability to reach all points within its workspace and its high accuracy in motion control. The research concludes that the symmetrical manipulator is a viable option for precision tasks in various industries.,2007-05-23,True
Uniqueness Domains in the Workspace of Parallel Manipulators,"  This work investigates new kinematic features of parallel manipulators. It is
well known that parallel manipulators admit generally several direct kinematic
solutions for a given set of input joint values. The aim of this paper is to
characterize the uniqueness domains in the workspace of parallel manipulators,
as well as their image in the joint space. The study focuses on the most usual
case of parallel manipulators with only one inverse kinematic solution. The
notion of aspect introduced for serial manipulators in [Borrel 86] is redefined
for such parallel manipulators. Then, it is shown that it is possible to link
several solutions to the forward kinematic problem without meeting a
singularity, thus meaning that the aspects are not uniqueness domains. An
additional set of surfaces, namely the characteristic surfaces, are
characterized which divide the workspace into basic regions and yield new
uniqueness domains. This study is illustrated all along the paper with a 3-RPR
planar parallel manipulator. An octree model of spaces is used to compute the
joint space, the workspace and all other newly defined sets.
",2007-05-23,False
Uniqueness Domains in the Workspace of Parallel Manipulators,"The objective of this research paper is to study the uniqueness domains of parallel manipulators in their workspace. The paper first defines the concept of uniqueness domains and presents a method to compute them for different types of parallel manipulators. The study then investigates the impact of design parameters, such as link lengths and joint angles, on the size and shape of the uniqueness domains. Key results indicate that the size and shape of the uniqueness domains vary significantly with changes in the design parameters. The paper also highlights the importance of uniqueness domains in the design and control of parallel manipulators. Overall, the study contributes to a better understanding of the behavior of parallel manipulators and can aid in the optimization of their design for specific applications.",2007-05-23,True
The Kinematic design of a 3-dof Hybrid Manipulator,"  This paper focuses on the kinematic properties of a new
three-degree-of-freedom hybrid manipulator. This manipulator is obtained by
adding in series to a five-bar planar mechanism (similar to the one studied by
Bajpai and Roth) a third revolute passing through the line of centers of the
two actuated revolute joints of the above linkage. The resulting architecture
is hybrid in that it has both serial and parallel links. Fully-parallel
manipulators are known for the existence of particularly undesirable
singularities (referred to as parallel singularities) where control is lost [4]
and [6]. On the other hand, due to their cantilever type of kinematic
arrangement, fully serial manipulators suffer from a lack of stiffness and from
relatively large positioning errors. The hybrid manipulator studied is
intrinsically stiffer and more accurate. Furthermore, since all actuators are
located on the first axis, the inertial effects are considerably reduced. In
addition, it is shown that the special kinematic structure of our manipulator
has the potential of avoiding parallel singularities by a suitable choice of
the ""working mode"", thus leading to larger workspaces. The influence of the
different structural dimensions (e.g. the link lengths) on the kinematic and
mechanical properties are analysed in view of the optimal design of such hybrid
manipulators.
",2007-05-23,False
The Kinematic design of a 3-dof Hybrid Manipulator,"The research paper focuses on the kinematic design of a 3-degree-of-freedom (3-dof) hybrid manipulator, which combines the advantages of both serial and parallel manipulators. The authors present the mathematical model of the manipulator and derive its kinematic equations, which are used to analyze its motion characteristics. They also propose a novel approach for optimizing the manipulator's workspace using a genetic algorithm. The results of the study show that the proposed manipulator has a large workspace and good motion performance, making it suitable for various applications in industry and automation. Overall, the paper provides valuable insights into the design and optimization of hybrid manipulators.",2007-05-23,True
Definition sets for the Direct Kinematics of Parallel Manipulators,"  The aim of this paper is to characterize the uniqueness domains in the
workspace of parallel manipulators, as well as their image in the joint space.
The notion of aspect introduced for serial manipulators in [Borrel 86] is
redefined for such parallel manipulators. Then, it is shown that it is possible
to link several solutions to the direct kinematic problem without meeting a
singularity, thus meaning that the aspects are not uniqueness domains.
Additional surfaces are characterized in the workspace which yield new
uniqueness domains. An octree model of spaces is used to compute the joint
space, the workspace and all other newly defined sets. This study is
illustrated all along the paper with a 3-RPR planar parallel manipulator.
",2007-05-23,False
Definition sets for the Direct Kinematics of Parallel Manipulators,"This research paper aims to define the sets of equations required for the direct kinematics of parallel manipulators and analyze their properties. The key findings suggest that the number of equations required for a given manipulator is dependent on the degree of freedom and the number of legs. Furthermore, the paper concludes that using a combination of forward and inverse kinematics can improve the accuracy of the direct kinematics solution.",2007-05-23,True
"Optical Variability of Infrared Power Law-Selected Galaxies & X-ray
  Sources in the GOODS-South Field","  We investigate the use of optical variability to identify and study Active
Galactic Nuclei (AGN) in the GOODS-South field. A sample of 22 mid-infrared
power law sources and 102 X-ray sources with optical counterparts in the HST
ACS images were selected. Each object is classified with a variability
significance value related to the standard deviation of its magnitude in five
epochs separated by 45-day intervals. The variability significance is compared
to the optical, mid-IR, and X-ray properties of the sources. We find that 26%
of all AGN candidates (either X-ray- or mid-IR-selected) are optical variables.
The fraction of optical variables increases to 51% when considering sources
with soft X-ray band ratios. For the mid-IR AGN candidates which have
multiwavelength SEDs, we find optical variability for 64% of those classified
with SEDs like Broad Line AGNs. While mostly unobscured AGN appear to have the
most significant optical variability, some of the more obscured AGNs are also
observed as variables. In particular, we find two mid-IR power law-selected AGN
candidates without X-ray emission that display optical variability, confirming
their AGN nature.
",2009-06-23,False
"Optical Variability of Infrared Power Law-Selected Galaxies & X-ray
  Sources in the GOODS-South Field","This research paper examines the optical variability of infrared power law-selected galaxies and X-ray sources in the GOODS-South Field. Using multi-epoch imaging data, we identify sources that show significant variability and study their properties. Our analysis reveals a diverse population of objects, including active galactic nuclei, star-forming galaxies, and transients. We find that optical variability is a useful tool for identifying and characterizing sources in the infrared and X-ray regimes. These results have important implications for our understanding of the physics of high-energy astrophysical sources and their evolution over time.",2009-06-23,True
Improved Analysis of Kannan's Shortest Lattice Vector Algorithm,"  The security of lattice-based cryptosystems such as NTRU, GGH and Ajtai-Dwork
essentially relies upon the intractability of computing a shortest non-zero
lattice vector and a closest lattice vector to a given target vector in high
dimensions. The best algorithms for these tasks are due to Kannan, and, though
remarkably simple, their complexity estimates have not been improved since more
than twenty years. Kannan's algorithm for solving the shortest vector problem
is in particular crucial in Schnorr's celebrated block reduction algorithm, on
which are based the best known attacks against the lattice-based encryption
schemes mentioned above. Understanding precisely Kannan's algorithm is of prime
importance for providing meaningful key-sizes. In this paper we improve the
complexity analyses of Kannan's algorithms and discuss the possibility of
improving the underlying enumeration strategy.
",2009-04-16,False
Improved Analysis of Kannan's Shortest Lattice Vector Algorithm,"This research paper presents an improved analysis of Kannan's shortest lattice vector algorithm, which is widely used in cryptography and coding theory. The algorithm is a fundamental tool for solving the shortest vector problem in lattices, which has important applications in areas such as integer factorization, coding theory, and cryptanalysis. In this paper, we propose a new approach to analyzing the runtime of Kannan's algorithm, based on a refined analysis of its key subroutine, the Gram-Schmidt orthogonalization process. Our analysis provides a more accurate estimate of the running time of the algorithm, and shows that it achieves a better asymptotic performance than previously thought. We also present numerical experiments to confirm the validity of our analysis, and to demonstrate the practical impact of our improvements. Our results have implications for the design and analysis of lattice-based cryptographic systems, and highlight the importance of rigorous analysis in the development of efficient algorithms for solving lattice problems.",2009-04-16,True
Ultrametric and tree potential,"  We study infinite tree and ultrametric matrices, and their action on the
boundary of the tree. For each tree matrix we show the existence of a symmetric
random walk associated to it and we study its Green potential. We provide a
representation theorem for harmonic functions that includes simple expressions
for any increasing harmonic function and the Martin kernel. In the boundary, we
construct the Markov kernel whose Green function is the extension of the matrix
and we simulate it by using a cascade of killing independent exponential random
variables and conditionally independent uniform variables. For ultrametric
matrices we supply probabilistic conditions to study its potential properties
when immersed in its minimal tree matrix extension.
",2007-05-23,False
Ultrametric and tree potential,"This research paper explores the concept of ultrametric and tree potential in mathematical analysis. It provides a detailed explanation of these concepts and their relevance in different fields of study. The paper also discusses the significant results obtained from the analysis of these potentials and their applications in various real-world scenarios. Notably, the study concludes that the ultrametric and tree potential have immense potential in solving complex problems in mathematics, computer science, physics, and other disciplines.",2007-05-23,True
"Artificial Neural Networks and Support Vector Machines for Water Demand
  Time Series Forecasting","  Water plays a pivotal role in many physical processes, and most importantly
in sustaining human life, animal life and plant life. Water supply entities
therefore have the responsibility to supply clean and safe water at the rate
required by the consumer. It is therefore necessary to implement mechanisms and
systems that can be employed to predict both short-term and long-term water
demands. The increasingly growing field of computational intelligence
techniques has been proposed as an efficient tool in the modelling of dynamic
phenomena. The primary objective of this paper is to compare the efficiency of
two computational intelligence techniques in water demand forecasting. The
techniques under comparison are the Artificial Neural Networks (ANNs) and the
Support Vector Machines (SVMs). In this study it was observed that the ANNs
perform better than the SVMs. This performance is measured against the
generalisation ability of the two.
",2007-05-23,False
"Artificial Neural Networks and Support Vector Machines for Water Demand
  Time Series Forecasting","This research paper explores the use of artificial neural networks (ANN) and support vector machines (SVM) for water demand time series forecasting. The study analyzes the performance of both techniques using real-world data from a water distribution system. The results show that both ANN and SVM models can effectively forecast water demand, with SVM outperforming ANN in terms of accuracy and model simplicity. The study also compares the performance of the models with traditional time series forecasting techniques and finds that both ANN and SVM outperform these methods. The study concludes that SVM is a promising technique for water demand forecasting and suggests that it should be further explored in future research.",2007-05-23,True
"Quantum Interference and Superposition in Cognition: Development of a
  Theory for the Disjunction of Concepts","  We elaborate a theory for the modeling of concepts using the mathematical
structure of quantum mechanics. Concepts are represented by vectors in the
complex Hilbert space of quantum mechanics and membership weights of items are
modeled by quantum weights calculated following the quantum rules. We apply
this theory to model the disjunction of concepts and show that experimental
data of membership weights of items with respect to the disjunction of concepts
can be modeled accurately. It is the quantum effects of interference and
superposition, combined with an effect of context, that are at the origin of
the effects of overextension and underextension observed as deviations from a
classical use of the disjunction. We put forward a graphical explanation of the
effects of overextension and underextension by interpreting the quantum model
applied to the modeling of the disjunction of concepts.
",2012-03-28,False
"Quantum Interference and Superposition in Cognition: Development of a
  Theory for the Disjunction of Concepts","This research paper explores the potential role of quantum interference and superposition in cognitive processes, and develops a theory for the disjunction of concepts. Through a review of existing literature and a synthesis of relevant concepts from quantum mechanics and cognitive psychology, this paper proposes that the disjunction of concepts may be explained by quantum interference and superposition. The theory suggests that the human mind may be capable of processing multiple, contradictory concepts simultaneously, leading to more creative and flexible thinking. The potential implications of this theory for fields such as education, problem-solving, and decision-making are discussed. Overall, this paper offers a novel perspective on the cognitive processes underlying concept formation and disjunction, and highlights the importance of interdisciplinary research in understanding the complex nature of the human mind.",2012-03-28,True
"Precision measurements of large scale structure with future type Ia
  supernova surveys","  Type Ia supernovae are currently the best known standard candles at
cosmological distances. In addition to providing a powerful probe of dark
energy they are an ideal source of information about the peculiar velocity
field of the local universe. Even with the very small number of supernovae
presently available it has been possible to measure the dipole and quadrupole
of the local velocity field out to z~0.025. With future continuous all-sky
surveys like the LSST project the luminosity distances of tens of thousands of
nearby supernovae will be measured accurately. This will allow for a
determination of the local velocity structure of the universe as a function of
redshift with unprecedented accuracy, provided the redshifts of the host
galaxies are known. Using catalogues of mock surveys we estimate that future
low redshift supernova surveys will be able to probe sigma-8 to a precision of
roughly 5% at 95% C.L. This is comparable to the precision in future galaxy and
weak lensing surveys and with a relatively modest observational effort it will
provide a crucial cross-check on future measurements of the matter power
spectrum.
",2009-06-23,False
"Precision measurements of large scale structure with future type Ia
  supernova surveys","This research paper explores the potential of future Type Ia supernova surveys to provide precise measurements of large scale structure in the universe. Through analyzing the properties and distribution of Type Ia supernovae, researchers could gain insights into the dark energy that drives the expansion of the universe. The paper examines the challenges associated with conducting such surveys and the potential benefits of obtaining high-quality data. Ultimately, the paper highlights the importance of precision measurements for advancing our understanding of the large scale structure of the universe.",2009-06-23,True
Charting the landscape of supercritical string theory,"  Special solutions of string theory in supercritical dimensions can
interpolate in time between theories with different numbers of spacetime
dimensions (via dimension quenching) and different amounts of worldsheet
supersymmetry (via c-duality). These solutions connect supercritical string
theories to the more familiar string duality web in ten dimensions, and provide
a precise link between supersymmetric and purely bosonic string theories.
Dimension quenching and c-duality appear to be natural concepts in string
theory, giving rise to large networks of interconnected theories. We describe
some of these networks in detail and discuss general consistency constraints on
the types of transitions that arise in this framework.
",2008-11-26,False
Charting the landscape of supercritical string theory,"This research paper explores the current landscape of supercritical string theory, a theoretical framework that aims to unify quantum mechanics and general relativity. Through a thorough review of literature and analysis of recent developments in the field, we provide an overview of the key concepts and mathematical structures that underpin supercritical string theory. We also examine the challenges and open questions facing researchers in this area, including the role of supersymmetry, the nature of extra dimensions, and the relationship between string theory and other branches of physics. Our analysis sheds light on the current state of the field and provides a roadmap for future research in this exciting and rapidly evolving area of theoretical physics.",2008-11-26,True
A New Three-DOF Parallel Mechanism: Milling Machine Applications,"  This paper describes a new parallel kinematic architecture for machining
applications, namely, the orthoglide. This machine features three fixed
parallel linear joints which are mounted orthogonally and a mobile platform
which moves in the Cartesian x-y-z space with fixed orientation. The main
interest of the orthoglide is that it takes benefit from the advantages of the
popular PPP serial machines (regular Cartesian workspace shape and uniform
performances) as well as from the parallel kinematic arrangement of the links
(less inertia and better dynamic performances), which makes the orthoglide well
suited to high-speed machining applications. Possible extension of the
orthoglide to 5-axis machining is also investigated.
",2007-05-23,False
A New Three-DOF Parallel Mechanism: Milling Machine Applications,"The article discusses the design and development of a new three-degree-of-freedom (DOF) parallel mechanism for use in milling machine applications. The mechanism is constructed using a combination of linear and rotational joints, which allows for greater precision and stability during milling operations. The study includes a detailed analysis of the mechanism's kinematics, dynamics, and performance characteristics, and concludes that the new mechanism is highly effective in reducing vibration and improving machining accuracy. The authors suggest that the new mechanism has potential for use in a wide range of industrial applications, particularly in the manufacturing of high-precision components.",2007-05-23,True
"What Can the Cosmic Microwave Background Tell Us About the Outer Solar
  System?","  We discuss two new observational techniques that use observations of the
Cosmic Microwave Background (CMB) to place constraints upon the mass, distance,
and size distribution of small objects in the Kuiper Belt and inner Oort Cloud,
collectively known as Trans-Neptunian Objects (TNOs). The first new technique
considers the spectral distortion of the isotropic, or monopole, CMB by TNOs
that have been heated by solar radiation to temperatures above that of the CMB.
We apply this technique to the spectral measurements of the CMB by the Far
Infrared Absolute Spectrophotometer (FIRAS) on the Cosmic Background Explorer
(COBE). The second technique utilizes the change in amplitude of the TNO signal
due to the orbital motion of the observer to separate the TNO signal from the
invariant extra-galactic CMB and construct a map of the mass distribution in
the outer Solar System. We estimate the ability of future CMB experiments to
create such a map.
",2009-11-13,False
"What Can the Cosmic Microwave Background Tell Us About the Outer Solar
  System?","The cosmic microwave background (CMB) is a crucial tool for understanding the origins and evolution of the universe. Recent studies have shown that the CMB can also provide valuable information about the outer solar system. This research paper explores how the CMB can reveal the properties of distant objects such as Kuiper Belt Objects and the Oort Cloud. We examine the ways in which the CMB can be used to study the composition, size, and shape of these bodies. Additionally, we discuss the implications of these findings for our understanding of the formation and evolution of the outer solar system. Our analysis suggests that the CMB is a powerful tool for investigating the outer reaches of our solar system and can provide valuable insights into the history of our cosmic neighborhood.",2009-11-13,True
"A new method to derive star formation histories of galaxies from their
  star cluster distributions","  Star formation happens in a clustered way which is why the star cluster
population of a particular galaxy is closely related to the star formation
history of this galaxy. From the probabilistic nature of a mass function
follows that the mass of the most-massive cluster of a complete population,
M_max, has a distribution with the total mass of the population as a parameter.
The total mass of the population is connected to the star formation rate (SFR)
by the length of a formation epoch.
  Since due to evolutionary effects only massive star clusters are observable
up to high ages it is convenient to use this M_max(SFR) relation for the
reconstruction of a star formation history. The age-distribution of the
most-massive clusters can therefore be used to constrain the star formation
history of a galaxy. The method, including an assessment of the inherent
uncertainties, is introduced with this contribution, while following papers
will apply this method to a number of galaxies.
",2009-06-23,False
"A new method to derive star formation histories of galaxies from their
  star cluster distributions","The research paper proposes a new method to derive the star formation histories of galaxies based on their star cluster distributions. The authors show that by analyzing the spatial distribution and ages of star clusters in a galaxy, it is possible to reconstruct the galaxy's star formation history. 

The authors applied their method to a sample of nearby galaxies and found that the resulting star formation histories were consistent with previous studies, but that their method provided more detailed information about the timing and duration of star formation episodes. 

One of the key conclusions of the study is that the star formation history of a galaxy can be inferred from its star cluster population, which provides a valuable tool for understanding the evolution of galaxies over cosmic time. The authors suggest that their method could be applied to larger samples of galaxies, including those at higher redshifts, to further explore the relationship between star formation and galaxy evolution.",2009-06-23,True
"Decoherence of a driven multilevel quantum system interacting with a
  multi-bath reservoir","  A general theory is presented for the treatment of decoherence of a
multilevel quantum system (with many degrees of freedom) interacting with
multi-bath reservoir and driven by ac fields. In this approach, the system is
described by a reduced density operator and the multi-bath reservoir is
characterized by a number of spectral densities. The reduced density operator
is governed by the master equation in which the effect of ac driving fields and
the leakage to non-computational states are included. The theory is applied to
the study of decoherence of a two-dimensional (2D) SQUID flux qubit coupled to
control and readout circuits. The predicted results are in very good agreement
with available experimental results in the absence of driving fields and with
the analytic results of a dissipative two-level system in the presence of weak
driving fields. The relaxation and decoherence times versus the parameters and
temperature of the control and readout circuits are also explored in details to
facilitate the optimization of the 2D SQUID qubit.
",2007-05-23,False
"Decoherence of a driven multilevel quantum system interacting with a
  multi-bath reservoir","The research paper explores the decoherence of a driven multilevel quantum system that interacts with a multi-bath reservoir. The study aims to investigate the effect of the multi-bath reservoir on the coherence of the quantum system. The research uses a model of a driven three-level system, which is coupled to three independent baths with different spectral densities. The study finds that the coherence of the quantum system is highly sensitive to the spectral density of the baths. The research also shows that the coherence of the system can be enhanced by adjusting the driving frequency and the coupling between the system and the baths. Overall, the study provides insights into the factors that affect the decoherence of a multilevel quantum system and offers potential strategies for mitigating this effect.",2007-05-23,True
"Avalanches Injecting Flux into the Central Hole of a Superconducting
  MgB2 Ring","  Magneto-optical imaging was used to observe dendritic flux avalanches
connecting the outer and inner edges of a ring-shaped superconducting MgB2
film. Such avalanches create heated channels across the entire width of the
ring, and inject large amounts of flux into the central hole. By measuring the
injected flux and the corresponding reduction of current, which is typically
15%, we estimate the maximum temperature in the channel to be 100 K, and the
duration of the process to be on the order of a microsecond. Flux creep
simulations reproduce all the observed features in the current density before
and after injection events.
",2007-05-23,False
"Avalanches Injecting Flux into the Central Hole of a Superconducting
  MgB2 Ring","This research paper presents a study on the effects of avalanches on the flux injection into the central hole of a superconducting MgB2 ring. The authors utilize a combination of experimental measurements and theoretical simulations to investigate the behavior of the superconductor under different avalanche conditions. The results show that avalanches can significantly enhance the flux injection, leading to a faster recovery of the superconducting state after a magnetic field disturbance. These findings provide important insights into the dynamics of superconducting materials and have potential applications in various fields, including energy storage and transportation.",2007-05-23,True
The alternating sign matrix polytope,"  We define the alternating sign matrix polytope as the convex hull of nxn
alternating sign matrices and prove its equivalent description in terms of
inequalities. This is analogous to the well known result of Birkhoff and von
Neumann that the convex hull of the permutation matrices equals the set of all
nonnegative doubly stochastic matrices. We count the facets and vertices of the
alternating sign matrix polytope and describe its projection to the
permutohedron as well as give a complete characterization of its face lattice
in terms of modified square ice configurations. Furthermore we prove that the
dimension of any face can be easily determined from this characterization.
",2018-05-28,False
The alternating sign matrix polytope,"The research paper titled ""The alternating sign matrix polytope"" investigates a mathematical object called the alternating sign matrix polytope (ASMP). The ASMP is a convex polytope that can be defined as the set of all real-valued matrices whose entries are either 0 or 1 and satisfy certain conditions. The authors of this paper study the geometric and combinatorial properties of the ASMP, including its volume, facet structure, and connections to other mathematical objects such as the tessellation of a hyperplane arrangement. They also provide a characterization of the vertices of the ASMP and prove that it is the convex hull of a finite set of points. The main conclusion of the paper is that the ASMP is a rich and interesting mathematical object that has important applications in various fields such as combinatorics, algebraic geometry, and statistical mechanics.",2018-05-28,True
"Cellular Systems with Full-Duplex Amplify-and-Forward Relaying and
  Cooperative Base-Stations","  In this paper the benefits provided by multi-cell processing of signals
transmitted by mobile terminals which are received via dedicated relay
terminals (RTs) are assessed. Unlike previous works, each RT is assumed here to
be capable of full-duplex operation and receives the transmission of adjacent
relay terminals. Focusing on intra-cell TDMA and non-fading channels, a
simplified uplink cellular model introduced by Wyner is considered. This
framework facilitates analytical derivation of the per-cell sum-rate of
multi-cell and conventional single-cell receivers. In particular, the analysis
is based on the observation that the signal received at the base stations can
be interpreted as the outcome of a two-dimensional linear time invariant
system. Numerical results are provided as well in order to provide further
insight into the performance benefits of multi-cell processing with relaying.
",2016-11-18,False
"Cellular Systems with Full-Duplex Amplify-and-Forward Relaying and
  Cooperative Base-Stations","The research paper investigates a cellular communication system with full-duplex amplify-and-forward relaying and cooperative base-stations. The primary focus is on analyzing the system's performance in terms of achievable rates and outage probabilities. The study finds that full-duplex relaying and cooperation among base-stations significantly improve the system's performance, particularly in scenarios with weak direct links. The results suggest that the proposed system can provide reliable and efficient communication in various practical scenarios.",2016-11-18,True
"An estimation of single and double diffractive heavy flavour production
  in hadron-hadron colliders","  Results from a phenomenological analysis for diffractive hadroproduction of
heavy flavors at high energies are reported. Diffractive production of charm,
bottom and top are calculated using Regge factorization, taking into account
recent experimental determination of the diffractive parton density functions
in Pomeron by the H1 Collaboration at DESY-HERA. In addition, multiple-Pomeron
corrections are considered through the rapidity gap survival probability
factor. We give numerical predictions for single diffractive as well as double
Pomeron exchange (DPE) cross sections, which agree with the available data for
diffractive production of charm and beauty. We make estimates which could be
compared to future measurements at the LHC.
",2008-11-26,False
"An estimation of single and double diffractive heavy flavour production
  in hadron-hadron colliders",This research paper focuses on the estimation of heavy flavour production in hadron-hadron colliders. The study aims to provide an understanding of the production mechanisms of single and double diffractive heavy flavours in high-energy hadron-hadron collisions. The research is based on the theoretical framework of perturbative Quantum Chromodynamics (pQCD) and Monte Carlo simulations. The paper presents the results of the estimation of the cross-sections and differential distributions for the production of charm and bottom quarks in single and double diffractive processes. The analysis includes a comparison of the results with experimental data from the Large Hadron Collider (LHC) experiments. The study is expected to contribute to the overall understanding of heavy flavour production in hadron-hadron collisions and provide insights for future collider experiments.,2008-11-26,True
Current constraints on interacting holographic dark energy,"  Although there is mounting observational evidence that the cosmic expansion
is undergoing a late-time acceleration, the physical mechanism behind such a
phenomenon is yet unknown. In this paper, we investigate a holographic dark
energy (HDE) model with interaction between the components of the dark sector
in the light of current cosmological observations. We use both the new
\emph{gold} sample of 182 type Ia supernovae (SNe Ia) and the 192 SNe Ia
ESSENCE data, the baryon acoustic oscillation measurement from the Sloan
Digital Sky Survey and the shift parameter from the three-year Wilkinson
Microwave Anisotropy Probe data. In agreement with previous results, we show
that these observations suggest a very weak coupling or even a noninteracting
HDE. The phantom crossing behavior in the context of these scenarios is also
briefly discussed.
",2009-06-23,False
Current constraints on interacting holographic dark energy,"The research paper ""Current constraints on interacting holographic dark energy"" aims to explore the viability of holographic dark energy (HDE) models in explaining the accelerating expansion of the universe. The authors investigate the interaction between dark energy and dark matter and consider various observational constraints to test the HDE models.

Through their analysis, the authors find that the HDE models can provide a viable explanation for the accelerating expansion of the universe, but they need to consider the interaction between dark energy and dark matter. The authors also find that the observational constraints, such as the cosmic microwave background radiation and baryon acoustic oscillations, are consistent with the HDE models.

One notable conclusion of the research is that the interaction between dark energy and dark matter can significantly affect the evolution of the universe. The authors suggest that future observational studies should focus on testing the interaction between dark energy and dark matter to provide more insight into the nature of dark energy. Overall, the research paper provides valuable insights into the constraints on HDE models and their potential to explain the accelerating expansion of the universe.",2009-06-23,True
Measuring Earth Matter Density and Testing the MSW Theory,"  In this talk I have raised the question of how the future discovery of
leptonic CP violation can be made robust even at accepting the rather large
current experimental uncertainties in our knowledges of neutrino propagation in
matter. To make progress toward answering the difficult question, I listed ways
to proceed: (1) Obtain tighter constraints on the MSW theory by testing it by
various neutrino experiments. (2) Measure the matter effect in situ, namely
within the experiment for discovering CP violation itself. (3) Uncover leptonic
CP violation in a matter effect free environment. I also reported a step made
toward the above point (2) by taking neutrino factory as a concrete setting; An
accurate in situ measurement of the matter effect looks promising.
",2007-05-23,False
Measuring Earth Matter Density and Testing the MSW Theory,"This research paper focuses on measuring the density of Earth matter and testing the MSW (Mikheyev-Smirnov-Wolfenstein) theory. The MSW theory explains how neutrinos interact with matter as they travel through the Earth, affecting their oscillation patterns. The study used data from Super-Kamiokande, a neutrino observatory in Japan, to analyze the neutrino oscillation patterns and calculate the Earth matter density. The results showed that the MSW theory accurately predicted the oscillation patterns and provided a reliable estimate of the Earth matter density. The findings have important implications for understanding the behavior of neutrinos and the structure of the Earth's interior.",2007-05-23,True
Tracking User Attention in Collaborative Tagging Communities,"  Collaborative tagging has recently attracted the attention of both industry
and academia due to the popularity of content-sharing systems such as
CiteULike, del.icio.us, and Flickr. These systems give users the opportunity to
add data items and to attach their own metadata (or tags) to stored data. The
result is an effective content management tool for individual users. Recent
studies, however, suggest that, as tagging communities grow, the added content
and the metadata become harder to manage due to an ease in content diversity.
Thus, mechanisms that cope with increase of diversity are fundamental to
improve the scalability and usability of collaborative tagging systems. This
paper analyzes whether usage patterns can be harnessed to improve navigability
in a growing knowledge space. To this end, it presents a characterization of
two collaborative tagging communities that target scientific literature:
CiteULike and Bibsonomy. We explore three main directions: First, we analyze
the tagging activity distribution across the user population. Second, we define
new metrics for similarity in user interest and use these metrics to uncover
the structure of the tagging communities we study. The structure we uncover
suggests a clear segmentation of interests into a large number of individuals
with unique preferences and a core set of users with interspersed interests.
Finally, we offer preliminary results that demonstrate that the interest-based
structure of the tagging community can be used to facilitate content usage as
communities scale.
",2007-06-24,False
Tracking User Attention in Collaborative Tagging Communities,"This research paper aims to investigate the tracking of user attention in collaborative tagging communities. Collaborative tagging is a process where users collectively assign tags to content, such as images or web pages, to organize and classify them. The focus of this study is to explore how user attention can be monitored and analyzed in these communities, specifically examining the factors that influence user attention and the impact of user attention on the quality of tagging and user engagement. The research will employ a mixed-methods approach, utilizing both quantitative and qualitative data collection and analysis. The findings of this research will contribute to the understanding of user behavior and engagement in collaborative tagging communities and inform the development of tools to improve the effectiveness of tagging systems.",2007-06-24,True
Periodic oscillations of dark solitons in parabolic potentials,"  We reformulate the Gross-Pitaevskii equation with an external parabolic
potential as a discrete dynamical system, by using the basis of Hermite
functions. We consider small amplitude stationary solutions with a single node,
called dark solitons, and examine their existence and linear stability.
Furthermore, we prove the persistence of a periodic motion in a neighborhood of
such solutions. Our results are corroborated by numerical computations
elucidating the existence, linear stability and dynamics of the relevant
solutions.
",2007-05-23,False
Periodic oscillations of dark solitons in parabolic potentials,"This research paper investigates the periodic oscillations of dark solitons in parabolic potentials. The study explores the dynamics of dark solitons, a localized wave packet that maintains its shape while propagating in a nonlinear medium. The findings reveal that the parabolic potential induces periodic oscillations in the soliton's amplitude, phase, and velocity. These oscillations have significant implications for the soliton's stability and suggest potential applications in optical and quantum communication systems. Overall, this research highlights the importance of understanding the fundamental properties of dark solitons in different potential landscapes.",2007-05-23,True
"Optical dilution and feedback cooling of a gram-scale oscillator to 6.9
  mK","  We report on use of a radiation pressure induced restoring force, the optical
spring effect, to optically dilute the mechanical damping of a 1 gram suspended
mirror, which is then cooled by active feedback (cold damping). Optical
dilution relaxes the limit on cooling imposed by mechanical losses, allowing
the oscillator mode to reach a minimum temperature of 6.9 mK, a factor of
~40000 below the environmental temperature. A further advantage of the optical
spring effect is that it can increase the number of oscillations before
decoherence by several orders of magnitude. In the present experiment we infer
an increase in the dynamical lifetime of the state by a factor of ~200.
",2009-11-13,False
"Optical dilution and feedback cooling of a gram-scale oscillator to 6.9
  mK","This research paper presents a study on the use of optical dilution and feedback cooling to achieve ultra-low temperature in a gram-scale oscillator. The experiment involves the use of a cryogen-free dilution refrigerator along with a high-power optical cavity to cool the oscillator down to 6.9 mK. The results show that the combined use of these techniques can provide a powerful tool for achieving extremely low temperatures in macroscopic systems. This research has significant implications for developing novel technologies that require ultra-cold temperatures, such as quantum computers and gravitational wave detectors.",2009-11-13,True
"Theoretical Analysis of Subthreshold Oscillatory Behaviors in Nonlinear
  Autonomous Systems","  We have developed a linearization method to investigate the subthreshold
oscillatory behaviors in nonlinear autonomous systems. By considering firstly
the neuronal system as an example, we show that this theoretical approach can
predict quantitatively the subthreshold oscillatory activities, including the
damping coefficients and the oscillatory frequencies which are in good
agreement with those observed in experiments. Then we generalize the
linearization method to an arbitrary autonomous nonlinear system. The detailed
extension of this theoretical approach is also presented and further discussed.
",2007-05-23,False
"Theoretical Analysis of Subthreshold Oscillatory Behaviors in Nonlinear
  Autonomous Systems","This research paper focuses on the theoretical analysis of subthreshold oscillatory behaviors in nonlinear autonomous systems. The authors investigate the conditions under which such oscillations can occur and the relationship between the system's parameters and the characteristics of the oscillations. They also explore the dynamics of the system near the onset of oscillations and demonstrate that the system's response to perturbations can change significantly as it approaches the oscillation threshold. The authors conclude that their analysis provides valuable insights into the behavior of nonlinear autonomous systems, which can be useful in a wide range of applications, from neuroscience to electronics.",2007-05-23,True
"Residual nuclide formation in 206,207,208,nat-Pb and 209-Bi induced by
  0.04-2.6 GeV Protons as well as in 56-Fe induced by 0.3-2.6 GeV Protons","  5972 independent and cumulative yields of radioactive residuals nuclei have
been measured in 55 thin 206,207,208,nat-Pb and 209-Bi targets irradiated by
0.04, 0.07, 0.10, 0.15, 0.25, 0.6, 0.8, 1.2, 1.4, 1.6, and 2.6 GeV protons.
Besides, 219 yields have been measured in 0.3, 0.5, 0.75, 1.0, 1.5, and 2.6 GeV
proton-irradiated 56-Fe target. The protons were extracted from the ITEP U-10
synchrotron. The measured data are compared with experimental results obtained
elsewhere and with theoretical calculations by LAHET, MCNPX, CEM03, LAQGSM03,
CASCADE, CASCADO, and LAHETO codes. The predictive power was found to be
different for each of the codes tested, but was satisfactory on the whole in
the case of spallation products. At the same time, none of the codes can
de-scribe well the product yields throughout the whole product mass range, and
all codes must be further improved.
",2007-05-23,False
"Residual nuclide formation in 206,207,208,nat-Pb and 209-Bi induced by
  0.04-2.6 GeV Protons as well as in 56-Fe induced by 0.3-2.6 GeV Protons","This research paper investigates the formation of residual nuclides in different target materials induced by proton beams with energies ranging from 0.04 to 2.6 GeV. Specifically, the study examines the production of residual nuclides in 206,207,208,nat-Pb and 209-Bi, as well as in 56-Fe. The experimental results reveal that the production cross-sections of residual nuclides are strongly dependent on the target material, proton energy, and incident angle. The study provides important insights into the mechanisms of nuclear reactions induced by proton beams, and the findings may have implications for the design of future nuclear facilities and radiation shielding.",2007-05-23,True
"Satellite Observations of Separator Line Geometry of Three-Dimensional
  Magnetic Reconnection","  Detection of a separator line that connects magnetic nulls and the
determination of the dynamics and plasma environment of such a structure can
improve our understanding of the three-dimensional (3D) magnetic reconnection
process. However, this type of field and particle configuration has not been
directly observed in space plasmas. Here we report the identification of a pair
of nulls, the null-null line that connects them, and associated fans and spines
in the magnetotail of Earth using data from the four Cluster spacecraft. With
di and de designating the ion and electron inertial lengths, respectively, the
separation between the nulls is found to be ~0.7di and an associated
oscillation is identified as a lower hybrid wave with wavelength ~ de. This in
situ evidence of the full 3D reconnection geometry and associated dynamics
provides an important step toward to establishing an observational framework of
3D reconnection.
",2007-07-02,False
"Satellite Observations of Separator Line Geometry of Three-Dimensional
  Magnetic Reconnection","This research paper focuses on the use of satellite observations to study the geometry of three-dimensional magnetic reconnection and the separator lines that form during the process. The study uses data from the Magnetospheric Multiscale (MMS) mission to analyze the formation and evolution of the separator lines in the Earth's magnetosphere. The results show that the separator lines are complex and highly dynamic structures that play a critical role in the energy transfer during magnetic reconnection. The findings have important implications for our understanding of space weather and the dynamics of magnetic fields in the universe. Ultimately, this research advances our knowledge of the fundamental physics behind magnetic reconnection and contributes to the development of more accurate models and predictions of space weather phenomena.",2007-07-02,True
"Angles Between Infinite Dimensional Subspaces with Applications to the
  Rayleigh-Ritz and Alternating Projectors Methods","  We define angles from-to and between infinite dimensional subspaces of a
Hilbert space, inspired by the work of E. J. Hannan, 1961/1962 for general
canonical correlations of stochastic processes. The spectral theory of
selfadjoint operators is used to investigate the properties of the angles,
e.g., to establish connections between the angles corresponding to orthogonal
complements. The classical gaps and angles of Dixmier and Friedrichs are
characterized in terms of the angles. We introduce principal invariant
subspaces and prove that they are connected by an isometry that appears in the
polar decomposition of the product of corresponding orthogonal projectors.
Point angles are defined by analogy with the point operator spectrum. We bound
the Hausdorff distance between the sets of the squared cosines of the angles
corresponding to the original subspaces and their perturbations. We show that
the squared cosines of the angles from one subspace to another can be
interpreted as Ritz values in the Rayleigh-Ritz method, where the former
subspace serves as a trial subspace and the orthogonal projector of the latter
subspace serves as an operator in the Rayleigh-Ritz method. The Hausdorff
distance between the Ritz values, corresponding to different trial subspaces,
is shown to be bounded by a constant times the gap between the trial subspaces.
We prove a similar eigenvalue perturbation bound that involves the gap squared.
Finally, we consider the classical alternating projectors method and propose
its ultimate acceleration, using the conjugate gradient approach. The
corresponding convergence rate estimate is obtained in terms of the angles. We
illustrate a possible acceleration for the domain decomposition method with a
small overlap for the 1D diffusion equation.
",2010-07-02,False
"Angles Between Infinite Dimensional Subspaces with Applications to the
  Rayleigh-Ritz and Alternating Projectors Methods","This research paper explores the notion of angles between infinite dimensional subspaces, specifically in the context of the Rayleigh-Ritz and alternating projectors methods. The primary theme is to investigate the relationship between these angles and the convergence rates of these two methods. The paper provides a theoretical framework for analyzing these angles and presents several significant findings. One important conclusion is that the convergence rate of the Rayleigh-Ritz method is related to the angle between the subspace generated by the eigenvectors of the matrix and the subspace generated by the trial vectors. Another key finding is that the alternating projectors method converges faster when the angle between the subspaces is smaller. Overall, this paper contributes to a better understanding of the behavior of these methods and provides insights into their performance in various applications.",2010-07-02,True
"High-energy threshold reaction rates on 0.8 GeV proton-irradiated thick
  Pb-target","  This works presents results of activation-aided determination of threshold
reaction rates in 92 209Bi, natPb, 197Au, 181Ta, 169Tm, natIn, 93Nb, 64Zn,
65Cu, 63Cu, 59Co, 19F, and 12C samples and in 121 27Al samples. All the samples
were aligned with the proton beam axis inside and outside the demountable 92-cm
thick Pb target of 15-cm diameter assembled of 23 4-cm thick discs. The samples
were placed on 12 target disks to reproduce the long axis distribution of
protons and neutrons. In June 2006, the target was exposed for 18 hours to a
800-MeV proton beam extracted from the ITEP U-10 accelerator. The proton
fluence and the proton beam shape were determined using the 27Al(p,x)7Be
monitor reaction. The reaction rates were determined by the direct
gamma-spectrometry techniques. In total, 1196 gamma-spectra have been measured,
and about 1500 reaction rates determined. The measured reaction rates were
simulated by the MCNPX code using the following databases: ENDF/B6 for neutrons
below 20 MeV, MENDL2 for 20-100 MeV neutrons, and MENDL2P for proton cross
sections up to 200 MeV. An acceptable agreement of simulations with
experimental data has been found.
",2007-05-23,False
"High-energy threshold reaction rates on 0.8 GeV proton-irradiated thick
  Pb-target","The research paper investigates the high-energy threshold reaction rates on a 0.8 GeV proton-irradiated thick Pb-target. The study found that the reaction rates increase with increasing proton energy and target thickness, and that the production of residual nuclides is dominated by spallation and fission reactions. These findings have implications for nuclear physics, radiation protection, and nuclear waste management.",2007-05-23,True
"No Way Back: Maximizing survival time below the Schwarzschild event
  horizon","  It has long been known that once you cross the event horizon of a black hole,
your destiny lies at the central singularity, irrespective of what you do.
Furthermore, your demise will occur in a finite amount of proper time. In this
paper, the use of rockets in extending the amount of time before the collision
with the central singularity is examined. In general, the use of such rockets
can increase your remaining time, but only up to a maximum value; this is at
odds with the ``more you struggle, the less time you have'' statement that is
sometimes discussed in relation to black holes. The derived equations are
simple to solve numerically and the framework can be employed as a teaching
tool for general relativity.
",2009-11-13,False
"No Way Back: Maximizing survival time below the Schwarzschild event
  horizon","This research paper explores the concept of maximizing survival time below the Schwarzschild event horizon, with a focus on the impossibility of escaping once crossed. The study examines the different strategies that could prolong human survival within this region, such as the use of advanced technology and the manipulation of time dilation effects. The critical outcomes of this research are the identification of the limits of human survival in such extreme conditions and the need for further exploration of innovative techniques to enhance survival time. The conclusion highlights the importance of continued research in this area to expand our understanding of the fundamental laws of physics and the potential implications for space exploration and beyond.",2009-11-13,True
Detection of Aneuploidy with Digital PCR,"  The widespread use of genetic testing in high risk pregnancies has created
strong interest in rapid and accurate molecular diagnostics for common
chromosomal aneuploidies. We show here that digital polymerase chain reaction
(dPCR) can be used for accurate measurement of trisomy 21 (Down's Syndrome),
the most common human aneuploidy. dPCR is generally applicable to any
aneuploidy, does not depend on allelic distribution or gender, and is able to
detect signals in the presence of mosaics or contaminating maternal DNA.
",2007-05-23,False
Detection of Aneuploidy with Digital PCR,"This research paper discusses the use of digital PCR (dPCR) as a method for detecting aneuploidy, a condition where there is an abnormal number of chromosomes in a cell. The study concluded that dPCR is a reliable and accurate technique for detecting aneuploidy, and can potentially be used as a non-invasive prenatal testing method. The results of the study highlight the potential of dPCR as a diagnostic tool for genetic disorders.",2007-05-23,True
"Fuzzy Artmap and Neural Network Approach to Online Processing of Inputs
  with Missing Values","  An ensemble based approach for dealing with missing data, without predicting
or imputing the missing values is proposed. This technique is suitable for
online operations of neural networks and as a result, is used for online
condition monitoring. The proposed technique is tested in both classification
and regression problems. An ensemble of Fuzzy-ARTMAPs is used for
classification whereas an ensemble of multi-layer perceptrons is used for the
regression problem. Results obtained using this ensemble-based technique are
compared to those obtained using a combination of auto-associative neural
networks and genetic algorithms and findings show that this method can perform
up to 9% better in regression problems. Another advantage of the proposed
technique is that it eliminates the need for finding the best estimate of the
data, and hence, saves time.
",2007-05-23,False
"Fuzzy Artmap and Neural Network Approach to Online Processing of Inputs
  with Missing Values",This research paper focuses on the application of Fuzzy ARTMAP and neural network techniques for online processing of inputs that contain missing values. The study reveals that the proposed approach achieves high accuracy in predicting missing values and outperforms other existing methods. The outcomes of this study highlight the potential of Fuzzy ARTMAP and neural networks as effective tools for handling incomplete data in online processing applications.,2007-05-23,True
"The 2003 Outburst of the X-ray Transient H 1743-322: Comparisons with
  the Black Hole Microquasar XTE J1550-564","  The bright X-ray transient H 1743-322 was observed daily by the Rossi X-ray
Timing Explorer (RXTE) during most of its 8-month outburst in 2003. We present
a detailed spectral analysis and a supporting timing analysis of all of these
data, and we discuss the behavior and evolution of the source in terms of the
three principal X-ray states defined by Remillard and McClintock. These X-ray
results are complemented by Very Large Array (VLA) data obtained at six
frequencies that provide quite complete coverage of the entire outburst cycle
at 4.860 GHz and 8.460 GHz. We also present photometric data and finding charts
for the optical counterpart in both outburst and quiescence. We closely compare
H 1743-322 to the well-studied black-hole X-ray transient XTE J1550-564 and
find the behaviors of these systems to be very similar. As reported elsewhere,
both H 1743-322 and XTE J1550-564 are relativistic jet sources and both exhibit
a pair of high-frequency QPO oscillations with a 3:2 frequency ratio. The many
striking similarities between these two sources argue strongly that H 1743-322
is a black hole binary, although presently no dynamical data exist to support
this conclusion.
",2009-06-23,False
"The 2003 Outburst of the X-ray Transient H 1743-322: Comparisons with
  the Black Hole Microquasar XTE J1550-564","The research paper discusses the outburst of the X-ray transient H 1743-322 in 2003 and compares it to the black hole microquasar XTE J1550-564. The authors analyze the X-ray and radio properties of both objects during their outbursts and find that H 1743-322 had a longer duration and lower peak luminosity than XTE J1550-564. They also suggest that the differences in the outburst properties may be due to the different accretion rates and magnetic field strengths of the black holes. Overall, the paper provides insight into the behavior of black holes during outbursts and highlights the importance of studying multiple objects to understand the underlying physics.",2009-06-23,True
Strategies for the Design of a Slide-o-Cam Transmission,"  The optimization of the pressure angle in a cam-follower transmission is
reported in this paper. This transmission is based on Slide-o-Cam, a cam
mechanism with multiple rollers mounted on a common translating follower. The
design of Slide-o-Cam, a transmission intended to produce a sliding motion from
a turning drive, or vice versa, was reported elsewhere. This transmission
provides pure-rolling motion, thereby reducing the friction of rack-and-pinions
and linear drives. The pressure angle is a suitable performance index for this
transmission because it determines the amount of force transmitted to the load
vs. that transmitted to the machine frame. Two alternative design strategies
are studied, namely, (i) increase the number of lobes on each cam or (ii)
increase the number of cams. This device is intended to replace the current
ball-screws in Orthoglide, a three-DOF parallel robot for the production of
translational motions, currently under development at Ecole Centrale de Nantes
for machining applications.
",2007-05-23,False
Strategies for the Design of a Slide-o-Cam Transmission,"The research paper titled ""Strategies for the Design of a Slide-o-Cam Transmission"" discusses the design strategies for a slide-o-cam transmission, which is a type of variable transmission used in various mechanical systems. The paper highlights the importance of considering the design parameters of the transmission, such as the cam profile, cam follower, and sliding mechanism, in order to optimize its performance. The authors present different design approaches and simulation techniques that can be used to evaluate the transmission's efficiency, power density, and durability. The paper concludes that the design of a slide-o-cam transmission depends on the specific application requirements and that a careful selection of design parameters can lead to significant improvements in its functionality. Overall, the research provides valuable insights into the design process of this type of transmission and offers practical recommendations for its optimization.",2007-05-23,True
"Regions of Feasible Point-to-Point Trajectories in the Cartesian
  Workspace of Fully-Parallel Manipulators","  The goal of this paper is to define the n-connected regions in the Cartesian
workspace of fully-parallel manipulators, i.e. the maximal regions where it is
possible to execute point-to-point motions. The manipulators considered in this
study may have multiple direct and inverse kinematic solutions. The N-connected
regions are characterized by projection, onto the Cartesian workspace, of the
connected components of the reachable configuration space defined in the
Cartesian product of the Cartesian space by the joint space. Generalized octree
models are used for the construction of all spaces. This study is illustrated
with a simple planar fully-parallel manipulator.
",2007-05-23,False
"Regions of Feasible Point-to-Point Trajectories in the Cartesian
  Workspace of Fully-Parallel Manipulators",This research paper investigates the regions of feasible point-to-point trajectories in the Cartesian workspace of fully-parallel manipulators. The study aims to identify the geometric constraints that restrict the end-effector's motion and determine the feasible regions of motion. The research employs mathematical modeling and simulation techniques to develop a methodology for analyzing the workspace of parallel manipulators. The study's findings highlight the importance of considering the manipulator's geometry in determining the feasible regions of motion and provide insights into the design of parallel manipulators for optimal performance. The research concludes that the proposed methodology is effective in analyzing the workspace of parallel manipulators and can be used in the design and optimization of these systems.,2007-05-23,True
"The Design of Parallel Kinematic Machine Tools Using Kinetostatic
  Performance Criteria","  Most industrial machine tools have a serial kinematic architecture, which
means that each axis has to carry the following one, including its actuators
and joints. High Speed Machining highlights some drawbacks of such
architectures: heavy moving parts require from the machine structure high
stiffness to limit bending problems that lower the machine accuracy, and limit
the dynamic performances of the feed axes. That is why PKMs attract more and
more researchers and companies, because they are claimed to offer several
advantages over their serial counterparts, like high structural rigidity and
high dynamic capacities. Indeed, the parallel kinematic arrangement of the
links provides higher stiffness and lower moving masses that reduce inertia
effects. Thus, PKMs have better dynamic performances. However, the design of a
parallel kinematic machine tool (PKMT) is a hard task that requires further
research studies before wide industrial use can be expected. Many criteria need
to be taken into account in the design of a PKMT. We pay special attention to
the description of kinetostatic criteria that rely on the conditioning of the
Jacobian matrix of the mechanism. The organisation of this paper is as follows:
next section introduces general remarks about PKMs, then is explained why PKMs
can be interesting alternative machine tool designs. Then are presented
existing PKMTs. An application to the design of a small-scale machine tool
prototype developed at IRCCyN is presented at the end of this paper.
",2007-05-23,False
"The Design of Parallel Kinematic Machine Tools Using Kinetostatic
  Performance Criteria","The paper presents a novel approach for designing parallel kinematic machine tools (PKMTs) using Kinetostatic Performance Criteria (KPC) as the basis for design optimization. The KPC approach considers the dynamic performance of the machine tool, such as its stiffness, accuracy, and workspace, in addition to its kinematic performance. The paper demonstrates the effectiveness of the KPC approach through a case study involving the design of a 5-axis PKMT. The results show that the KPC approach can significantly improve the performance of PKMTs compared to traditional design approaches. The paper concludes that the KPC approach can provide a valuable tool for the design and optimization of PKMTs in various applications.",2007-05-23,True
"Statistical Mechanics of the Glass Transition in One-Component Liquids
  with Anisotropic Potential","  We study a recently introduced model of one-component glass-forming liquids
whose constituents interact with anisotropic potential. This system is
interesting per-se and as a model of liquids like glycerol (interacting via
hydrogen bonds) which are excellent glass formers. We work out the statistical
mechanics of this system, encoding the liquid and glass disorder using
appropriate quasi-particles (36 of them). The theory provides a full
explanation of the glass transition phenomenology, including the identification
of a diverging length scale and a relation between the structural changes and
the diverging relaxation times.
",2009-11-13,False
"Statistical Mechanics of the Glass Transition in One-Component Liquids
  with Anisotropic Potential","The glass transition in one-component liquids with anisotropic potential is a fundamental problem in statistical mechanics. In this research paper, we investigate the mechanism of glass transition using computer simulations and theoretical analysis. Our results show that the anisotropy of the potential has a significant impact on the glass-forming ability of the liquid. We find that the glass transition occurs when the relaxation time of the liquid becomes extremely long, and the system becomes stuck in a metastable state. Moreover, we show that the dynamics of the glass transition can be described by a mode-coupling theory, which predicts the existence of a critical point separating the liquid and glass phases. Our findings provide insight into the fundamental physics of glass transition and have important implications for materials science and engineering.",2009-11-13,True
"Couplings between a single massless tensor field with the mixed symmetry
  (3,1) and one vector field","  Under the hypotheses of smoothness in the coupling constant, locality,
Lorentz covariance, and Poincare invariance of the deformations, combined with
the preservation of the number of derivatives on each field, the consistent
interactions between a single free massless tensor gauge field with the mixed
symmetry of a two-column Young diagram of the type (3,1) and one Abelian vector
field have been investigated. The computations are done with the help of the
deformation theory based on a cohomological approach, in the context of the
antifield-BRST formalism. The main result is that there exist nontrivial
cross-couplings between these types of fields in five spatiotemporal
dimensions, which break the PT invariance and allow for the deformation of the
gauge transformations of the vector field, but not of the gauge algebra.
",2008-11-26,False
"Couplings between a single massless tensor field with the mixed symmetry
  (3,1) and one vector field","The research paper titled ""Couplings between a single massless tensor field with the mixed symmetry (3,1) and one vector field"" explores the interaction between a massless tensor field and a vector field. The paper focuses on a specific type of tensor field with mixed symmetry (3,1), and investigates the couplings between this field and a vector field in the context of general relativity. The authors derive the equations of motion for both fields and analyze the resulting dynamics. They find that the tensor field has both propagating and non-propagating modes, and that the vector field can interact with both types of modes. The paper concludes that this coupling between the tensor and vector fields has important implications for gravitational waves and the overall behavior of the universe.",2008-11-26,True
